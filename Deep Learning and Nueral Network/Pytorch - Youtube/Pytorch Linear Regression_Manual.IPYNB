{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inputs=np.array(\n",
    "                [[73,67,43],\n",
    "                 [91,88,64],\n",
    "                 [87,134,58],\n",
    "                 [102,43,37],\n",
    "                 [69,96,70]\n",
    "                ], dtype='float32'\n",
    ")\n",
    "\n",
    "Targets=np.array([\n",
    "                [56,70],\n",
    "                [81,101],\n",
    "                [119,133],\n",
    "                [22,37],\n",
    "                [103,119]\n",
    "],dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56.,  70.],\n",
       "       [ 81., 101.],\n",
       "       [119., 133.],\n",
       "       [ 22.,  37.],\n",
       "       [103., 119.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=torch.from_numpy(Inputs)\n",
    "targets=torch.from_numpy(Targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will start with random value\n",
    "w=torch.randn(2,3,requires_grad=True)\n",
    "b=torch.randn(2,requires_grad=True)\n",
    "loss=torch.tensor(2.0,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0416, -0.1877,  1.6296],\n",
       "        [-0.7736,  0.5379,  2.2422]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0281,  0.4673], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x@w.t()+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 54.4356,  76.4451],\n",
       "        [ 83.9676, 120.9020],\n",
       "        [ 65.7243, 135.2850],\n",
       "        [ 47.9558,  27.6471],\n",
       "        [ 93.1587, 155.6786]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE Loss = difference square ==> sum it up ==> devide by number of elements\n",
    "def mse(t1,t2):\n",
    "    diff=t1-t2\n",
    "    return torch.sum(diff*diff)/diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss= mse(preds,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(549.5757, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0416, -0.1877,  1.6296],\n",
      "        [-0.7736,  0.5379,  2.2422]], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -502.1391, -1362.2559,  -539.1724],\n",
       "        [  811.4393,  1121.6715,   780.9682]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(w)\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0281,  0.4673], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-7.1516, 11.1916])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(b)\n",
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=0.00001\n",
    "w = w - le*w.grad\n",
    "b = b - le*b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0366, -0.1740,  1.6350],\n",
       "        [-0.7818,  0.5267,  2.2344]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0280,  0.4672], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(504.4145, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -344.3463, -1187.6105,  -432.6481],\n",
      "        [  637.3398,   932.9778,   664.7554]])\n",
      "tensor([-5.2683,  9.1216])\n",
      "Epoch: 0\n",
      "Loss: tensor(504.4145, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0331, -0.1622,  1.6393],\n",
      "        [-0.7881,  0.5173,  2.2278]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0279,  0.4671], grad_fn=<SubBackward0>)\n",
      "tensor(472.8268, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -215.2654, -1043.8408,  -345.1712],\n",
      "        [  494.5739,   777.9542,   569.3196]])\n",
      "tensor([-3.7257,  7.4233])\n",
      "Epoch: 1\n",
      "Loss: tensor(472.8268, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0310, -0.1517,  1.6428],\n",
      "        [-0.7931,  0.5095,  2.2221]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0279,  0.4670], grad_fn=<SubBackward0>)\n",
      "tensor(450.3995, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[-109.7522, -925.4208, -273.3312],\n",
      "        [ 377.5306,  650.5728,  490.9408]])\n",
      "tensor([-2.4627,  6.0302])\n",
      "Epoch: 2\n",
      "Loss: tensor(450.3995, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0299, -0.1425,  1.6455],\n",
      "        [-0.7969,  0.5030,  2.2172]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0279,  0.4670], grad_fn=<SubBackward0>)\n",
      "tensor(434.1588, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -23.5816, -827.8107, -214.3267],\n",
      "        [ 281.6021,  545.8842,  426.5643]])\n",
      "tensor([-1.4292,  4.8875])\n",
      "Epoch: 3\n",
      "Loss: tensor(434.1588, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0296, -0.1342,  1.6476],\n",
      "        [-0.7997,  0.4976,  2.2129]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0279,  0.4669], grad_fn=<SubBackward0>)\n",
      "tensor(422.1003, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  46.7124, -747.2877, -165.8602],\n",
      "        [ 203.0067,  459.8259,  373.6832]])\n",
      "tensor([-0.5840,  3.9505])\n",
      "Epoch: 4\n",
      "Loss: tensor(422.1003, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0301, -0.1267,  1.6493],\n",
      "        [-0.8017,  0.4930,  2.2092]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0278,  0.4669], grad_fn=<SubBackward0>)\n",
      "tensor(412.8733, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 103.9758, -680.7946, -126.0446],\n",
      "        [ 138.6381,  389.0605,  330.2378]])\n",
      "tensor([0.1064, 3.1822])\n",
      "Epoch: 5\n",
      "Loss: tensor(412.8733, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0311, -0.1199,  1.6506],\n",
      "        [-0.8031,  0.4891,  2.2059]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0278,  0.4669], grad_fn=<SubBackward0>)\n",
      "tensor(405.5672, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 150.5457, -625.8196,  -93.3306],\n",
      "        [  85.9475,  330.8505,  294.5386]])\n",
      "tensor([0.6700, 2.5525])\n",
      "Epoch: 6\n",
      "Loss: tensor(405.5672, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0326, -0.1136,  1.6515],\n",
      "        [-0.8039,  0.4858,  2.2029]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0279,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(399.5685, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 188.3403, -580.3032,  -66.4465],\n",
      "        [  42.8422,  282.9476,  265.1982]])\n",
      "tensor([1.1294, 2.0365])\n",
      "Epoch: 7\n",
      "Loss: tensor(399.5685, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0345, -0.1078,  1.6521],\n",
      "        [-0.8044,  0.4830,  2.2003]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0279,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(394.4631, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 218.9340, -542.5527,  -44.3483],\n",
      "        [   7.6057,  243.5076,  241.0785]])\n",
      "tensor([1.5033, 1.6139])\n",
      "Epoch: 8\n",
      "Loss: tensor(394.4631, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0367, -0.1024,  1.6526],\n",
      "        [-0.8044,  0.4805,  2.1979]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0279,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(389.9724, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 243.6181, -511.1816,  -26.1799],\n",
      "        [ -21.1735,  211.0144,  221.2437]])\n",
      "tensor([1.8071, 1.2678])\n",
      "Epoch: 9\n",
      "Loss: tensor(389.9724, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0392, -0.0973,  1.6529],\n",
      "        [-0.8042,  0.4784,  2.1957]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0279,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(385.9080, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 263.4548, -485.0483,  -11.2371],\n",
      "        [ -44.6528,  184.2245,  204.9266]])\n",
      "tensor([2.0533, 0.9847])\n",
      "Epoch: 10\n",
      "Loss: tensor(385.9080, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0418, -0.0925,  1.6530],\n",
      "        [-0.8038,  0.4766,  2.1936]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0279,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(382.1433, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 279.3151, -463.2170,    1.0577],\n",
      "        [ -63.7799,  162.1203,  191.4991]])\n",
      "tensor([2.2522, 0.7532])\n",
      "Epoch: 11\n",
      "Loss: tensor(382.1433, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0446, -0.0878,  1.6530],\n",
      "        [-0.8032,  0.4749,  2.1917]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0279,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(378.5923, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 291.9127, -444.9210,   11.1775],\n",
      "        [ -79.3380,  143.8595,  180.4415]])\n",
      "tensor([2.4124, 0.5641])\n",
      "Epoch: 12\n",
      "Loss: tensor(378.5923, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0475, -0.0834,  1.6528],\n",
      "        [-0.8024,  0.4735,  2.1899]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0280,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(375.1971, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 301.8353, -429.5285,   19.5124],\n",
      "        [ -91.9648,  128.7575,  171.3311]])\n",
      "tensor([2.5407, 0.4097])\n",
      "Epoch: 13\n",
      "Loss: tensor(375.1971, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0505, -0.0791,  1.6526],\n",
      "        [-0.8014,  0.4722,  2.1882]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0280,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(371.9189, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 309.5648, -416.5222,   26.3814],\n",
      "        [-102.1885,  116.2468,  163.8180]])\n",
      "tensor([2.6430, 0.2839])\n",
      "Epoch: 14\n",
      "Loss: tensor(371.9189, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0536, -0.0749,  1.6524],\n",
      "        [-0.8004,  0.4711,  2.1865]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0280,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(368.7305, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 315.4969, -405.4761,   32.0473],\n",
      "        [-110.4391,  105.8655,  157.6169]])\n",
      "tensor([2.7239, 0.1815])\n",
      "Epoch: 15\n",
      "Loss: tensor(368.7305, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0568, -0.0709,  1.6521],\n",
      "        [-0.7993,  0.4700,  2.1850]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0280,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(365.6146, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 319.9556, -396.0424,   36.7249],\n",
      "        [-117.0703,   97.2336,  152.4933]])\n",
      "tensor([2.7873, 0.0984])\n",
      "Epoch: 16\n",
      "Loss: tensor(365.6146, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0600, -0.0669,  1.6517],\n",
      "        [-0.7981,  0.4690,  2.1834]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0281,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(362.5583, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 323.2074, -387.9342,   40.5910],\n",
      "        [-122.3738,   90.0372,  148.2538]])\n",
      "tensor([2.8362, 0.0310])\n",
      "Epoch: 17\n",
      "Loss: tensor(362.5583, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0632, -0.0630,  1.6513],\n",
      "        [-0.7969,  0.4681,  2.1820]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0281,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(359.5537, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 325.4713, -380.9168,   43.7908],\n",
      "        [-126.5883,   84.0206,  144.7402]])\n",
      "tensor([ 2.8734, -0.0234])\n",
      "Epoch: 18\n",
      "Loss: tensor(359.5537, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0665, -0.0592,  1.6509],\n",
      "        [-0.7957,  0.4673,  2.1805]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0281,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(356.5947, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 326.9267, -374.7968,   46.4432],\n",
      "        [-129.9097,   78.9728,  141.8225]])\n",
      "tensor([ 2.9009, -0.0673])\n",
      "Epoch: 19\n",
      "Loss: tensor(356.5947, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0697, -0.0555,  1.6504],\n",
      "        [-0.7944,  0.4665,  2.1791]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0282,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(353.6772, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 327.7210, -369.4159,   48.6460],\n",
      "        [-132.4980,   74.7220,  139.3947]])\n",
      "tensor([ 2.9205, -0.1024])\n",
      "Epoch: 20\n",
      "Loss: tensor(353.6772, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0730, -0.0518,  1.6499],\n",
      "        [-0.7930,  0.4657,  2.1777]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0282,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(350.7984, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 327.9749, -364.6436,   50.4796],\n",
      "        [-134.4873,   71.1240,  137.3679]])\n",
      "tensor([ 2.9337, -0.1303])\n",
      "Epoch: 21\n",
      "Loss: tensor(350.7984, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0763, -0.0481,  1.6494],\n",
      "        [-0.7917,  0.4650,  2.1763]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0282,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(347.9563, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 327.7881, -360.3737,   52.0097],\n",
      "        [-135.9840,   68.0645,  135.6714]])\n",
      "tensor([ 2.9415, -0.1525])\n",
      "Epoch: 22\n",
      "Loss: tensor(347.9563, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0796, -0.0445,  1.6489],\n",
      "        [-0.7903,  0.4644,  2.1750]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0282,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(345.1494, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 327.2420, -356.5179,   53.2907],\n",
      "        [-137.0768,   65.4481,  134.2465]])\n",
      "tensor([ 2.9450, -0.1697])\n",
      "Epoch: 23\n",
      "Loss: tensor(345.1494, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0828, -0.0410,  1.6483],\n",
      "        [-0.7890,  0.4637,  2.1736]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0283,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(342.3764, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 326.4033, -353.0044,   54.3667],\n",
      "        [-137.8401,   63.1949,  133.0437]])\n",
      "tensor([ 2.9450, -0.1831])\n",
      "Epoch: 24\n",
      "Loss: tensor(342.3764, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0861, -0.0374,  1.6478],\n",
      "        [-0.7876,  0.4631,  2.1723]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0283,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(339.6364, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 325.3267, -349.7744,   55.2741],\n",
      "        [-138.3324,   61.2419,  132.0243]])\n",
      "tensor([ 2.9420, -0.1932])\n",
      "Epoch: 25\n",
      "Loss: tensor(339.6364, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0894, -0.0339,  1.6472],\n",
      "        [-0.7862,  0.4625,  2.1710]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0283,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(336.9288, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 324.0579, -346.7787,   56.0431],\n",
      "        [-138.6053,   59.5339,  131.1541]])\n",
      "tensor([ 2.9368, -0.2007])\n",
      "Epoch: 26\n",
      "Loss: tensor(336.9288, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0926, -0.0305,  1.6467],\n",
      "        [-0.7848,  0.4619,  2.1697]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0284,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(334.2530, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 322.6336, -343.9774,   56.6985],\n",
      "        [-138.6967,   58.0298,  130.4079]])\n",
      "tensor([ 2.9296, -0.2061])\n",
      "Epoch: 27\n",
      "Loss: tensor(334.2530, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0958, -0.0270,  1.6461],\n",
      "        [-0.7834,  0.4613,  2.1684]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0284,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(331.6082, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 321.0841, -341.3378,   57.2602],\n",
      "        [-138.6412,   56.6926,  129.7628]])\n",
      "tensor([ 2.9209, -0.2096])\n",
      "Epoch: 28\n",
      "Loss: tensor(331.6082, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.0990, -0.0236,  1.6455],\n",
      "        [-0.7820,  0.4607,  2.1671]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0284,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(328.9941, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 319.4338, -338.8339,   57.7444],\n",
      "        [-138.4653,   55.4934,  129.2010]])\n",
      "tensor([ 2.9109, -0.2117])\n",
      "Epoch: 29\n",
      "Loss: tensor(328.9941, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1022, -0.0202,  1.6450],\n",
      "        [-0.7806,  0.4602,  2.1658]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0285,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(326.4102, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 317.7033, -336.4432,   58.1648],\n",
      "        [-138.1908,   54.4093,  128.7084]])\n",
      "tensor([ 2.8999, -0.2126])\n",
      "Epoch: 30\n",
      "Loss: tensor(326.4102, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1054, -0.0169,  1.6444],\n",
      "        [-0.7793,  0.4596,  2.1645]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0285,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(323.8562, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 315.9096, -334.1472,   58.5329],\n",
      "        [-137.8366,   53.4195,  128.2722]])\n",
      "tensor([ 2.8881, -0.2126])\n",
      "Epoch: 31\n",
      "Loss: tensor(323.8562, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1086, -0.0135,  1.6438],\n",
      "        [-0.7779,  0.4591,  2.1632]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0285,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(321.3317, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 314.0665, -331.9310,   58.8578],\n",
      "        [-137.4181,   52.5076,  127.8822]])\n",
      "tensor([ 2.8756, -0.2118])\n",
      "Epoch: 32\n",
      "Loss: tensor(321.3317, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1117, -0.0102,  1.6432],\n",
      "        [-0.7765,  0.4586,  2.1619]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0285,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(318.8360, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 312.1852, -329.7823,   59.1471],\n",
      "        [-136.9484,   51.6592,  127.5295]])\n",
      "tensor([ 2.8626, -0.2103])\n",
      "Epoch: 33\n",
      "Loss: tensor(318.8360, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1148, -0.0069,  1.6426],\n",
      "        [-0.7751,  0.4580,  2.1606]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0286,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(316.3691, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 310.2743, -327.6918,   59.4064],\n",
      "        [-136.4363,   50.8652,  127.2087]])\n",
      "tensor([ 2.8492, -0.2083])\n",
      "Epoch: 34\n",
      "Loss: tensor(316.3691, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1179, -0.0036,  1.6420],\n",
      "        [-0.7738,  0.4575,  2.1594]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0286,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(313.9303, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 308.3419, -325.6505,   59.6413],\n",
      "        [-135.8914,   50.1149,  126.9129]])\n",
      "tensor([ 2.8355, -0.2059])\n",
      "Epoch: 35\n",
      "Loss: tensor(313.9303, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-1.2101e-01, -3.5906e-04,  1.6414e+00],\n",
      "        [-7.7242e-01,  4.5703e-01,  2.1581e+00]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0286,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(311.5195, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 306.3942, -323.6516,   59.8559],\n",
      "        [-135.3177,   49.4040,  126.6398]])\n",
      "tensor([ 2.8215, -0.2031])\n",
      "Epoch: 36\n",
      "Loss: tensor(311.5195, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1241,  0.0029,  1.6408],\n",
      "        [-0.7711,  0.4565,  2.1568]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0287,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(309.1362, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 304.4365, -321.6894,   60.0537],\n",
      "        [-134.7236,   48.7236,  126.3837]])\n",
      "tensor([ 2.8074, -0.2001])\n",
      "Epoch: 37\n",
      "Loss: tensor(309.1362, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1271,  0.0061,  1.6402],\n",
      "        [-0.7697,  0.4560,  2.1556]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0287,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(306.7802, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 302.4721, -319.7600,   60.2371],\n",
      "        [-134.1122,   48.0703,  126.1426]])\n",
      "tensor([ 2.7931, -0.1969])\n",
      "Epoch: 38\n",
      "Loss: tensor(306.7802, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1301,  0.0093,  1.6396],\n",
      "        [-0.7684,  0.4556,  2.1543]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0287,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(304.4511, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 300.5051, -317.8590,   60.4088],\n",
      "        [-133.4884,   47.4386,  125.9130]])\n",
      "tensor([ 2.7788, -0.1935])\n",
      "Epoch: 39\n",
      "Loss: tensor(304.4511, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1331,  0.0125,  1.6390],\n",
      "        [-0.7670,  0.4551,  2.1531]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0287,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(302.1485, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 298.5385, -315.9827,   60.5710],\n",
      "        [-132.8539,   46.8270,  125.6940]])\n",
      "tensor([ 2.7643, -0.1899])\n",
      "Epoch: 40\n",
      "Loss: tensor(302.1485, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1361,  0.0156,  1.6384],\n",
      "        [-0.7657,  0.4546,  2.1518]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0288,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(299.8721, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 296.5738, -314.1298,   60.7244],\n",
      "        [-132.2128,   46.2303,  125.4826]])\n",
      "tensor([ 2.7499, -0.1862])\n",
      "Epoch: 41\n",
      "Loss: tensor(299.8721, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1391,  0.0188,  1.6378],\n",
      "        [-0.7644,  0.4542,  2.1505]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0288,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(297.6217, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 294.6128, -312.2979,   60.8707],\n",
      "        [-131.5655,   45.6489,  125.2789]])\n",
      "tensor([ 2.7354, -0.1825])\n",
      "Epoch: 42\n",
      "Loss: tensor(297.6217, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1420,  0.0219,  1.6372],\n",
      "        [-0.7631,  0.4537,  2.1493]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0288,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(295.3967, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 292.6582, -310.4841,   61.0114],\n",
      "        [-130.9156,   45.0780,  125.0800]])\n",
      "tensor([ 2.7209, -0.1787])\n",
      "Epoch: 43\n",
      "Loss: tensor(295.3967, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1450,  0.0250,  1.6366],\n",
      "        [-0.7618,  0.4533,  2.1480]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0288,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(293.1970, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 290.7096, -308.6885,   61.1464],\n",
      "        [-130.2627,   44.5187,  124.8866]])\n",
      "tensor([ 2.7065, -0.1748])\n",
      "Epoch: 44\n",
      "Loss: tensor(293.1970, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1479,  0.0281,  1.6360],\n",
      "        [-0.7605,  0.4528,  2.1468]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0289,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(291.0223, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 288.7696, -306.9082,   61.2776],\n",
      "        [-129.6093,   43.9680,  124.6967]])\n",
      "tensor([ 2.6921, -0.1709])\n",
      "Epoch: 45\n",
      "Loss: tensor(291.0223, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1508,  0.0312,  1.6354],\n",
      "        [-0.7592,  0.4524,  2.1455]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0289,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(288.8722, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 286.8373, -305.1440,   61.4044],\n",
      "        [-128.9545,   43.4268,  124.5112]])\n",
      "tensor([ 2.6777, -0.1670])\n",
      "Epoch: 46\n",
      "Loss: tensor(288.8722, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1536,  0.0342,  1.6348],\n",
      "        [-0.7579,  0.4519,  2.1443]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0289,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(286.7464, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 284.9146, -303.3937,   61.5281],\n",
      "        [-128.3011,   42.8920,  124.3279]])\n",
      "tensor([ 2.6634, -0.1630])\n",
      "Epoch: 47\n",
      "Loss: tensor(286.7464, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1565,  0.0372,  1.6341],\n",
      "        [-0.7566,  0.4515,  2.1431]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0290,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(284.6446, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 283.0014, -301.6574,   61.6487],\n",
      "        [-127.6493,   42.3636,  124.1468]])\n",
      "tensor([ 2.6491, -0.1591])\n",
      "Epoch: 48\n",
      "Loss: tensor(284.6446, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1593,  0.0403,  1.6335],\n",
      "        [-0.7553,  0.4511,  2.1418]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0290,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(282.5666, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 281.0989, -299.9337,   61.7670],\n",
      "        [-126.9987,   41.8417,  123.9683]])\n",
      "tensor([ 2.6349, -0.1552])\n",
      "Epoch: 49\n",
      "Loss: tensor(282.5666, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1621,  0.0433,  1.6329],\n",
      "        [-0.7541,  0.4507,  2.1406]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0290,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(280.5119, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 279.2063, -298.2230,   61.8825],\n",
      "        [-126.3504,   41.3251,  123.7912]])\n",
      "tensor([ 2.6208, -0.1512])\n",
      "Epoch: 50\n",
      "Loss: tensor(280.5119, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1649,  0.0462,  1.6323],\n",
      "        [-0.7528,  0.4502,  2.1393]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0290,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(278.4804, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 277.3242, -296.5247,   61.9959],\n",
      "        [-125.7045,   40.8135,  123.6157]])\n",
      "tensor([ 2.6067, -0.1473])\n",
      "Epoch: 51\n",
      "Loss: tensor(278.4804, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1677,  0.0492,  1.6317],\n",
      "        [-0.7515,  0.4498,  2.1381]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0291,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(276.4717, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 275.4528, -294.8384,   62.1071],\n",
      "        [-125.0611,   40.3071,  123.4418]])\n",
      "tensor([ 2.5928, -0.1434])\n",
      "Epoch: 52\n",
      "Loss: tensor(276.4717, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1704,  0.0522,  1.6310],\n",
      "        [-0.7503,  0.4494,  2.1369]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0291,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(274.4855, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 273.5927, -293.1632,   62.2169],\n",
      "        [-124.4211,   39.8045,  123.2686]])\n",
      "tensor([ 2.5788, -0.1395])\n",
      "Epoch: 53\n",
      "Loss: tensor(274.4855, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1732,  0.0551,  1.6304],\n",
      "        [-0.7490,  0.4490,  2.1356]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0291,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(272.5217, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 271.7437, -291.4993,   62.3249],\n",
      "        [-123.7829,   39.3080,  123.0977]])\n",
      "tensor([ 2.5650, -0.1356])\n",
      "Epoch: 54\n",
      "Loss: tensor(272.5217, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1759,  0.0580,  1.6298],\n",
      "        [-0.7478,  0.4486,  2.1344]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0291,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(270.5800, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 269.9059, -289.8467,   62.4312],\n",
      "        [-123.1488,   38.8145,  122.9270]])\n",
      "tensor([ 2.5512, -0.1318])\n",
      "Epoch: 55\n",
      "Loss: tensor(270.5800, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1786,  0.0609,  1.6292],\n",
      "        [-0.7466,  0.4483,  2.1332]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0292,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(268.6599, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 268.0795, -288.2045,   62.5362],\n",
      "        [-122.5180,   38.3249,  122.7572]])\n",
      "tensor([ 2.5376, -0.1279])\n",
      "Epoch: 56\n",
      "Loss: tensor(268.6599, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1813,  0.0638,  1.6286],\n",
      "        [-0.7453,  0.4479,  2.1319]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0292,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(266.7613, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 266.2640, -286.5735,   62.6396],\n",
      "        [-121.8907,   37.8388,  122.5880]])\n",
      "tensor([ 2.5240, -0.1241])\n",
      "Epoch: 57\n",
      "Loss: tensor(266.7613, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1839,  0.0666,  1.6279],\n",
      "        [-0.7441,  0.4475,  2.1307]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0292,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(264.8839, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 264.4594, -284.9532,   62.7414],\n",
      "        [-121.2670,   37.3566,  122.4196]])\n",
      "tensor([ 2.5104, -0.1203])\n",
      "Epoch: 58\n",
      "Loss: tensor(264.8839, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1866,  0.0695,  1.6273],\n",
      "        [-0.7429,  0.4471,  2.1295]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0292,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(263.0274, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 262.6667, -283.3427,   62.8423],\n",
      "        [-120.6461,   36.8786,  122.2523]])\n",
      "tensor([ 2.4970, -0.1165])\n",
      "Epoch: 59\n",
      "Loss: tensor(263.0274, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1892,  0.0723,  1.6267],\n",
      "        [-0.7417,  0.4468,  2.1283]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0293,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(261.1915, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 260.8849, -281.7428,   62.9418],\n",
      "        [-120.0291,   36.4038,  122.0854]])\n",
      "tensor([ 2.4836, -0.1128])\n",
      "Epoch: 60\n",
      "Loss: tensor(261.1915, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1918,  0.0751,  1.6260],\n",
      "        [-0.7405,  0.4464,  2.1271]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0293,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(259.3762, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 259.1147, -280.1527,   63.0403],\n",
      "        [-119.4153,   35.9328,  121.9195]])\n",
      "tensor([ 2.4704, -0.1091])\n",
      "Epoch: 61\n",
      "Loss: tensor(259.3762, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1944,  0.0779,  1.6254],\n",
      "        [-0.7393,  0.4460,  2.1258]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0293,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(257.5809, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 257.3550, -278.5732,   63.1372],\n",
      "        [-118.8054,   35.4649,  121.7539]])\n",
      "tensor([ 2.4572, -0.1053])\n",
      "Epoch: 62\n",
      "Loss: tensor(257.5809, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1970,  0.0807,  1.6248],\n",
      "        [-0.7381,  0.4457,  2.1246]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0293,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(255.8057, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 255.6072, -277.0033,   63.2333],\n",
      "        [-118.1998,   34.9995,  121.5884]])\n",
      "tensor([ 2.4440, -0.1017])\n",
      "Epoch: 63\n",
      "Loss: tensor(255.8057, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.1995,  0.0835,  1.6241],\n",
      "        [-0.7369,  0.4453,  2.1234]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0294,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(254.0500, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 253.8705, -275.4429,   63.3284],\n",
      "        [-117.5966,   34.5386,  121.4242]])\n",
      "tensor([ 2.4310, -0.0980])\n",
      "Epoch: 64\n",
      "Loss: tensor(254.0500, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2021,  0.0863,  1.6235],\n",
      "        [-0.7358,  0.4450,  2.1222]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0294,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(252.3138, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 252.1445, -273.8926,   63.4222],\n",
      "        [-116.9972,   34.0809,  121.2605]])\n",
      "tensor([ 2.4180, -0.0944])\n",
      "Epoch: 65\n",
      "Loss: tensor(252.3138, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2046,  0.0890,  1.6229],\n",
      "        [-0.7346,  0.4446,  2.1210]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0294,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(250.5970, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 250.4297, -272.3518,   63.5150],\n",
      "        [-116.4013,   33.6265,  121.0975]])\n",
      "tensor([ 2.4052, -0.0908])\n",
      "Epoch: 66\n",
      "Loss: tensor(250.5970, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2071,  0.0917,  1.6222],\n",
      "        [-0.7334,  0.4443,  2.1198]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0294,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(248.8988, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 248.7250, -270.8217,   63.6061],\n",
      "        [-115.8086,   33.1755,  120.9349]])\n",
      "tensor([ 2.3924, -0.0872])\n",
      "Epoch: 67\n",
      "Loss: tensor(248.8988, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2096,  0.0944,  1.6216],\n",
      "        [-0.7323,  0.4440,  2.1186]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0295,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(247.2195, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 247.0312, -269.3008,   63.6963],\n",
      "        [-115.2198,   32.7276,  120.7729]])\n",
      "tensor([ 2.3796, -0.0836])\n",
      "Epoch: 68\n",
      "Loss: tensor(247.2195, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2121,  0.0971,  1.6210],\n",
      "        [-0.7311,  0.4436,  2.1173]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0295,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(245.5586, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 245.3490, -267.7889,   63.7858],\n",
      "        [-114.6350,   32.2818,  120.6109]])\n",
      "tensor([ 2.3670, -0.0801])\n",
      "Epoch: 69\n",
      "Loss: tensor(245.5586, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2145,  0.0998,  1.6203],\n",
      "        [-0.7300,  0.4433,  2.1161]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0295,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(243.9161, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 243.6772, -266.2865,   63.8742],\n",
      "        [-114.0535,   31.8398,  120.4496]])\n",
      "tensor([ 2.3544, -0.0766])\n",
      "Epoch: 70\n",
      "Loss: tensor(243.9161, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2170,  0.1025,  1.6197],\n",
      "        [-0.7288,  0.4430,  2.1149]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0295,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(242.2915, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 242.0160, -264.7935,   63.9614],\n",
      "        [-113.4753,   31.4009,  120.2890]])\n",
      "tensor([ 2.3419, -0.0731])\n",
      "Epoch: 71\n",
      "Loss: tensor(242.2915, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2194,  0.1051,  1.6191],\n",
      "        [-0.7277,  0.4427,  2.1137]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0295,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(240.6848, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 240.3659, -263.3095,   64.0480],\n",
      "        [-112.9006,   30.9651,  120.1288]])\n",
      "tensor([ 2.3295, -0.0697])\n",
      "Epoch: 72\n",
      "Loss: tensor(240.6848, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2218,  0.1077,  1.6184],\n",
      "        [-0.7266,  0.4424,  2.1125]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0296,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(239.0957, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 238.7256, -261.8354,   64.1330],\n",
      "        [-112.3300,   30.5315,  119.9687]])\n",
      "tensor([ 2.3172, -0.0662])\n",
      "Epoch: 73\n",
      "Loss: tensor(239.0957, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2242,  0.1104,  1.6178],\n",
      "        [-0.7254,  0.4421,  2.1113]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0296,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(237.5240, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 237.0961, -260.3703,   64.2172],\n",
      "        [-111.7626,   30.1013,  119.8092]])\n",
      "tensor([ 2.3049, -0.0628])\n",
      "Epoch: 74\n",
      "Loss: tensor(237.5240, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2265,  0.1130,  1.6171],\n",
      "        [-0.7243,  0.4418,  2.1101]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0296,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(235.9693, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 235.4771, -258.9141,   64.3005],\n",
      "        [-111.1981,   29.6745,  119.6505]])\n",
      "tensor([ 2.2927, -0.0594])\n",
      "Epoch: 75\n",
      "Loss: tensor(235.9693, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2289,  0.1156,  1.6165],\n",
      "        [-0.7232,  0.4415,  2.1089]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0296,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(234.4316, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 233.8681, -257.4673,   64.3826],\n",
      "        [-110.6379,   29.2499,  119.4918]])\n",
      "tensor([ 2.2806, -0.0561])\n",
      "Epoch: 76\n",
      "Loss: tensor(234.4316, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2312,  0.1181,  1.6158],\n",
      "        [-0.7221,  0.4412,  2.1077]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0297,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(232.9106, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 232.2695, -256.0294,   64.4637],\n",
      "        [-110.0808,   28.8284,  119.3335]])\n",
      "tensor([ 2.2685, -0.0527])\n",
      "Epoch: 77\n",
      "Loss: tensor(232.9106, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2336,  0.1207,  1.6152],\n",
      "        [-0.7210,  0.4409,  2.1065]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0297,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(231.4063, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 230.6815, -254.6001,   64.5442],\n",
      "        [-109.5267,   28.4106,  119.1762]])\n",
      "tensor([ 2.2566, -0.0494])\n",
      "Epoch: 78\n",
      "Loss: tensor(231.4063, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2359,  0.1232,  1.6146],\n",
      "        [-0.7199,  0.4406,  2.1054]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0297,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(229.9182, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 229.1036, -253.1797,   64.6235],\n",
      "        [-108.9762,   27.9950,  119.0191]])\n",
      "tensor([ 2.2447, -0.0461])\n",
      "Epoch: 79\n",
      "Loss: tensor(229.9182, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2381,  0.1258,  1.6139],\n",
      "        [-0.7188,  0.4403,  2.1042]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0297,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(228.4462, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 227.5355, -251.7683,   64.7018],\n",
      "        [-108.4293,   27.5821,  118.8622]])\n",
      "tensor([ 2.2329, -0.0429])\n",
      "Epoch: 80\n",
      "Loss: tensor(228.4462, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2404,  0.1283,  1.6133],\n",
      "        [-0.7177,  0.4401,  2.1030]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0298,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(226.9902, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 225.9774, -250.3660,   64.7791],\n",
      "        [-107.8852,   27.1725,  118.7061]])\n",
      "tensor([ 2.2211, -0.0396])\n",
      "Epoch: 81\n",
      "Loss: tensor(226.9902, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2427,  0.1308,  1.6126],\n",
      "        [-0.7167,  0.4398,  2.1018]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0298,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(225.5499, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 224.4294, -248.9721,   64.8554],\n",
      "        [-107.3453,   26.7649,  118.5498]])\n",
      "tensor([ 2.2094, -0.0364])\n",
      "Epoch: 82\n",
      "Loss: tensor(225.5499, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2449,  0.1333,  1.6120],\n",
      "        [-0.7156,  0.4395,  2.1006]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0298,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(224.1252, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 222.8917, -247.5866,   64.9311],\n",
      "        [-106.8074,   26.3613,  118.3948]])\n",
      "tensor([ 2.1978, -0.0332])\n",
      "Epoch: 83\n",
      "Loss: tensor(224.1252, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2472,  0.1358,  1.6113],\n",
      "        [-0.7145,  0.4393,  2.0994]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0298,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(222.7158, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 221.3636, -246.2097,   65.0057],\n",
      "        [-106.2736,   25.9598,  118.2398]])\n",
      "tensor([ 2.1863, -0.0300])\n",
      "Epoch: 84\n",
      "Loss: tensor(222.7158, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2494,  0.1382,  1.6107],\n",
      "        [-0.7135,  0.4390,  2.0982]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0298,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(221.3216, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 219.8452, -244.8415,   65.0794],\n",
      "        [-105.7424,   25.5615,  118.0856]])\n",
      "tensor([ 2.1749, -0.0269])\n",
      "Epoch: 85\n",
      "Loss: tensor(221.3216, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2516,  0.1407,  1.6100],\n",
      "        [-0.7124,  0.4387,  2.0971]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0299,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(219.9422, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 218.3368, -243.4814,   65.1524],\n",
      "        [-105.2151,   25.1654,  117.9313]])\n",
      "tensor([ 2.1635, -0.0238])\n",
      "Epoch: 86\n",
      "Loss: tensor(219.9422, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2538,  0.1431,  1.6094],\n",
      "        [-0.7113,  0.4385,  2.0959]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0299,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(218.5779, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 216.8379, -242.1302,   65.2242],\n",
      "        [-104.6904,   24.7729,  117.7779]])\n",
      "tensor([ 2.1522, -0.0206])\n",
      "Epoch: 87\n",
      "Loss: tensor(218.5779, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2559,  0.1455,  1.6087],\n",
      "        [-0.7103,  0.4382,  2.0947]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0299,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(217.2280, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 215.3485, -240.7873,   65.2952],\n",
      "        [-104.1694,   24.3823,  117.6246]])\n",
      "tensor([ 2.1409, -0.0176])\n",
      "Epoch: 88\n",
      "Loss: tensor(217.2280, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2581,  0.1479,  1.6081],\n",
      "        [-0.7093,  0.4380,  2.0935]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0299,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(215.8925, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 213.8686, -239.4529,   65.3652],\n",
      "        [-103.6519,   23.9940,  117.4714]])\n",
      "tensor([ 2.1297, -0.0145])\n",
      "Epoch: 89\n",
      "Loss: tensor(215.8925, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2602,  0.1503,  1.6074],\n",
      "        [-0.7082,  0.4378,  2.0923]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0300,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(214.5714, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 212.3985, -238.1264,   65.4344],\n",
      "        [-103.1373,   23.6089,  117.3189]])\n",
      "tensor([ 2.1186, -0.0115])\n",
      "Epoch: 90\n",
      "Loss: tensor(214.5714, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2623,  0.1527,  1.6068],\n",
      "        [-0.7072,  0.4375,  2.0912]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0300,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(213.2642, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 210.9375, -236.8083,   65.5027],\n",
      "        [-102.6257,   23.2263,  117.1669]])\n",
      "tensor([ 2.1076, -0.0085])\n",
      "Epoch: 91\n",
      "Loss: tensor(213.2642, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2644,  0.1551,  1.6061],\n",
      "        [-0.7062,  0.4373,  2.0900]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0300,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(211.9710, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 209.4858, -235.4986,   65.5700],\n",
      "        [-102.1165,   22.8470,  117.0156]])\n",
      "tensor([ 2.0966, -0.0054])\n",
      "Epoch: 92\n",
      "Loss: tensor(211.9710, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2665,  0.1574,  1.6054],\n",
      "        [-0.7051,  0.4371,  2.0888]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0300,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(210.6915, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 208.0431, -234.1973,   65.6361],\n",
      "        [-101.6114,   22.4695,  116.8642]])\n",
      "tensor([ 2.0857, -0.0025])\n",
      "Epoch: 93\n",
      "Loss: tensor(210.6915, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2686,  0.1598,  1.6048],\n",
      "        [-0.7041,  0.4368,  2.0877]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0300,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(209.4256, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 206.6102, -232.9035,   65.7018],\n",
      "        [-101.1095,   22.0944,  116.7130]])\n",
      "tensor([2.0748e+00, 4.7088e-04])\n",
      "Epoch: 94\n",
      "Loss: tensor(209.4256, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2707,  0.1621,  1.6041],\n",
      "        [-0.7031,  0.4366,  2.0865]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0301,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(208.1730, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 205.1866, -231.6174,   65.7667],\n",
      "        [-100.6100,   21.7227,  116.5628]])\n",
      "tensor([2.0641, 0.0034])\n",
      "Epoch: 95\n",
      "Loss: tensor(208.1730, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2727,  0.1644,  1.6035],\n",
      "        [-0.7021,  0.4364,  2.0853]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0301,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(206.9338, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 203.7719, -230.3398,   65.8305],\n",
      "        [-100.1136,   21.3535,  116.4129]])\n",
      "tensor([2.0534, 0.0063])\n",
      "Epoch: 96\n",
      "Loss: tensor(206.9338, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2748,  0.1667,  1.6028],\n",
      "        [-0.7011,  0.4362,  2.0842]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0301,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(205.7076, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 202.3661, -229.0702,   65.8935],\n",
      "        [ -99.6211,   20.9857,  116.2627]])\n",
      "tensor([2.0427, 0.0092])\n",
      "Epoch: 97\n",
      "Loss: tensor(205.7076, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2768,  0.1690,  1.6022],\n",
      "        [-0.7001,  0.4360,  2.0830]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0301,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(204.4942, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 200.9688, -227.8089,   65.9552],\n",
      "        [ -99.1300,   20.6222,  116.1141]])\n",
      "tensor([2.0321, 0.0121])\n",
      "Epoch: 98\n",
      "Loss: tensor(204.4942, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2788,  0.1713,  1.6015],\n",
      "        [-0.6991,  0.4358,  2.0818]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0301,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(203.2937, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 199.5813, -226.5546,   66.0168],\n",
      "        [ -98.6428,   20.2605,  115.9653]])\n",
      "tensor([2.0216, 0.0149])\n",
      "Epoch: 99\n",
      "Loss: tensor(203.2937, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2808,  0.1736,  1.6008],\n",
      "        [-0.6981,  0.4356,  2.0807]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0302,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(202.1057, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 198.2022, -225.3086,   66.0770],\n",
      "        [ -98.1583,   19.9012,  115.8170]])\n",
      "tensor([2.0112, 0.0178])\n",
      "Epoch: 100\n",
      "Loss: tensor(202.1057, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2828,  0.1758,  1.6002],\n",
      "        [-0.6972,  0.4354,  2.0795]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0302,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(200.9301, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 196.8327, -224.0695,   66.1370],\n",
      "        [ -97.6776,   19.5435,  115.6684]])\n",
      "tensor([2.0008, 0.0205])\n",
      "Epoch: 101\n",
      "Loss: tensor(200.9301, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2848,  0.1780,  1.5995],\n",
      "        [-0.6962,  0.4352,  2.0784]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0302,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(199.7670, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 195.4711, -222.8390,   66.1956],\n",
      "        [ -97.1984,   19.1902,  115.5214]])\n",
      "tensor([1.9905, 0.0233])\n",
      "Epoch: 102\n",
      "Loss: tensor(199.7670, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2867,  0.1803,  1.5988],\n",
      "        [-0.6952,  0.4350,  2.0772]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0302,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(198.6158, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 194.1185, -221.6160,   66.2535],\n",
      "        [ -96.7224,   18.8386,  115.3743]])\n",
      "tensor([1.9802, 0.0261])\n",
      "Epoch: 103\n",
      "Loss: tensor(198.6158, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2887,  0.1825,  1.5982],\n",
      "        [-0.6942,  0.4348,  2.0761]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0302,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(197.4766, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 192.7749, -220.3998,   66.3108],\n",
      "        [ -96.2499,   18.4890,  115.2274]])\n",
      "tensor([1.9700, 0.0289])\n",
      "Epoch: 104\n",
      "Loss: tensor(197.4766, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2906,  0.1847,  1.5975],\n",
      "        [-0.6933,  0.4346,  2.0749]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0303,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(196.3493, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 191.4392, -219.1922,   66.3669],\n",
      "        [ -95.7799,   18.1421,  115.0809]])\n",
      "tensor([1.9599, 0.0316])\n",
      "Epoch: 105\n",
      "Loss: tensor(196.3493, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2925,  0.1869,  1.5969],\n",
      "        [-0.6923,  0.4344,  2.0738]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0303,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(195.2337, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 190.1133, -217.9908,   66.4229],\n",
      "        [ -95.3133,   17.7971,  114.9346]])\n",
      "tensor([1.9498, 0.0343])\n",
      "Epoch: 106\n",
      "Loss: tensor(195.2337, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2944,  0.1891,  1.5962],\n",
      "        [-0.6914,  0.4342,  2.0726]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0303,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(194.1297, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 188.7950, -216.7976,   66.4776],\n",
      "        [ -94.8498,   17.4542,  114.7885]])\n",
      "tensor([1.9398, 0.0370])\n",
      "Epoch: 107\n",
      "Loss: tensor(194.1297, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2963,  0.1912,  1.5955],\n",
      "        [-0.6904,  0.4341,  2.0715]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0303,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(193.0372, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 187.4851, -215.6121,   66.5314],\n",
      "        [ -94.3886,   17.1144,  114.6431]])\n",
      "tensor([1.9298, 0.0396])\n",
      "Epoch: 108\n",
      "Loss: tensor(193.0372, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.2982,  0.1934,  1.5949],\n",
      "        [-0.6895,  0.4339,  2.0703]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0303,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(191.9558, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 186.1842, -214.4330,   66.5849],\n",
      "        [ -93.9294,   16.7773,  114.4985]])\n",
      "tensor([1.9200, 0.0423])\n",
      "Epoch: 109\n",
      "Loss: tensor(191.9558, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3000,  0.1955,  1.5942],\n",
      "        [-0.6885,  0.4337,  2.0692]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0304,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(190.8856, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 184.8910, -213.2622,   66.6370],\n",
      "        [ -93.4729,   16.4431,  114.3544]])\n",
      "tensor([1.9101, 0.0449])\n",
      "Epoch: 110\n",
      "Loss: tensor(190.8856, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3019,  0.1977,  1.5935],\n",
      "        [-0.6876,  0.4336,  2.0680]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0304,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(189.8264, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 183.6066, -212.0977,   66.6889],\n",
      "        [ -93.0201,   16.1101,  114.2101]])\n",
      "tensor([1.9004, 0.0475])\n",
      "Epoch: 111\n",
      "Loss: tensor(189.8264, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3037,  0.1998,  1.5929],\n",
      "        [-0.6867,  0.4334,  2.0669]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0304,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(188.7781, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 182.3302, -210.9411,   66.7398],\n",
      "        [ -92.5695,   15.7800,  114.0664]])\n",
      "tensor([1.8907, 0.0501])\n",
      "Epoch: 112\n",
      "Loss: tensor(188.7781, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3055,  0.2019,  1.5922],\n",
      "        [-0.6857,  0.4332,  2.0657]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0304,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(187.7405, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 181.0620, -209.7914,   66.7899],\n",
      "        [ -92.1217,   15.4521,  113.9232]])\n",
      "tensor([1.8810, 0.0527])\n",
      "Epoch: 113\n",
      "Loss: tensor(187.7405, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3073,  0.2040,  1.5915],\n",
      "        [-0.6848,  0.4331,  2.0646]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0304,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(186.7135, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 179.8017, -208.6491,   66.8391],\n",
      "        [ -91.6776,   15.1254,  113.7795]])\n",
      "tensor([1.8714, 0.0552])\n",
      "Epoch: 114\n",
      "Loss: tensor(186.7135, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3091,  0.2061,  1.5909],\n",
      "        [-0.6839,  0.4329,  2.0635]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0304,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(185.6969, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 178.5501, -207.5132,   66.8879],\n",
      "        [ -91.2350,   14.8023,  113.6370]])\n",
      "tensor([1.8619, 0.0578])\n",
      "Epoch: 115\n",
      "Loss: tensor(185.6969, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3109,  0.2082,  1.5902],\n",
      "        [-0.6830,  0.4328,  2.0623]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0305,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(184.6908, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 177.3065, -206.3843,   66.9360],\n",
      "        [ -90.7952,   14.4813,  113.4949]])\n",
      "tensor([1.8524, 0.0603])\n",
      "Epoch: 116\n",
      "Loss: tensor(184.6908, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3127,  0.2102,  1.5895],\n",
      "        [-0.6821,  0.4326,  2.0612]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0305,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(183.6948, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 176.0704, -205.2629,   66.9830],\n",
      "        [ -90.3578,   14.1629,  113.3533]])\n",
      "tensor([1.8430, 0.0628])\n",
      "Epoch: 117\n",
      "Loss: tensor(183.6948, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3145,  0.2123,  1.5889],\n",
      "        [-0.6812,  0.4325,  2.0601]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0305,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(182.7089, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 174.8427, -204.1481,   67.0295],\n",
      "        [ -89.9233,   13.8463,  113.2118]])\n",
      "tensor([1.8336, 0.0653])\n",
      "Epoch: 118\n",
      "Loss: tensor(182.7089, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3162,  0.2143,  1.5882],\n",
      "        [-0.6803,  0.4324,  2.0589]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0305,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(181.7331, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 173.6225, -203.0405,   67.0752],\n",
      "        [ -89.4915,   13.5317,  113.0707]])\n",
      "tensor([1.8244, 0.0677])\n",
      "Epoch: 119\n",
      "Loss: tensor(181.7331, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3179,  0.2163,  1.5875],\n",
      "        [-0.6794,  0.4322,  2.0578]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0305,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(180.7669, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 172.4100, -201.9398,   67.1199],\n",
      "        [ -89.0635,   13.2184,  112.9291]])\n",
      "tensor([1.8151, 0.0702])\n",
      "Epoch: 120\n",
      "Loss: tensor(180.7669, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3197,  0.2184,  1.5868],\n",
      "        [-0.6785,  0.4321,  2.0567]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0306,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(179.8106, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 171.2060, -200.8452,   67.1645],\n",
      "        [ -88.6377,   12.9077,  112.7881]])\n",
      "tensor([1.8059, 0.0726])\n",
      "Epoch: 121\n",
      "Loss: tensor(179.8106, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3214,  0.2204,  1.5862],\n",
      "        [-0.6776,  0.4320,  2.0555]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0306,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(178.8639, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 170.0091, -199.7581,   67.2078],\n",
      "        [ -88.2144,   12.5990,  112.6476]])\n",
      "tensor([1.7968, 0.0750])\n",
      "Epoch: 122\n",
      "Loss: tensor(178.8639, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3231,  0.2224,  1.5855],\n",
      "        [-0.6767,  0.4318,  2.0544]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0306,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(177.9267, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 168.8201, -198.6775,   67.2506],\n",
      "        [ -87.7935,   12.2927,  112.5074]])\n",
      "tensor([1.7877, 0.0774])\n",
      "Epoch: 123\n",
      "Loss: tensor(177.9267, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3248,  0.2244,  1.5848],\n",
      "        [-0.6758,  0.4317,  2.0533]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0306,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(176.9989, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 167.6383, -197.6039,   67.2925],\n",
      "        [ -87.3748,   11.9890,  112.3680]])\n",
      "tensor([1.7787, 0.0797])\n",
      "Epoch: 124\n",
      "Loss: tensor(176.9989, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3264,  0.2263,  1.5842],\n",
      "        [-0.6750,  0.4316,  2.0522]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0306,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(176.0804, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 166.4645, -196.5365,   67.3339],\n",
      "        [ -86.9593,   11.6867,  112.2284]])\n",
      "tensor([1.7697, 0.0821])\n",
      "Epoch: 125\n",
      "Loss: tensor(176.0804, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3281,  0.2283,  1.5835],\n",
      "        [-0.6741,  0.4315,  2.0510]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0306,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(175.1710, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 165.2988, -195.4753,   67.3750],\n",
      "        [ -86.5449,   11.3881,  112.0900]])\n",
      "tensor([1.7608, 0.0844])\n",
      "Epoch: 126\n",
      "Loss: tensor(175.1710, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3298,  0.2303,  1.5828],\n",
      "        [-0.6732,  0.4314,  2.0499]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0307,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(174.2706, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 164.1400, -194.4211,   67.4149],\n",
      "        [ -86.1330,   11.0912,  111.9520]])\n",
      "tensor([1.7520, 0.0867])\n",
      "Epoch: 127\n",
      "Loss: tensor(174.2706, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3314,  0.2322,  1.5821],\n",
      "        [-0.6724,  0.4313,  2.0488]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0307,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(173.3792, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 162.9882, -193.3737,   67.4539],\n",
      "        [ -85.7247,   10.7956,  111.8136]])\n",
      "tensor([1.7432, 0.0890])\n",
      "Epoch: 128\n",
      "Loss: tensor(173.3792, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3330,  0.2341,  1.5815],\n",
      "        [-0.6715,  0.4312,  2.0477]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0307,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(172.4966, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 161.8448, -192.3321,   67.4929],\n",
      "        [ -85.3188,   10.5019,  111.6755]])\n",
      "tensor([1.7344, 0.0913])\n",
      "Epoch: 129\n",
      "Loss: tensor(172.4966, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3346,  0.2361,  1.5808],\n",
      "        [-0.6707,  0.4310,  2.0466]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0307,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(171.6228, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 160.7079, -191.2975,   67.5307],\n",
      "        [ -84.9148,   10.2111,  111.5383]])\n",
      "tensor([1.7257, 0.0936])\n",
      "Epoch: 130\n",
      "Loss: tensor(171.6228, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3363,  0.2380,  1.5801],\n",
      "        [-0.6698,  0.4309,  2.0455]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0307,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(170.7574, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 159.5780, -190.2697,   67.5676],\n",
      "        [ -84.5130,    9.9224,  111.4014]])\n",
      "tensor([1.7171, 0.0958])\n",
      "Epoch: 131\n",
      "Loss: tensor(170.7574, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3379,  0.2399,  1.5794],\n",
      "        [-0.6690,  0.4308,  2.0443]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0308,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(169.9007, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 158.4561, -189.2475,   67.6042],\n",
      "        [ -84.1142,    9.6353,  111.2645]])\n",
      "tensor([1.7085, 0.0981])\n",
      "Epoch: 132\n",
      "Loss: tensor(169.9007, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3394,  0.2418,  1.5788],\n",
      "        [-0.6681,  0.4308,  2.0432]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0308,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(169.0523, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 157.3416, -188.2314,   67.6403],\n",
      "        [ -83.7180,    9.3498,  111.1278]])\n",
      "tensor([1.7000, 0.1003])\n",
      "Epoch: 133\n",
      "Loss: tensor(169.0523, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3410,  0.2436,  1.5781],\n",
      "        [-0.6673,  0.4307,  2.0421]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0308,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(168.2123, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 156.2342, -187.2215,   67.6758],\n",
      "        [ -83.3237,    9.0670,  110.9919]])\n",
      "tensor([1.6915, 0.1025])\n",
      "Epoch: 134\n",
      "Loss: tensor(168.2123, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3426,  0.2455,  1.5774],\n",
      "        [-0.6665,  0.4306,  2.0410]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0308,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(167.3804, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 155.1331, -186.2189,   67.7100],\n",
      "        [ -82.9319,    8.7858,  110.8560]])\n",
      "tensor([1.6831, 0.1047])\n",
      "Epoch: 135\n",
      "Loss: tensor(167.3804, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3441,  0.2474,  1.5767],\n",
      "        [-0.6656,  0.4305,  2.0399]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0308,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(166.5568, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 154.0398, -185.2217,   67.7440],\n",
      "        [ -82.5426,    8.5069,  110.7205]])\n",
      "tensor([1.6747, 0.1068])\n",
      "Epoch: 136\n",
      "Loss: tensor(166.5568, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3457,  0.2492,  1.5760],\n",
      "        [-0.6648,  0.4304,  2.0388]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0308,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(165.7409, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 152.9530, -184.2310,   67.7771],\n",
      "        [ -82.1554,    8.2297,  110.5854]])\n",
      "tensor([1.6663, 0.1090])\n",
      "Epoch: 137\n",
      "Loss: tensor(165.7409, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3472,  0.2511,  1.5754],\n",
      "        [-0.6640,  0.4303,  2.0377]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0309,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(164.9331, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 151.8734, -183.2462,   67.8098],\n",
      "        [ -81.7703,    7.9550,  110.4508]])\n",
      "tensor([1.6581, 0.1111])\n",
      "Epoch: 138\n",
      "Loss: tensor(164.9331, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3487,  0.2529,  1.5747],\n",
      "        [-0.6632,  0.4302,  2.0366]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0309,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(164.1331, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 150.8011, -182.2674,   67.8419],\n",
      "        [ -81.3880,    7.6818,  110.3162]])\n",
      "tensor([1.6498, 0.1132])\n",
      "Epoch: 139\n",
      "Loss: tensor(164.1331, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3502,  0.2547,  1.5740],\n",
      "        [-0.6624,  0.4302,  2.0355]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0309,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(163.3408, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 149.7356, -181.2944,   67.8734],\n",
      "        [ -81.0076,    7.4109,  110.1823]])\n",
      "tensor([1.6417, 0.1153])\n",
      "Epoch: 140\n",
      "Loss: tensor(163.3408, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3517,  0.2565,  1.5733],\n",
      "        [-0.6615,  0.4301,  2.0344]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0309,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(162.5563, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 148.6763, -180.3283,   67.9038],\n",
      "        [ -80.6294,    7.1418,  110.0487]])\n",
      "tensor([1.6335, 0.1174])\n",
      "Epoch: 141\n",
      "Loss: tensor(162.5563, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3532,  0.2583,  1.5727],\n",
      "        [-0.6607,  0.4300,  2.0333]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0309,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(161.7791, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 147.6247, -179.3672,   67.9341],\n",
      "        [ -80.2540,    6.8743,  109.9149]])\n",
      "tensor([1.6255, 0.1195])\n",
      "Epoch: 142\n",
      "Loss: tensor(161.7791, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3547,  0.2601,  1.5720],\n",
      "        [-0.6599,  0.4299,  2.0322]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0309,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(161.0094, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 146.5794, -178.4123,   67.9636],\n",
      "        [ -79.8807,    6.6087,  109.7818]])\n",
      "tensor([1.6174, 0.1216])\n",
      "Epoch: 143\n",
      "Loss: tensor(161.0094, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3561,  0.2619,  1.5713],\n",
      "        [-0.6591,  0.4299,  2.0311]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0310,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(160.2470, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 145.5410, -177.4632,   67.9926],\n",
      "        [ -79.5098,    6.3449,  109.6487]])\n",
      "tensor([1.6094, 0.1236])\n",
      "Epoch: 144\n",
      "Loss: tensor(160.2470, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3576,  0.2637,  1.5706],\n",
      "        [-0.6583,  0.4298,  2.0300]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0310,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(159.4920, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 144.5093, -176.5199,   68.0209],\n",
      "        [ -79.1404,    6.0837,  109.5165]])\n",
      "tensor([1.6015, 0.1256])\n",
      "Epoch: 145\n",
      "Loss: tensor(159.4920, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3590,  0.2655,  1.5699],\n",
      "        [-0.6575,  0.4298,  2.0289]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0310,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(158.7442, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 143.4841, -175.5826,   68.0485],\n",
      "        [ -78.7732,    5.8245,  109.3846]])\n",
      "tensor([1.5936, 0.1276])\n",
      "Epoch: 146\n",
      "Loss: tensor(158.7442, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3605,  0.2672,  1.5693],\n",
      "        [-0.6568,  0.4297,  2.0278]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0310,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(158.0034, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 142.4657, -174.6509,   68.0757],\n",
      "        [ -78.4090,    5.5660,  109.2524]])\n",
      "tensor([1.5858, 0.1296])\n",
      "Epoch: 147\n",
      "Loss: tensor(158.0034, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3619,  0.2690,  1.5686],\n",
      "        [-0.6560,  0.4296,  2.0267]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0310,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(157.2697, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 141.4532, -173.7254,   68.1019],\n",
      "        [ -78.0463,    5.3105,  109.1212]])\n",
      "tensor([1.5780, 0.1316])\n",
      "Epoch: 148\n",
      "Loss: tensor(157.2697, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3633,  0.2707,  1.5679],\n",
      "        [-0.6552,  0.4296,  2.0256]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0310,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(156.5428, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 140.4478, -172.8051,   68.1279],\n",
      "        [ -77.6859,    5.0564,  108.9900]])\n",
      "tensor([1.5703, 0.1336])\n",
      "Epoch: 149\n",
      "Loss: tensor(156.5428, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3647,  0.2724,  1.5672],\n",
      "        [-0.6544,  0.4295,  2.0245]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0310,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(155.8227, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 139.4491, -171.8905,   68.1533],\n",
      "        [ -77.3278,    4.8040,  108.8591]])\n",
      "tensor([1.5626, 0.1355])\n",
      "Epoch: 150\n",
      "Loss: tensor(155.8227, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3661,  0.2742,  1.5665],\n",
      "        [-0.6536,  0.4295,  2.0234]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0311,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(155.1095, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 138.4562, -170.9819,   68.1778],\n",
      "        [ -76.9726,    4.5526,  108.7279]])\n",
      "tensor([1.5549, 0.1374])\n",
      "Epoch: 151\n",
      "Loss: tensor(155.1095, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3675,  0.2759,  1.5658],\n",
      "        [-0.6529,  0.4294,  2.0223]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0311,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(154.4029, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 137.4701, -170.0785,   68.2020],\n",
      "        [ -76.6186,    4.3040,  108.5977]])\n",
      "tensor([1.5473, 0.1394])\n",
      "Epoch: 152\n",
      "Loss: tensor(154.4029, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3689,  0.2776,  1.5652],\n",
      "        [-0.6521,  0.4294,  2.0213]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0311,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(153.7029, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 136.4903, -169.1807,   68.2256],\n",
      "        [ -76.2675,    4.0563,  108.4673]])\n",
      "tensor([1.5398, 0.1413])\n",
      "Epoch: 153\n",
      "Loss: tensor(153.7029, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3702,  0.2793,  1.5645],\n",
      "        [-0.6513,  0.4294,  2.0202]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0311,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(153.0096, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 135.5169, -168.2882,   68.2487],\n",
      "        [ -75.9171,    3.8120,  108.3383]])\n",
      "tensor([1.5323, 0.1432])\n",
      "Epoch: 154\n",
      "Loss: tensor(153.0096, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3716,  0.2809,  1.5638],\n",
      "        [-0.6506,  0.4293,  2.0191]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0311,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(152.3225, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 134.5496, -167.4016,   68.2710],\n",
      "        [ -75.5694,    3.5688,  108.2090]])\n",
      "tensor([1.5248, 0.1450])\n",
      "Epoch: 155\n",
      "Loss: tensor(152.3225, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3729,  0.2826,  1.5631],\n",
      "        [-0.6498,  0.4293,  2.0180]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0311,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(151.6419, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 133.5887, -166.5201,   68.2930],\n",
      "        [ -75.2250,    3.3260,  108.0792]])\n",
      "tensor([1.5174, 0.1469])\n",
      "Epoch: 156\n",
      "Loss: tensor(151.6419, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3743,  0.2843,  1.5624],\n",
      "        [-0.6491,  0.4292,  2.0169]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0312,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(150.9674, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 132.6337, -165.6444,   68.3141],\n",
      "        [ -74.8812,    3.0862,  107.9506]])\n",
      "tensor([1.5100, 0.1487])\n",
      "Epoch: 157\n",
      "Loss: tensor(150.9674, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3756,  0.2859,  1.5618],\n",
      "        [-0.6483,  0.4292,  2.0158]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0312,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(150.2993, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 131.6848, -164.7742,   68.3347],\n",
      "        [ -74.5406,    2.8474,  107.8217]])\n",
      "tensor([1.5027, 0.1506])\n",
      "Epoch: 158\n",
      "Loss: tensor(150.2993, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3769,  0.2876,  1.5611],\n",
      "        [-0.6476,  0.4292,  2.0148]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0312,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(149.6374, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 130.7424, -163.9088,   68.3550],\n",
      "        [ -74.2006,    2.6115,  107.6939]])\n",
      "tensor([1.4954, 0.1524])\n",
      "Epoch: 159\n",
      "Loss: tensor(149.6374, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3782,  0.2892,  1.5604],\n",
      "        [-0.6468,  0.4292,  2.0137]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0312,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(148.9815, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 129.8058, -163.0490,   68.3746],\n",
      "        [ -73.8634,    2.3767,  107.5661]])\n",
      "tensor([1.4882, 0.1542])\n",
      "Epoch: 160\n",
      "Loss: tensor(148.9815, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3795,  0.2908,  1.5597],\n",
      "        [-0.6461,  0.4291,  2.0126]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0312,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(148.3315, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 128.8751, -162.1945,   68.3937],\n",
      "        [ -73.5286,    2.1430,  107.4381]])\n",
      "tensor([1.4810, 0.1560])\n",
      "Epoch: 161\n",
      "Loss: tensor(148.3315, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3808,  0.2925,  1.5590],\n",
      "        [-0.6454,  0.4291,  2.0115]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0312,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(147.6875, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 127.9506, -161.3453,   68.4121],\n",
      "        [ -73.1953,    1.9115,  107.3107]])\n",
      "tensor([1.4738, 0.1578])\n",
      "Epoch: 162\n",
      "Loss: tensor(147.6875, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3821,  0.2941,  1.5583],\n",
      "        [-0.6446,  0.4291,  2.0105]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0312,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(147.0492, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 127.0320, -160.5013,   68.4300],\n",
      "        [ -72.8646,    1.6811,  107.1833]])\n",
      "tensor([1.4667, 0.1595])\n",
      "Epoch: 163\n",
      "Loss: tensor(147.0492, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3834,  0.2957,  1.5576],\n",
      "        [-0.6439,  0.4291,  2.0094]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0313,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(146.4168, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 126.1196, -159.6620,   68.4477],\n",
      "        [ -72.5359,    1.4524,  107.0562]])\n",
      "tensor([1.4596, 0.1613])\n",
      "Epoch: 164\n",
      "Loss: tensor(146.4168, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3846,  0.2973,  1.5570],\n",
      "        [-0.6432,  0.4291,  2.0083]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0313,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(145.7901, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 125.2125, -158.8286,   68.4643],\n",
      "        [ -72.2077,    1.2268,  106.9303]])\n",
      "tensor([1.4526, 0.1630])\n",
      "Epoch: 165\n",
      "Loss: tensor(145.7901, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3859,  0.2989,  1.5563],\n",
      "        [-0.6425,  0.4291,  2.0073]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0313,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(145.1691, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 124.3118, -157.9999,   68.4808],\n",
      "        [ -71.8827,    1.0015,  106.8039]])\n",
      "tensor([1.4456, 0.1647])\n",
      "Epoch: 166\n",
      "Loss: tensor(145.1691, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3871,  0.3005,  1.5556],\n",
      "        [-0.6417,  0.4290,  2.0062]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0313,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(144.5537, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 123.4164, -157.1765,   68.4966],\n",
      "        [ -71.5596,    0.7780,  106.6778]])\n",
      "tensor([1.4387, 0.1664])\n",
      "Epoch: 167\n",
      "Loss: tensor(144.5537, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3884,  0.3020,  1.5549],\n",
      "        [-0.6410,  0.4290,  2.0051]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0313,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(143.9438, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 122.5269, -156.3583,   68.5117],\n",
      "        [ -71.2377,    0.5567,  106.5525]])\n",
      "tensor([1.4318, 0.1681])\n",
      "Epoch: 168\n",
      "Loss: tensor(143.9438, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3896,  0.3036,  1.5542],\n",
      "        [-0.6403,  0.4290,  2.0041]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0313,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(143.3392, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 121.6435, -155.5447,   68.5266],\n",
      "        [ -70.9182,    0.3367,  106.4271]])\n",
      "tensor([1.4249, 0.1698])\n",
      "Epoch: 169\n",
      "Loss: tensor(143.3392, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3908,  0.3051,  1.5535],\n",
      "        [-0.6396,  0.4290,  2.0030]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0313,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(142.7401, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 1.2077e+02, -1.5474e+02,  6.8541e+01],\n",
      "        [-7.0601e+01,  1.1761e-01,  1.0630e+02]])\n",
      "tensor([1.4181, 0.1715])\n",
      "Epoch: 170\n",
      "Loss: tensor(142.7401, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3920,  0.3067,  1.5529],\n",
      "        [-0.6389,  0.4290,  2.0019]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0314,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(142.1463, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 1.1989e+02, -1.5393e+02,  6.8555e+01],\n",
      "        [-7.0285e+01, -9.9609e-02,  1.0618e+02]])\n",
      "tensor([1.4114, 0.1731])\n",
      "Epoch: 171\n",
      "Loss: tensor(142.1463, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3932,  0.3082,  1.5522],\n",
      "        [-0.6382,  0.4290,  2.0009]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0314,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(141.5578, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 119.0268, -153.1339,   68.5682],\n",
      "        [ -69.9713,   -0.3145,  106.0524]])\n",
      "tensor([1.4046, 0.1748])\n",
      "Epoch: 172\n",
      "Loss: tensor(141.5578, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3944,  0.3098,  1.5515],\n",
      "        [-0.6375,  0.4290,  1.9998]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0314,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(140.9744, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 118.1655, -152.3405,   68.5807],\n",
      "        [ -69.6592,   -0.5283,  105.9281]])\n",
      "tensor([1.3979, 0.1764])\n",
      "Epoch: 173\n",
      "Loss: tensor(140.9744, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3956,  0.3113,  1.5508],\n",
      "        [-0.6368,  0.4290,  1.9987]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0314,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(140.3962, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 117.3099, -151.5516,   68.5930],\n",
      "        [ -69.3489,   -0.7402,  105.8043]])\n",
      "tensor([1.3913, 0.1780])\n",
      "Epoch: 174\n",
      "Loss: tensor(140.3962, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3968,  0.3128,  1.5501],\n",
      "        [-0.6361,  0.4290,  1.9977]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0314,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(139.8230, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 116.4598, -150.7679,   68.6046],\n",
      "        [ -69.0406,   -0.9510,  105.6805]])\n",
      "tensor([1.3847, 0.1797])\n",
      "Epoch: 175\n",
      "Loss: tensor(139.8230, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3979,  0.3143,  1.5494],\n",
      "        [-0.6354,  0.4291,  1.9966]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0314,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(139.2549, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 115.6155, -149.9884,   68.6161],\n",
      "        [ -68.7343,   -1.1602,  105.5571]])\n",
      "tensor([1.3781, 0.1812])\n",
      "Epoch: 176\n",
      "Loss: tensor(139.2549, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.3991,  0.3158,  1.5487],\n",
      "        [-0.6347,  0.4291,  1.9956]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0314,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(138.6917, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 114.7766, -149.2137,   68.6270],\n",
      "        [ -68.4297,   -1.3680,  105.4339]])\n",
      "tensor([1.3716, 0.1828])\n",
      "Epoch: 177\n",
      "Loss: tensor(138.6917, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4002,  0.3173,  1.5481],\n",
      "        [-0.6340,  0.4291,  1.9945]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0315,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(138.1335, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 113.9429, -148.4442,   68.6373],\n",
      "        [ -68.1266,   -1.5735,  105.3112]])\n",
      "tensor([1.3651, 0.1844])\n",
      "Epoch: 178\n",
      "Loss: tensor(138.1335, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4014,  0.3188,  1.5474],\n",
      "        [-0.6334,  0.4291,  1.9935]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0315,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(137.5800, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 113.1145, -147.6793,   68.6471],\n",
      "        [ -67.8255,   -1.7782,  105.1886]])\n",
      "tensor([1.3586, 0.1860])\n",
      "Epoch: 179\n",
      "Loss: tensor(137.5800, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4025,  0.3203,  1.5467],\n",
      "        [-0.6327,  0.4291,  1.9924]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0315,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(137.0313, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 112.2913, -146.9195,   68.6561],\n",
      "        [ -67.5267,   -1.9819,  105.0658]])\n",
      "tensor([1.3522, 0.1875])\n",
      "Epoch: 180\n",
      "Loss: tensor(137.0313, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4036,  0.3217,  1.5460],\n",
      "        [-0.6320,  0.4291,  1.9914]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0315,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(136.4873, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 111.4741, -146.1633,   68.6653],\n",
      "        [ -67.2292,   -2.1833,  104.9438]])\n",
      "tensor([1.3458, 0.1890])\n",
      "Epoch: 181\n",
      "Loss: tensor(136.4873, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4047,  0.3232,  1.5453],\n",
      "        [-0.6313,  0.4292,  1.9903]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0315,  0.4668], grad_fn=<SubBackward0>)\n",
      "tensor(135.9480, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 110.6618, -145.4122,   68.6738],\n",
      "        [ -66.9334,   -2.3834,  104.8221]])\n",
      "tensor([1.3395, 0.1905])\n",
      "Epoch: 182\n",
      "Loss: tensor(135.9480, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4058,  0.3246,  1.5446],\n",
      "        [-0.6307,  0.4292,  1.9893]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0315,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(135.4134, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 109.8547, -144.6660,   68.6817],\n",
      "        [ -66.6391,   -2.5818,  104.7007]])\n",
      "tensor([1.3332, 0.1921])\n",
      "Epoch: 183\n",
      "Loss: tensor(135.4134, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4069,  0.3261,  1.5439],\n",
      "        [-0.6300,  0.4292,  1.9882]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0315,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(134.8832, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 109.0531, -143.9237,   68.6894],\n",
      "        [ -66.3469,   -2.7788,  104.5795]])\n",
      "tensor([1.3269, 0.1935])\n",
      "Epoch: 184\n",
      "Loss: tensor(134.8832, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4080,  0.3275,  1.5432],\n",
      "        [-0.6293,  0.4292,  1.9872]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0316,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(134.3577, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 108.2564, -143.1864,   68.6964],\n",
      "        [ -66.0573,   -2.9756,  104.4579]])\n",
      "tensor([1.3207, 0.1950])\n",
      "Epoch: 185\n",
      "Loss: tensor(134.3577, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4091,  0.3290,  1.5426],\n",
      "        [-0.6287,  0.4293,  1.9861]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0316,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(133.8365, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 107.4650, -142.4534,   68.7030],\n",
      "        [ -65.7684,   -3.1698,  104.3372]])\n",
      "tensor([1.3145, 0.1965])\n",
      "Epoch: 186\n",
      "Loss: tensor(133.8365, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4102,  0.3304,  1.5419],\n",
      "        [-0.6280,  0.4293,  1.9851]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0316,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(133.3198, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 106.6785, -141.7252,   68.7091],\n",
      "        [ -65.4808,   -3.3622,  104.2170]])\n",
      "tensor([1.3084, 0.1980])\n",
      "Epoch: 187\n",
      "Loss: tensor(133.3198, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4112,  0.3318,  1.5412],\n",
      "        [-0.6274,  0.4293,  1.9840]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0316,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(132.8073, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 105.8971, -141.0014,   68.7147],\n",
      "        [ -65.1953,   -3.5536,  104.0967]])\n",
      "tensor([1.3023, 0.1994])\n",
      "Epoch: 188\n",
      "Loss: tensor(132.8073, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4123,  0.3332,  1.5405],\n",
      "        [-0.6267,  0.4294,  1.9830]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0316,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(132.2992, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 105.1212, -140.2813,   68.7203],\n",
      "        [ -64.9115,   -3.7436,  103.9769]])\n",
      "tensor([1.2962, 0.2008])\n",
      "Epoch: 189\n",
      "Loss: tensor(132.2992, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4134,  0.3346,  1.5398],\n",
      "        [-0.6261,  0.4294,  1.9820]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0316,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(131.7953, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 104.3495, -139.5667,   68.7247],\n",
      "        [ -64.6297,   -3.9324,  103.8570]])\n",
      "tensor([1.2902, 0.2023])\n",
      "Epoch: 190\n",
      "Loss: tensor(131.7953, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4144,  0.3360,  1.5391],\n",
      "        [-0.6254,  0.4294,  1.9809]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0316,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(131.2957, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 103.5834, -138.8559,   68.7291],\n",
      "        [ -64.3488,   -4.1191,  103.7379]])\n",
      "tensor([1.2842, 0.2037])\n",
      "Epoch: 191\n",
      "Loss: tensor(131.2957, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4154,  0.3374,  1.5384],\n",
      "        [-0.6248,  0.4295,  1.9799]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0316,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(130.8002, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 102.8221, -138.1495,   68.7331],\n",
      "        [ -64.0706,   -4.3054,  103.6184]])\n",
      "tensor([1.2782, 0.2051])\n",
      "Epoch: 192\n",
      "Loss: tensor(130.8002, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4165,  0.3388,  1.5377],\n",
      "        [-0.6241,  0.4295,  1.9789]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0317,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(130.3088, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 102.0658, -137.4473,   68.7366],\n",
      "        [ -63.7933,   -4.4896,  103.4996]])\n",
      "tensor([1.2723, 0.2065])\n",
      "Epoch: 193\n",
      "Loss: tensor(130.3088, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4175,  0.3402,  1.5371],\n",
      "        [-0.6235,  0.4296,  1.9778]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0317,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(129.8214, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 101.3138, -136.7499,   68.7394],\n",
      "        [ -63.5183,   -4.6733,  103.3805]])\n",
      "tensor([1.2664, 0.2079])\n",
      "Epoch: 194\n",
      "Loss: tensor(129.8214, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4185,  0.3415,  1.5364],\n",
      "        [-0.6229,  0.4296,  1.9768]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0317,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(129.3380, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 100.5675, -136.0561,   68.7422],\n",
      "        [ -63.2441,   -4.8544,  103.2624]])\n",
      "tensor([1.2605, 0.2092])\n",
      "Epoch: 195\n",
      "Loss: tensor(129.3380, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4195,  0.3429,  1.5357],\n",
      "        [-0.6222,  0.4297,  1.9757]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0317,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(128.8586, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  99.8255, -135.3669,   68.7443],\n",
      "        [ -62.9718,   -5.0351,  103.1441]])\n",
      "tensor([1.2547, 0.2106])\n",
      "Epoch: 196\n",
      "Loss: tensor(128.8586, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4205,  0.3442,  1.5350],\n",
      "        [-0.6216,  0.4297,  1.9747]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0317,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(128.3831, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  99.0885, -134.6817,   68.7460],\n",
      "        [ -62.7008,   -5.2135,  103.0266]])\n",
      "tensor([1.2489, 0.2119])\n",
      "Epoch: 197\n",
      "Loss: tensor(128.3831, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4215,  0.3456,  1.5343],\n",
      "        [-0.6210,  0.4298,  1.9737]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0317,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(127.9115, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  98.3564, -134.0006,   68.7476],\n",
      "        [ -62.4321,   -5.3915,  102.9086]])\n",
      "tensor([1.2431, 0.2133])\n",
      "Epoch: 198\n",
      "Loss: tensor(127.9115, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4225,  0.3469,  1.5336],\n",
      "        [-0.6203,  0.4298,  1.9727]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0317,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(127.4437, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  97.6287, -133.3241,   68.7484],\n",
      "        [ -62.1651,   -5.5684,  102.7909]])\n",
      "tensor([1.2374, 0.2146])\n",
      "Epoch: 199\n",
      "Loss: tensor(127.4437, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4235,  0.3483,  1.5329],\n",
      "        [-0.6197,  0.4299,  1.9716]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0317,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(126.9797, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  96.9054, -132.6519,   68.7486],\n",
      "        [ -61.8996,   -5.7438,  102.6735]])\n",
      "tensor([1.2317, 0.2159])\n",
      "Epoch: 200\n",
      "Loss: tensor(126.9797, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4244,  0.3496,  1.5322],\n",
      "        [-0.6191,  0.4299,  1.9706]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0318,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(126.5194, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  96.1880, -131.9826,   68.7491],\n",
      "        [ -61.6357,   -5.9181,  102.5563]])\n",
      "tensor([1.2261, 0.2172])\n",
      "Epoch: 201\n",
      "Loss: tensor(126.5194, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4254,  0.3509,  1.5316],\n",
      "        [-0.6185,  0.4300,  1.9696]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0318,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(126.0628, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  95.4741, -131.3186,   68.7486],\n",
      "        [ -61.3726,   -6.0900,  102.4398]])\n",
      "tensor([1.2205, 0.2185])\n",
      "Epoch: 202\n",
      "Loss: tensor(126.0628, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4263,  0.3522,  1.5309],\n",
      "        [-0.6179,  0.4301,  1.9686]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0318,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(125.6098, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  94.7651, -130.6581,   68.7479],\n",
      "        [ -61.1114,   -6.2615,  102.3232]])\n",
      "tensor([1.2149, 0.2198])\n",
      "Epoch: 203\n",
      "Loss: tensor(125.6098, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4273,  0.3535,  1.5302],\n",
      "        [-0.6173,  0.4301,  1.9675]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0318,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(125.1604, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  94.0613, -130.0013,   68.7471],\n",
      "        [ -60.8512,   -6.4308,  102.2073]])\n",
      "tensor([1.2093, 0.2211])\n",
      "Epoch: 204\n",
      "Loss: tensor(125.1604, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4282,  0.3548,  1.5295],\n",
      "        [-0.6167,  0.4302,  1.9665]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0318,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(124.7147, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  93.3611, -129.3493,   68.7453],\n",
      "        [ -60.5933,   -6.5996,  102.0912]])\n",
      "tensor([1.2038, 0.2223])\n",
      "Epoch: 205\n",
      "Loss: tensor(124.7147, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4292,  0.3561,  1.5288],\n",
      "        [-0.6161,  0.4302,  1.9655]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0318,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(124.2725, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  92.6661, -128.7007,   68.7435],\n",
      "        [ -60.3367,   -6.7670,  101.9755]])\n",
      "tensor([1.1983, 0.2236])\n",
      "Epoch: 206\n",
      "Loss: tensor(124.2725, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4301,  0.3574,  1.5281],\n",
      "        [-0.6154,  0.4303,  1.9645]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0318,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(123.8337, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  91.9747, -128.0569,   68.7408],\n",
      "        [ -60.0818,   -6.9333,  101.8599]])\n",
      "tensor([1.1929, 0.2248])\n",
      "Epoch: 207\n",
      "Loss: tensor(123.8337, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4310,  0.3587,  1.5274],\n",
      "        [-0.6148,  0.4304,  1.9634]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0318,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(123.3984, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  91.2889, -127.4158,   68.7384],\n",
      "        [ -59.8286,   -7.0988,  101.7442]])\n",
      "tensor([1.1875, 0.2260])\n",
      "Epoch: 208\n",
      "Loss: tensor(123.3984, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4319,  0.3600,  1.5268],\n",
      "        [-0.6142,  0.4305,  1.9624]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0319,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(122.9665, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  90.6072, -126.7791,   68.7354],\n",
      "        [ -59.5760,   -7.2618,  101.6295]])\n",
      "tensor([1.1821, 0.2273])\n",
      "Epoch: 209\n",
      "Loss: tensor(122.9665, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4328,  0.3612,  1.5261],\n",
      "        [-0.6137,  0.4305,  1.9614]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0319,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(122.5379, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  89.9297, -126.1465,   68.7318],\n",
      "        [ -59.3255,   -7.4241,  101.5147]])\n",
      "tensor([1.1767, 0.2285])\n",
      "Epoch: 210\n",
      "Loss: tensor(122.5379, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4337,  0.3625,  1.5254],\n",
      "        [-0.6131,  0.4306,  1.9604]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0319,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(122.1127, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  89.2569, -125.5173,   68.7281],\n",
      "        [ -59.0768,   -7.5859,  101.3998]])\n",
      "tensor([1.1714, 0.2297])\n",
      "Epoch: 211\n",
      "Loss: tensor(122.1127, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4346,  0.3637,  1.5247],\n",
      "        [-0.6125,  0.4307,  1.9594]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0319,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(121.6908, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  88.5883, -124.8922,   68.7240],\n",
      "        [ -58.8291,   -7.7460,  101.2854]])\n",
      "tensor([1.1661, 0.2309])\n",
      "Epoch: 212\n",
      "Loss: tensor(121.6908, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4355,  0.3650,  1.5240],\n",
      "        [-0.6119,  0.4308,  1.9584]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0319,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(121.2721, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  87.9243, -124.2705,   68.7196],\n",
      "        [ -58.5827,   -7.9046,  101.1714]])\n",
      "tensor([1.1609, 0.2320])\n",
      "Epoch: 213\n",
      "Loss: tensor(121.2721, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4364,  0.3662,  1.5233],\n",
      "        [-0.6113,  0.4308,  1.9574]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0319,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(120.8566, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  87.2638, -123.6534,   68.7143],\n",
      "        [ -58.3378,   -8.0619,  101.0577]])\n",
      "tensor([1.1556, 0.2332])\n",
      "Epoch: 214\n",
      "Loss: tensor(120.8566, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4373,  0.3675,  1.5226],\n",
      "        [-0.6107,  0.4309,  1.9564]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0319,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(120.4442, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  86.6084, -123.0392,   68.7092],\n",
      "        [ -58.0945,   -8.2184,  100.9438]])\n",
      "tensor([1.1504, 0.2344])\n",
      "Epoch: 215\n",
      "Loss: tensor(120.4442, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4381,  0.3687,  1.5219],\n",
      "        [-0.6101,  0.4310,  1.9553]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0319,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(120.0351, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  85.9565, -122.4298,   68.7032],\n",
      "        [ -57.8526,   -8.3738,  100.8304]])\n",
      "tensor([1.1453, 0.2355])\n",
      "Epoch: 216\n",
      "Loss: tensor(120.0351, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4390,  0.3699,  1.5213],\n",
      "        [-0.6096,  0.4311,  1.9543]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0319,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(119.6291, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  85.3098, -121.8228,   68.6975],\n",
      "        [ -57.6124,   -8.5281,  100.7169]])\n",
      "tensor([1.1401, 0.2367])\n",
      "Epoch: 217\n",
      "Loss: tensor(119.6291, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4398,  0.3711,  1.5206],\n",
      "        [-0.6090,  0.4312,  1.9533]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0320,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(119.2261, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  84.6663, -121.2207,   68.6908],\n",
      "        [ -57.3728,   -8.6805,  100.6043]])\n",
      "tensor([1.1350, 0.2378])\n",
      "Epoch: 218\n",
      "Loss: tensor(119.2261, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4407,  0.3724,  1.5199],\n",
      "        [-0.6084,  0.4313,  1.9523]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0320,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(118.8261, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  84.0277, -120.6214,   68.6842],\n",
      "        [ -57.1343,   -8.8314,  100.4920]])\n",
      "tensor([1.1300, 0.2389])\n",
      "Epoch: 219\n",
      "Loss: tensor(118.8261, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4415,  0.3736,  1.5192],\n",
      "        [-0.6078,  0.4313,  1.9513]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0320,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(118.4292, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  83.3926, -120.0264,   68.6768],\n",
      "        [ -56.8985,   -8.9824,  100.3792]])\n",
      "tensor([1.1249, 0.2400])\n",
      "Epoch: 220\n",
      "Loss: tensor(118.4292, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4424,  0.3748,  1.5185],\n",
      "        [-0.6073,  0.4314,  1.9503]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0320,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(118.0352, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  82.7619, -119.4347,   68.6693],\n",
      "        [ -56.6638,   -9.1321,  100.2666]])\n",
      "tensor([1.1199, 0.2411])\n",
      "Epoch: 221\n",
      "Loss: tensor(118.0352, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4432,  0.3760,  1.5178],\n",
      "        [-0.6067,  0.4315,  1.9493]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0320,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(117.6441, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  82.1357, -118.8462,   68.6617],\n",
      "        [ -56.4298,   -9.2800,  100.1548]])\n",
      "tensor([1.1149, 0.2422])\n",
      "Epoch: 222\n",
      "Loss: tensor(117.6441, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4440,  0.3772,  1.5171],\n",
      "        [-0.6061,  0.4316,  1.9483]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0320,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(117.2559, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  81.5134, -118.2614,   68.6536],\n",
      "        [ -56.1983,   -9.4278,  100.0424]])\n",
      "tensor([1.1100, 0.2433])\n",
      "Epoch: 223\n",
      "Loss: tensor(117.2559, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4448,  0.3783,  1.5164],\n",
      "        [-0.6056,  0.4317,  1.9473]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0320,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(116.8707, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  80.8945, -117.6809,   68.6447],\n",
      "        [ -55.9670,   -9.5733,   99.9311]])\n",
      "tensor([1.1050, 0.2444])\n",
      "Epoch: 224\n",
      "Loss: tensor(116.8707, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4456,  0.3795,  1.5158],\n",
      "        [-0.6050,  0.4318,  1.9463]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0320,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(116.4882, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  80.2806, -117.1027,   68.6362],\n",
      "        [ -55.7377,   -9.7184,   99.8195]])\n",
      "tensor([1.1002, 0.2455])\n",
      "Epoch: 225\n",
      "Loss: tensor(116.4882, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4464,  0.3807,  1.5151],\n",
      "        [-0.6045,  0.4319,  1.9453]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0320,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(116.1085, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  79.6700, -116.5289,   68.6268],\n",
      "        [ -55.5095,   -9.8624,   99.7083]])\n",
      "tensor([1.0953, 0.2465])\n",
      "Epoch: 226\n",
      "Loss: tensor(116.1085, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4472,  0.3818,  1.5144],\n",
      "        [-0.6039,  0.4320,  1.9443]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0321,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(115.7317, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  79.0632, -115.9586,   68.6171],\n",
      "        [ -55.2825,  -10.0048,   99.5975]])\n",
      "tensor([1.0904, 0.2476])\n",
      "Epoch: 227\n",
      "Loss: tensor(115.7317, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4480,  0.3830,  1.5137],\n",
      "        [-0.6033,  0.4321,  1.9433]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0321,  0.4667], grad_fn=<SubBackward0>)\n",
      "tensor(115.3575, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  78.4605, -115.3917,   68.6071],\n",
      "        [ -55.0569,  -10.1464,   99.4866]])\n",
      "tensor([1.0856, 0.2486])\n",
      "Epoch: 228\n",
      "Loss: tensor(115.3575, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4488,  0.3842,  1.5130],\n",
      "        [-0.6028,  0.4322,  1.9423]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0321,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(114.9861, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  77.8621, -114.8279,   68.5970],\n",
      "        [ -54.8333,  -10.2875,   99.3757]])\n",
      "tensor([1.0809, 0.2496])\n",
      "Epoch: 229\n",
      "Loss: tensor(114.9861, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4496,  0.3853,  1.5123],\n",
      "        [-0.6022,  0.4323,  1.9413]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0321,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(114.6173, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  77.2678, -114.2672,   68.5867],\n",
      "        [ -54.6099,  -10.4264,   99.2657]])\n",
      "tensor([1.0761, 0.2507])\n",
      "Epoch: 230\n",
      "Loss: tensor(114.6173, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4504,  0.3865,  1.5116],\n",
      "        [-0.6017,  0.4324,  1.9403]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0321,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(114.2512, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  76.6768, -113.7104,   68.5758],\n",
      "        [ -54.3881,  -10.5646,   99.1556]])\n",
      "tensor([1.0714, 0.2517])\n",
      "Epoch: 231\n",
      "Loss: tensor(114.2512, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4511,  0.3876,  1.5110],\n",
      "        [-0.6012,  0.4325,  1.9393]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0321,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(113.8878, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  76.0898, -113.1569,   68.5645],\n",
      "        [ -54.1678,  -10.7019,   99.0458]])\n",
      "tensor([1.0667, 0.2527])\n",
      "Epoch: 232\n",
      "Loss: tensor(113.8878, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4519,  0.3887,  1.5103],\n",
      "        [-0.6006,  0.4326,  1.9384]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0321,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(113.5268, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  75.5063, -112.6070,   68.5529],\n",
      "        [ -53.9490,  -10.8383,   98.9359]])\n",
      "tensor([1.0620, 0.2537])\n",
      "Epoch: 233\n",
      "Loss: tensor(113.5268, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4526,  0.3898,  1.5096],\n",
      "        [-0.6001,  0.4327,  1.9374]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0321,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(113.1684, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  74.9265, -112.0606,   68.5407],\n",
      "        [ -53.7312,  -10.9735,   98.8263]])\n",
      "tensor([1.0574, 0.2547])\n",
      "Epoch: 234\n",
      "Loss: tensor(113.1684, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4534,  0.3910,  1.5089],\n",
      "        [-0.5995,  0.4328,  1.9364]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0321,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(112.8126, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  74.3507, -111.5174,   68.5284],\n",
      "        [ -53.5147,  -11.1077,   98.7170]])\n",
      "tensor([1.0528, 0.2556])\n",
      "Epoch: 235\n",
      "Loss: tensor(112.8126, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4541,  0.3921,  1.5082],\n",
      "        [-0.5990,  0.4330,  1.9354]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0322,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(112.4593, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  73.7788, -110.9771,   68.5160],\n",
      "        [ -53.2995,  -11.2406,   98.6080]])\n",
      "tensor([1.0482, 0.2566])\n",
      "Epoch: 236\n",
      "Loss: tensor(112.4593, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4549,  0.3932,  1.5075],\n",
      "        [-0.5985,  0.4331,  1.9344]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0322,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(112.1085, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  73.2103, -110.4406,   68.5029],\n",
      "        [ -53.0855,  -11.3728,   98.4991]])\n",
      "tensor([1.0436, 0.2576])\n",
      "Epoch: 237\n",
      "Loss: tensor(112.1085, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4556,  0.3943,  1.5068],\n",
      "        [-0.5979,  0.4332,  1.9334]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0322,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(111.7601, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  72.6463, -109.9061,   68.4902],\n",
      "        [ -52.8734,  -11.5045,   98.3900]])\n",
      "tensor([1.0391, 0.2585])\n",
      "Epoch: 238\n",
      "Loss: tensor(111.7601, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4563,  0.3954,  1.5062],\n",
      "        [-0.5974,  0.4333,  1.9324]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0322,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(111.4141, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  72.0853, -109.3759,   68.4766],\n",
      "        [ -52.6616,  -11.6343,   98.2817]])\n",
      "tensor([1.0346, 0.2595])\n",
      "Epoch: 239\n",
      "Loss: tensor(111.4141, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4570,  0.3965,  1.5055],\n",
      "        [-0.5969,  0.4334,  1.9315]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0322,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(111.0705, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  71.5281, -108.8486,   68.4629],\n",
      "        [ -52.4511,  -11.7629,   98.1736]])\n",
      "tensor([1.0301, 0.2604])\n",
      "Epoch: 240\n",
      "Loss: tensor(111.0705, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4578,  0.3976,  1.5048],\n",
      "        [-0.5964,  0.4335,  1.9305]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0322,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(110.7293, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  70.9746, -108.3244,   68.4490],\n",
      "        [ -52.2419,  -11.8910,   98.0656]])\n",
      "tensor([1.0257, 0.2613])\n",
      "Epoch: 241\n",
      "Loss: tensor(110.7293, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4585,  0.3987,  1.5041],\n",
      "        [-0.5958,  0.4336,  1.9295]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0322,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(110.3905, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  70.4247, -107.8035,   68.4346],\n",
      "        [ -52.0331,  -12.0169,   97.9584]])\n",
      "tensor([1.0213, 0.2623])\n",
      "Epoch: 242\n",
      "Loss: tensor(110.3905, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4592,  0.3997,  1.5034],\n",
      "        [-0.5953,  0.4338,  1.9285]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0322,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(110.0539, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  69.8782, -107.2858,   68.4198],\n",
      "        [ -51.8266,  -12.1432,   97.8507]])\n",
      "tensor([1.0169, 0.2632])\n",
      "Epoch: 243\n",
      "Loss: tensor(110.0539, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4599,  0.4008,  1.5027],\n",
      "        [-0.5948,  0.4339,  1.9275]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0322,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(109.7196, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  69.3356, -106.7708,   68.4051],\n",
      "        [ -51.6214,  -12.2686,   97.7430]])\n",
      "tensor([1.0125, 0.2641])\n",
      "Epoch: 244\n",
      "Loss: tensor(109.7196, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4606,  0.4019,  1.5021],\n",
      "        [-0.5943,  0.4340,  1.9266]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0322,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(109.3876, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  68.7961, -106.2596,   68.3897],\n",
      "        [ -51.4164,  -12.3917,   97.6363]])\n",
      "tensor([1.0081, 0.2650])\n",
      "Epoch: 245\n",
      "Loss: tensor(109.3876, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4613,  0.4029,  1.5014],\n",
      "        [-0.5938,  0.4341,  1.9256]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0323,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(109.0579, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  68.2605, -105.7509,   68.3744],\n",
      "        [ -51.2133,  -12.5148,   97.5292]])\n",
      "tensor([1.0038, 0.2659])\n",
      "Epoch: 246\n",
      "Loss: tensor(109.0579, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4619,  0.4040,  1.5007],\n",
      "        [-0.5933,  0.4343,  1.9246]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0323,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(108.7303, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  67.7281, -105.2454,   68.3585],\n",
      "        [ -51.0120,  -12.6374,   97.4220]])\n",
      "tensor([0.9995, 0.2667])\n",
      "Epoch: 247\n",
      "Loss: tensor(108.7303, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4626,  0.4051,  1.5000],\n",
      "        [-0.5927,  0.4344,  1.9236]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0323,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(108.4050, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  67.1990, -104.7435,   68.3421],\n",
      "        [ -50.8109,  -12.7582,   97.3156]])\n",
      "tensor([0.9953, 0.2676])\n",
      "Epoch: 248\n",
      "Loss: tensor(108.4050, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4633,  0.4061,  1.4993],\n",
      "        [-0.5922,  0.4345,  1.9227]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0323,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(108.0817, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  66.6738, -104.2440,   68.3259],\n",
      "        [ -50.6114,  -12.8787,   97.2090]])\n",
      "tensor([0.9910, 0.2685])\n",
      "Epoch: 249\n",
      "Loss: tensor(108.0817, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4640,  0.4071,  1.4986],\n",
      "        [-0.5917,  0.4346,  1.9217]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0323,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(107.7607, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  66.1515, -103.7480,   68.3090],\n",
      "        [ -50.4127,  -12.9976,   97.1030]])\n",
      "tensor([0.9868, 0.2693])\n",
      "Epoch: 250\n",
      "Loss: tensor(107.7607, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4646,  0.4082,  1.4980],\n",
      "        [-0.5912,  0.4348,  1.9207]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0323,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(107.4418, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  65.6331, -103.2544,   68.2922],\n",
      "        [ -50.2158,  -13.1164,   96.9967]])\n",
      "tensor([0.9826, 0.2702])\n",
      "Epoch: 251\n",
      "Loss: tensor(107.4418, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4653,  0.4092,  1.4973],\n",
      "        [-0.5907,  0.4349,  1.9197]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0323,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(107.1248, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  65.1172, -102.7648,   68.2745],\n",
      "        [ -50.0199,  -13.2340,   96.8905]])\n",
      "tensor([0.9784, 0.2710])\n",
      "Epoch: 252\n",
      "Loss: tensor(107.1248, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4659,  0.4102,  1.4966],\n",
      "        [-0.5902,  0.4350,  1.9188]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0323,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(106.8101, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  64.6057, -102.2770,   68.2572],\n",
      "        [ -49.8251,  -13.3507,   96.7848]])\n",
      "tensor([0.9743, 0.2719])\n",
      "Epoch: 253\n",
      "Loss: tensor(106.8101, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4666,  0.4113,  1.4959],\n",
      "        [-0.5897,  0.4352,  1.9178]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0323,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(106.4974, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  64.0970, -101.7929,   68.2392],\n",
      "        [ -49.6310,  -13.4662,   96.6794]])\n",
      "tensor([0.9702, 0.2727])\n",
      "Epoch: 254\n",
      "Loss: tensor(106.4974, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4672,  0.4123,  1.4952],\n",
      "        [-0.5892,  0.4353,  1.9168]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0323,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(106.1868, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  63.5920, -101.3112,   68.2213],\n",
      "        [ -49.4379,  -13.5803,   96.5744]])\n",
      "tensor([0.9661, 0.2735])\n",
      "Epoch: 255\n",
      "Loss: tensor(106.1868, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4678,  0.4133,  1.4945],\n",
      "        [-0.5887,  0.4354,  1.9159]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0324,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(105.8782, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  63.0899, -100.8327,   68.2028],\n",
      "        [ -49.2465,  -13.6943,   96.4692]])\n",
      "tensor([0.9620, 0.2743])\n",
      "Epoch: 256\n",
      "Loss: tensor(105.8782, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4685,  0.4143,  1.4939],\n",
      "        [-0.5882,  0.4356,  1.9149]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0324,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(105.5714, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  62.5917, -100.3565,   68.1845],\n",
      "        [ -49.0558,  -13.8069,   96.3643]])\n",
      "tensor([0.9580, 0.2751])\n",
      "Epoch: 257\n",
      "Loss: tensor(105.5714, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4691,  0.4153,  1.4932],\n",
      "        [-0.5878,  0.4357,  1.9139]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0324,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(105.2666, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 62.0962, -99.8836,  68.1656],\n",
      "        [-48.8665, -13.9190,  96.2595]])\n",
      "tensor([0.9539, 0.2759])\n",
      "Epoch: 258\n",
      "Loss: tensor(105.2666, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4697,  0.4163,  1.4925],\n",
      "        [-0.5873,  0.4359,  1.9130]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0324,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(104.9639, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 61.6039, -99.4138,  68.1463],\n",
      "        [-48.6784, -14.0303,  96.1548]])\n",
      "tensor([0.9499, 0.2767])\n",
      "Epoch: 259\n",
      "Loss: tensor(104.9639, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4703,  0.4173,  1.4918],\n",
      "        [-0.5868,  0.4360,  1.9120]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0324,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(104.6630, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 61.1146, -98.9471,  68.1266],\n",
      "        [-48.4908, -14.1401,  96.0507]])\n",
      "tensor([0.9460, 0.2775])\n",
      "Epoch: 260\n",
      "Loss: tensor(104.6630, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4710,  0.4183,  1.4911],\n",
      "        [-0.5863,  0.4361,  1.9111]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0324,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(104.3640, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 60.6291, -98.4821,  68.1071],\n",
      "        [-48.3047, -14.2496,  95.9464]])\n",
      "tensor([0.9420, 0.2783])\n",
      "Epoch: 261\n",
      "Loss: tensor(104.3640, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4716,  0.4193,  1.4904],\n",
      "        [-0.5858,  0.4363,  1.9101]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0324,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(104.0669, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 60.1465, -98.0205,  68.0872],\n",
      "        [-48.1195, -14.3578,  95.8425]])\n",
      "tensor([0.9381, 0.2790])\n",
      "Epoch: 262\n",
      "Loss: tensor(104.0669, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4722,  0.4203,  1.4898],\n",
      "        [-0.5853,  0.4364,  1.9091]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0324,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(103.7716, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 59.6665, -97.5623,  68.0666],\n",
      "        [-47.9352, -14.4651,  95.7388]])\n",
      "tensor([0.9342, 0.2798])\n",
      "Epoch: 263\n",
      "Loss: tensor(103.7716, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4728,  0.4212,  1.4891],\n",
      "        [-0.5848,  0.4366,  1.9082]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0324,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(103.4782, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 59.1900, -97.1064,  68.0460],\n",
      "        [-47.7523, -14.5719,  95.6352]])\n",
      "tensor([0.9303, 0.2805])\n",
      "Epoch: 264\n",
      "Loss: tensor(103.4782, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4733,  0.4222,  1.4884],\n",
      "        [-0.5844,  0.4367,  1.9072]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0324,  0.4666], grad_fn=<SubBackward0>)\n",
      "tensor(103.1867, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 58.7172, -96.6525,  68.0257],\n",
      "        [-47.5696, -14.6767,  95.5324]])\n",
      "tensor([0.9264, 0.2813])\n",
      "Epoch: 265\n",
      "Loss: tensor(103.1867, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4739,  0.4232,  1.4877],\n",
      "        [-0.5839,  0.4369,  1.9063]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0324,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(102.8969, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 58.2476, -96.2013,  68.0050],\n",
      "        [-47.3885, -14.7816,  95.4292]])\n",
      "tensor([0.9226, 0.2820])\n",
      "Epoch: 266\n",
      "Loss: tensor(102.8969, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4745,  0.4241,  1.4870],\n",
      "        [-0.5834,  0.4370,  1.9053]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0325,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(102.6090, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 57.7803, -95.7536,  67.9837],\n",
      "        [-47.2089, -14.8860,  95.3260]])\n",
      "tensor([0.9188, 0.2828])\n",
      "Epoch: 267\n",
      "Loss: tensor(102.6090, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4751,  0.4251,  1.4864],\n",
      "        [-0.5829,  0.4372,  1.9044]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0325,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(102.3226, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 57.3159, -95.3088,  67.9618],\n",
      "        [-47.0302, -14.9897,  95.2229]])\n",
      "tensor([0.9150, 0.2835])\n",
      "Epoch: 268\n",
      "Loss: tensor(102.3226, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4757,  0.4260,  1.4857],\n",
      "        [-0.5825,  0.4373,  1.9034]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0325,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(102.0382, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 56.8551, -94.8661,  67.9402],\n",
      "        [-46.8526, -15.0921,  95.1202]])\n",
      "tensor([0.9112, 0.2842])\n",
      "Epoch: 269\n",
      "Loss: tensor(102.0382, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4762,  0.4270,  1.4850],\n",
      "        [-0.5820,  0.4375,  1.9025]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0325,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(101.7554, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 56.3976, -94.4257,  67.9187],\n",
      "        [-46.6751, -15.1930,  95.0181]])\n",
      "tensor([0.9075, 0.2849])\n",
      "Epoch: 270\n",
      "Loss: tensor(101.7554, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4768,  0.4279,  1.4843],\n",
      "        [-0.5815,  0.4376,  1.9015]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0325,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(101.4744, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 55.9427, -93.9883,  67.8965],\n",
      "        [-46.4991, -15.2935,  94.9160]])\n",
      "tensor([0.9037, 0.2856])\n",
      "Epoch: 271\n",
      "Loss: tensor(101.4744, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4774,  0.4289,  1.4837],\n",
      "        [-0.5811,  0.4378,  1.9006]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0325,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(101.1950, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 55.4904, -93.5539,  67.8739],\n",
      "        [-46.3245, -15.3936,  94.8137]])\n",
      "tensor([0.9000, 0.2863])\n",
      "Epoch: 272\n",
      "Loss: tensor(101.1950, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4779,  0.4298,  1.4830],\n",
      "        [-0.5806,  0.4379,  1.8996]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0325,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(100.9173, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 55.0412, -93.1221,  67.8510],\n",
      "        [-46.1506, -15.4927,  94.7118]])\n",
      "tensor([0.8963, 0.2870])\n",
      "Epoch: 273\n",
      "Loss: tensor(100.9173, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4785,  0.4307,  1.4823],\n",
      "        [-0.5802,  0.4381,  1.8987]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0325,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(100.6412, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 54.5949, -92.6928,  67.8280],\n",
      "        [-45.9776, -15.5910,  94.6101]])\n",
      "tensor([0.8927, 0.2877])\n",
      "Epoch: 274\n",
      "Loss: tensor(100.6412, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4790,  0.4317,  1.4816],\n",
      "        [-0.5797,  0.4382,  1.8977]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0325,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(100.3668, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 54.1517, -92.2658,  67.8049],\n",
      "        [-45.8056, -15.6883,  94.5086]])\n",
      "tensor([0.8890, 0.2884])\n",
      "Epoch: 275\n",
      "Loss: tensor(100.3668, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4796,  0.4326,  1.4809],\n",
      "        [-0.5792,  0.4384,  1.8968]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0325,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(100.0940, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 53.7117, -91.8411,  67.7817],\n",
      "        [-45.6347, -15.7850,  94.4072]])\n",
      "tensor([0.8854, 0.2891])\n",
      "Epoch: 276\n",
      "Loss: tensor(100.0940, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4801,  0.4335,  1.4803],\n",
      "        [-0.5788,  0.4385,  1.8958]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0325,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(99.8229, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 53.2741, -91.4196,  67.7580],\n",
      "        [-45.4644, -15.8804,  94.3063]])\n",
      "tensor([0.8818, 0.2897])\n",
      "Epoch: 277\n",
      "Loss: tensor(99.8229, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4806,  0.4344,  1.4796],\n",
      "        [-0.5783,  0.4387,  1.8949]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0326,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(99.5532, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 52.8396, -91.0002,  67.7342],\n",
      "        [-45.2946, -15.9746,  94.2058]])\n",
      "tensor([0.8782, 0.2904])\n",
      "Epoch: 278\n",
      "Loss: tensor(99.5532, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4812,  0.4353,  1.4789],\n",
      "        [-0.5779,  0.4389,  1.8939]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0326,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(99.2851, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 52.4076, -90.5836,  67.7099],\n",
      "        [-45.1272, -16.0696,  94.1045]])\n",
      "tensor([0.8747, 0.2911])\n",
      "Epoch: 279\n",
      "Loss: tensor(99.2851, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4817,  0.4362,  1.4782],\n",
      "        [-0.5774,  0.4390,  1.8930]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0326,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(99.0187, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 51.9789, -90.1692,  67.6858],\n",
      "        [-44.9606, -16.1637,  94.0035]])\n",
      "tensor([0.8711, 0.2917])\n",
      "Epoch: 280\n",
      "Loss: tensor(99.0187, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4822,  0.4371,  1.4775],\n",
      "        [-0.5770,  0.4392,  1.8921]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0326,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(98.7537, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 51.5531, -89.7570,  67.6614],\n",
      "        [-44.7942, -16.2559,  93.9032]])\n",
      "tensor([0.8676, 0.2923])\n",
      "Epoch: 281\n",
      "Loss: tensor(98.7537, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4827,  0.4380,  1.4769],\n",
      "        [-0.5765,  0.4393,  1.8911]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0326,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(98.4903, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 51.1295, -89.3481,  67.6365],\n",
      "        [-44.6292, -16.3480,  93.8029]])\n",
      "tensor([0.8641, 0.2930])\n",
      "Epoch: 282\n",
      "Loss: tensor(98.4903, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4832,  0.4389,  1.4762],\n",
      "        [-0.5761,  0.4395,  1.8902]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0326,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(98.2284, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 50.7091, -88.9410,  67.6116],\n",
      "        [-44.4645, -16.4388,  93.7030]])\n",
      "tensor([0.8606, 0.2936])\n",
      "Epoch: 283\n",
      "Loss: tensor(98.2284, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4837,  0.4398,  1.4755],\n",
      "        [-0.5756,  0.4397,  1.8893]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0326,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(97.9679, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 50.2912, -88.5367,  67.5863],\n",
      "        [-44.3012, -16.5294,  93.6029]])\n",
      "tensor([0.8572, 0.2942])\n",
      "Epoch: 284\n",
      "Loss: tensor(97.9679, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4842,  0.4407,  1.4748],\n",
      "        [-0.5752,  0.4398,  1.8883]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0326,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(97.7089, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 49.8763, -88.1344,  67.5610],\n",
      "        [-44.1390, -16.6193,  93.5030]])\n",
      "tensor([0.8538, 0.2948])\n",
      "Epoch: 285\n",
      "Loss: tensor(97.7089, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4847,  0.4416,  1.4742],\n",
      "        [-0.5747,  0.4400,  1.8874]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0326,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(97.4514, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 49.4637, -87.7351,  67.5352],\n",
      "        [-43.9774, -16.7082,  93.4034]])\n",
      "tensor([0.8503, 0.2954])\n",
      "Epoch: 286\n",
      "Loss: tensor(97.4514, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4852,  0.4425,  1.4735],\n",
      "        [-0.5743,  0.4402,  1.8864]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0326,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(97.1954, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 49.0541, -87.3379,  67.5094],\n",
      "        [-43.8166, -16.7958,  93.3042]])\n",
      "tensor([0.8469, 0.2961])\n",
      "Epoch: 287\n",
      "Loss: tensor(97.1954, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4857,  0.4433,  1.4728],\n",
      "        [-0.5739,  0.4403,  1.8855]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0326,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(96.9407, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 48.6477, -86.9423,  67.4837],\n",
      "        [-43.6573, -16.8838,  93.2047]])\n",
      "tensor([0.8436, 0.2967])\n",
      "Epoch: 288\n",
      "Loss: tensor(96.9407, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4862,  0.4442,  1.4721],\n",
      "        [-0.5734,  0.4405,  1.8846]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0327,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(96.6874, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 48.2435, -86.5497,  67.4575],\n",
      "        [-43.4988, -16.9707,  93.1053]])\n",
      "tensor([0.8402, 0.2972])\n",
      "Epoch: 289\n",
      "Loss: tensor(96.6874, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4867,  0.4451,  1.4715],\n",
      "        [-0.5730,  0.4407,  1.8836]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0327,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(96.4357, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 47.8415, -86.1599,  67.4308],\n",
      "        [-43.3409, -17.0568,  93.0064]])\n",
      "tensor([0.8369, 0.2978])\n",
      "Epoch: 290\n",
      "Loss: tensor(96.4357, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4872,  0.4459,  1.4708],\n",
      "        [-0.5726,  0.4408,  1.8827]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0327,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(96.1851, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 47.4425, -85.7720,  67.4041],\n",
      "        [-43.1841, -17.1422,  92.9075]])\n",
      "tensor([0.8336, 0.2984])\n",
      "Epoch: 291\n",
      "Loss: tensor(96.1851, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4876,  0.4468,  1.4701],\n",
      "        [-0.5721,  0.4410,  1.8818]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0327,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(95.9361, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 47.0461, -85.3864,  67.3772],\n",
      "        [-43.0276, -17.2261,  92.8092]])\n",
      "tensor([0.8303, 0.2990])\n",
      "Epoch: 292\n",
      "Loss: tensor(95.9361, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4881,  0.4476,  1.4694],\n",
      "        [-0.5717,  0.4412,  1.8809]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0327,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(95.6884, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 46.6527, -85.0028,  67.3504],\n",
      "        [-42.8724, -17.3101,  92.7108]])\n",
      "tensor([0.8270, 0.2996])\n",
      "Epoch: 293\n",
      "Loss: tensor(95.6884, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4886,  0.4485,  1.4688],\n",
      "        [-0.5713,  0.4414,  1.8799]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0327,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(95.4420, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 46.2612, -84.6221,  67.3230],\n",
      "        [-42.7177, -17.3927,  92.6128]])\n",
      "tensor([0.8237, 0.3001])\n",
      "Epoch: 294\n",
      "Loss: tensor(95.4420, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4890,  0.4493,  1.4681],\n",
      "        [-0.5708,  0.4415,  1.8790]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0327,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(95.1969, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 45.8726, -84.2433,  67.2955],\n",
      "        [-42.5646, -17.4756,  92.5144]])\n",
      "tensor([0.8205, 0.3007])\n",
      "Epoch: 295\n",
      "Loss: tensor(95.1969, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4895,  0.4502,  1.4674],\n",
      "        [-0.5704,  0.4417,  1.8781]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0327,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(94.9532, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 45.4869, -83.8665,  67.2680],\n",
      "        [-42.4118, -17.5571,  92.4166]])\n",
      "tensor([0.8173, 0.3012])\n",
      "Epoch: 296\n",
      "Loss: tensor(94.9532, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4900,  0.4510,  1.4668],\n",
      "        [-0.5700,  0.4419,  1.8772]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0327,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(94.7107, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 45.1027, -83.4930,  67.2397],\n",
      "        [-42.2594, -17.6374,  92.3192]])\n",
      "tensor([0.8141, 0.3018])\n",
      "Epoch: 297\n",
      "Loss: tensor(94.7107, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4904,  0.4519,  1.4661],\n",
      "        [-0.5696,  0.4421,  1.8762]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0327,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(94.4696, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 44.7223, -83.1201,  67.2121],\n",
      "        [-42.1087, -17.7179,  92.2215]])\n",
      "tensor([0.8109, 0.3023])\n",
      "Epoch: 298\n",
      "Loss: tensor(94.4696, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4909,  0.4527,  1.4654],\n",
      "        [-0.5692,  0.4422,  1.8753]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0327,  0.4665], grad_fn=<SubBackward0>)\n",
      "tensor(94.2297, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 44.3439, -82.7503,  67.1839],\n",
      "        [-41.9581, -17.7971,  92.1243]])\n",
      "tensor([0.8077, 0.3029])\n",
      "Epoch: 299\n",
      "Loss: tensor(94.2297, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4913,  0.4535,  1.4647],\n",
      "        [-0.5687,  0.4424,  1.8744]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0327,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(93.9911, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 43.9677, -82.3828,  67.1553],\n",
      "        [-41.8096, -17.8766,  92.0266]])\n",
      "tensor([0.8046, 0.3034])\n",
      "Epoch: 300\n",
      "Loss: tensor(93.9911, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4917,  0.4543,  1.4641],\n",
      "        [-0.5683,  0.4426,  1.8735]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0328,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(93.7537, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 43.5943, -82.0171,  67.1268],\n",
      "        [-41.6613, -17.9550,  91.9294]])\n",
      "tensor([0.8014, 0.3039])\n",
      "Epoch: 301\n",
      "Loss: tensor(93.7537, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4922,  0.4552,  1.4634],\n",
      "        [-0.5679,  0.4428,  1.8726]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0328,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(93.5176, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 43.2232, -81.6540,  67.0979],\n",
      "        [-41.5133, -18.0321,  91.8328]])\n",
      "tensor([0.7983, 0.3044])\n",
      "Epoch: 302\n",
      "Loss: tensor(93.5176, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4926,  0.4560,  1.4627],\n",
      "        [-0.5675,  0.4430,  1.8716]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0328,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(93.2828, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 42.8544, -81.2930,  67.0689],\n",
      "        [-41.3663, -18.1087,  91.7362]])\n",
      "tensor([0.7952, 0.3049])\n",
      "Epoch: 303\n",
      "Loss: tensor(93.2828, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4930,  0.4568,  1.4621],\n",
      "        [-0.5671,  0.4431,  1.8707]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0328,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(93.0490, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 42.4880, -80.9342,  67.0395],\n",
      "        [-41.2203, -18.1848,  91.6396]])\n",
      "tensor([0.7922, 0.3054])\n",
      "Epoch: 304\n",
      "Loss: tensor(93.0490, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4935,  0.4576,  1.4614],\n",
      "        [-0.5667,  0.4433,  1.8698]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0328,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(92.8166, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 42.1241, -80.5773,  67.0102],\n",
      "        [-41.0753, -18.2608,  91.5430]])\n",
      "tensor([0.7891, 0.3059])\n",
      "Epoch: 305\n",
      "Loss: tensor(92.8166, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4939,  0.4584,  1.4607],\n",
      "        [-0.5662,  0.4435,  1.8689]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0328,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(92.5853, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 41.7626, -80.2227,  66.9805],\n",
      "        [-40.9307, -18.3351,  91.4470]])\n",
      "tensor([0.7861, 0.3064])\n",
      "Epoch: 306\n",
      "Loss: tensor(92.5853, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4943,  0.4592,  1.4600],\n",
      "        [-0.5658,  0.4437,  1.8680]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0328,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(92.3551, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 41.4035, -79.8701,  66.9507],\n",
      "        [-40.7874, -18.4095,  91.3507]])\n",
      "tensor([0.7830, 0.3069])\n",
      "Epoch: 307\n",
      "Loss: tensor(92.3551, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4947,  0.4600,  1.4594],\n",
      "        [-0.5654,  0.4439,  1.8671]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0328,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(92.1262, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 41.0469, -79.5195,  66.9209],\n",
      "        [-40.6447, -18.4831,  91.2547]])\n",
      "tensor([0.7800, 0.3074])\n",
      "Epoch: 308\n",
      "Loss: tensor(92.1262, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4951,  0.4608,  1.4587],\n",
      "        [-0.5650,  0.4441,  1.8661]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0328,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(91.8984, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 40.6924, -79.1712,  66.8906],\n",
      "        [-40.5030, -18.5562,  91.1588]])\n",
      "tensor([0.7770, 0.3079])\n",
      "Epoch: 309\n",
      "Loss: tensor(91.8984, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4955,  0.4616,  1.4580],\n",
      "        [-0.5646,  0.4442,  1.8652]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0328,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(91.6718, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 40.3404, -78.8247,  66.8604],\n",
      "        [-40.3623, -18.6291,  91.0629]])\n",
      "tensor([0.7741, 0.3084])\n",
      "Epoch: 310\n",
      "Loss: tensor(91.6718, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4959,  0.4624,  1.4574],\n",
      "        [-0.5642,  0.4444,  1.8643]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0328,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(91.4462, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 39.9909, -78.4801,  66.8300],\n",
      "        [-40.2215, -18.7002,  90.9677]])\n",
      "tensor([0.7711, 0.3089])\n",
      "Epoch: 311\n",
      "Loss: tensor(91.4462, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4963,  0.4632,  1.4567],\n",
      "        [-0.5638,  0.4446,  1.8634]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0328,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(91.2218, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 39.6434, -78.1379,  66.7994],\n",
      "        [-40.0821, -18.7715,  90.8721]])\n",
      "tensor([0.7682, 0.3093])\n",
      "Epoch: 312\n",
      "Loss: tensor(91.2218, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4967,  0.4639,  1.4560],\n",
      "        [-0.5634,  0.4448,  1.8625]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0328,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(90.9986, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 39.2980, -77.7981,  66.7683],\n",
      "        [-39.9431, -18.8416,  90.7771]])\n",
      "tensor([0.7653, 0.3098])\n",
      "Epoch: 313\n",
      "Loss: tensor(90.9986, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4971,  0.4647,  1.4554],\n",
      "        [-0.5630,  0.4450,  1.8616]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(90.7764, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 38.9555, -77.4592,  66.7376],\n",
      "        [-39.8056, -18.9119,  90.6818]])\n",
      "tensor([0.7624, 0.3102])\n",
      "Epoch: 314\n",
      "Loss: tensor(90.7764, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4975,  0.4655,  1.4547],\n",
      "        [-0.5626,  0.4452,  1.8607]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(90.5553, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 38.6154, -77.1226,  66.7067],\n",
      "        [-39.6688, -18.9814,  90.5866]])\n",
      "tensor([0.7595, 0.3107])\n",
      "Epoch: 315\n",
      "Loss: tensor(90.5553, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4979,  0.4663,  1.4540],\n",
      "        [-0.5622,  0.4454,  1.8598]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(90.3352, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 38.2768, -76.7885,  66.6753],\n",
      "        [-39.5322, -19.0499,  90.4920]])\n",
      "tensor([0.7566, 0.3111])\n",
      "Epoch: 316\n",
      "Loss: tensor(90.3352, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4983,  0.4670,  1.4534],\n",
      "        [-0.5618,  0.4456,  1.8589]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(90.1163, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 37.9408, -76.4560,  66.6439],\n",
      "        [-39.3962, -19.1174,  90.3976]])\n",
      "tensor([0.7538, 0.3116])\n",
      "Epoch: 317\n",
      "Loss: tensor(90.1163, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4987,  0.4678,  1.4527],\n",
      "        [-0.5614,  0.4458,  1.8580]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(89.8984, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 37.6071, -76.1254,  66.6124],\n",
      "        [-39.2612, -19.1847,  90.3033]])\n",
      "tensor([0.7509, 0.3120])\n",
      "Epoch: 318\n",
      "Loss: tensor(89.8984, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4990,  0.4686,  1.4520],\n",
      "        [-0.5610,  0.4459,  1.8571]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(89.6815, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 37.2752, -75.7973,  66.5804],\n",
      "        [-39.1268, -19.2514,  90.2090]])\n",
      "tensor([0.7481, 0.3124])\n",
      "Epoch: 319\n",
      "Loss: tensor(89.6815, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4994,  0.4693,  1.4514],\n",
      "        [-0.5606,  0.4461,  1.8562]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(89.4658, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 36.9457, -75.4708,  66.5484],\n",
      "        [-38.9936, -19.3177,  90.1148]])\n",
      "tensor([0.7453, 0.3129])\n",
      "Epoch: 320\n",
      "Loss: tensor(89.4658, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4998,  0.4701,  1.4507],\n",
      "        [-0.5603,  0.4463,  1.8553]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(89.2509, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 36.6187, -75.1459,  66.5165],\n",
      "        [-38.8605, -19.3830,  90.0210]])\n",
      "tensor([0.7425, 0.3133])\n",
      "Epoch: 321\n",
      "Loss: tensor(89.2509, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5001,  0.4708,  1.4500],\n",
      "        [-0.5599,  0.4465,  1.8544]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(89.0371, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 36.2935, -74.8233,  66.4842],\n",
      "        [-38.7286, -19.4479,  89.9271]])\n",
      "tensor([0.7397, 0.3137])\n",
      "Epoch: 322\n",
      "Loss: tensor(89.0371, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5005,  0.4716,  1.4494],\n",
      "        [-0.5595,  0.4467,  1.8535]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(88.8244, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 35.9704, -74.5027,  66.4516],\n",
      "        [-38.5976, -19.5127,  89.8332]])\n",
      "tensor([0.7370, 0.3141])\n",
      "Epoch: 323\n",
      "Loss: tensor(88.8244, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5009,  0.4723,  1.4487],\n",
      "        [-0.5591,  0.4469,  1.8526]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(88.6125, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 35.6496, -74.1836,  66.4191],\n",
      "        [-38.4672, -19.5767,  89.7396]])\n",
      "tensor([0.7342, 0.3145])\n",
      "Epoch: 324\n",
      "Loss: tensor(88.6125, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5012,  0.4731,  1.4480],\n",
      "        [-0.5587,  0.4471,  1.8517]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(88.4018, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 35.3309, -73.8666,  66.3864],\n",
      "        [-38.3375, -19.6400,  89.6461]])\n",
      "tensor([0.7315, 0.3149])\n",
      "Epoch: 325\n",
      "Loss: tensor(88.4018, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5016,  0.4738,  1.4474],\n",
      "        [-0.5583,  0.4473,  1.8508]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(88.1921, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 35.0139, -73.5518,  66.3533],\n",
      "        [-38.2079, -19.7021,  89.5532]])\n",
      "tensor([0.7288, 0.3153])\n",
      "Epoch: 326\n",
      "Loss: tensor(88.1921, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5019,  0.4745,  1.4467],\n",
      "        [-0.5579,  0.4475,  1.8499]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0329,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(87.9832, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 34.6996, -73.2383,  66.3203],\n",
      "        [-38.0792, -19.7636,  89.4605]])\n",
      "tensor([0.7261, 0.3157])\n",
      "Epoch: 327\n",
      "Loss: tensor(87.9832, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5023,  0.4753,  1.4460],\n",
      "        [-0.5576,  0.4477,  1.8490]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(87.7753, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 34.3871, -72.9269,  66.2871],\n",
      "        [-37.9516, -19.8254,  89.3674]])\n",
      "tensor([0.7234, 0.3161])\n",
      "Epoch: 328\n",
      "Loss: tensor(87.7753, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5026,  0.4760,  1.4454],\n",
      "        [-0.5572,  0.4479,  1.8481]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(87.5684, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 34.0764, -72.6177,  66.2534],\n",
      "        [-37.8248, -19.8864,  89.2745]])\n",
      "tensor([0.7207, 0.3165])\n",
      "Epoch: 329\n",
      "Loss: tensor(87.5684, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5030,  0.4767,  1.4447],\n",
      "        [-0.5568,  0.4481,  1.8472]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(87.3624, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 33.7678, -72.3101,  66.2198],\n",
      "        [-37.6987, -19.9470,  89.1817]])\n",
      "tensor([0.7181, 0.3169])\n",
      "Epoch: 330\n",
      "Loss: tensor(87.3624, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5033,  0.4774,  1.4441],\n",
      "        [-0.5564,  0.4483,  1.8463]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(87.1574, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 33.4615, -72.0042,  66.1861],\n",
      "        [-37.5731, -20.0068,  89.0892]])\n",
      "tensor([0.7155, 0.3172])\n",
      "Epoch: 331\n",
      "Loss: tensor(87.1574, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5036,  0.4782,  1.4434],\n",
      "        [-0.5561,  0.4485,  1.8454]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4664], grad_fn=<SubBackward0>)\n",
      "tensor(86.9533, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 33.1574, -71.6999,  66.1524],\n",
      "        [-37.4477, -20.0656,  88.9972]])\n",
      "tensor([0.7128, 0.3176])\n",
      "Epoch: 332\n",
      "Loss: tensor(86.9533, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5040,  0.4789,  1.4427],\n",
      "        [-0.5557,  0.4487,  1.8445]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(86.7501, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 32.8554, -71.3970,  66.1188],\n",
      "        [-37.3236, -20.1244,  88.9049]])\n",
      "tensor([0.7102, 0.3180])\n",
      "Epoch: 333\n",
      "Loss: tensor(86.7501, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5043,  0.4796,  1.4421],\n",
      "        [-0.5553,  0.4489,  1.8436]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(86.5478, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 32.5554, -71.0962,  66.0848],\n",
      "        [-37.2004, -20.1829,  88.8126]])\n",
      "tensor([0.7077, 0.3183])\n",
      "Epoch: 334\n",
      "Loss: tensor(86.5478, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5046,  0.4803,  1.4414],\n",
      "        [-0.5549,  0.4491,  1.8428]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(86.3464, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 32.2568, -70.7975,  66.0504],\n",
      "        [-37.0776, -20.2406,  88.7207]])\n",
      "tensor([0.7051, 0.3187])\n",
      "Epoch: 335\n",
      "Loss: tensor(86.3464, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5049,  0.4810,  1.4408],\n",
      "        [-0.5546,  0.4493,  1.8419]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(86.1459, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 31.9603, -70.5006,  66.0158],\n",
      "        [-36.9550, -20.2972,  88.6292]])\n",
      "tensor([0.7025, 0.3190])\n",
      "Epoch: 336\n",
      "Loss: tensor(86.1459, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5053,  0.4817,  1.4401],\n",
      "        [-0.5542,  0.4495,  1.8410]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(85.9463, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 31.6659, -70.2054,  65.9812],\n",
      "        [-36.8338, -20.3542,  88.5373]])\n",
      "tensor([0.7000, 0.3194])\n",
      "Epoch: 337\n",
      "Loss: tensor(85.9463, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5056,  0.4824,  1.4394],\n",
      "        [-0.5538,  0.4497,  1.8401]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(85.7475, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 31.3733, -69.9120,  65.9464],\n",
      "        [-36.7129, -20.4102,  88.4457]])\n",
      "tensor([0.6974, 0.3197])\n",
      "Epoch: 338\n",
      "Loss: tensor(85.7475, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5059,  0.4831,  1.4388],\n",
      "        [-0.5535,  0.4499,  1.8392]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(85.5498, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 31.0825, -69.6203,  65.9115],\n",
      "        [-36.5923, -20.4651,  88.3548]])\n",
      "tensor([0.6949, 0.3201])\n",
      "Epoch: 339\n",
      "Loss: tensor(85.5498, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5062,  0.4838,  1.4381],\n",
      "        [-0.5531,  0.4501,  1.8383]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(85.3527, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 30.7941, -69.3300,  65.8765],\n",
      "        [-36.4732, -20.5205,  88.2633]])\n",
      "tensor([0.6924, 0.3204])\n",
      "Epoch: 340\n",
      "Loss: tensor(85.3527, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5065,  0.4845,  1.4375],\n",
      "        [-0.5527,  0.4503,  1.8374]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0330,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(85.1565, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 30.5078, -69.0411,  65.8417],\n",
      "        [-36.3543, -20.5751,  88.1721]])\n",
      "tensor([0.6899, 0.3207])\n",
      "Epoch: 341\n",
      "Loss: tensor(85.1565, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5068,  0.4852,  1.4368],\n",
      "        [-0.5524,  0.4505,  1.8366]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(84.9613, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 30.2232, -68.7542,  65.8066],\n",
      "        [-36.2361, -20.6289,  88.0814]])\n",
      "tensor([0.6875, 0.3211])\n",
      "Epoch: 342\n",
      "Loss: tensor(84.9613, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5071,  0.4859,  1.4361],\n",
      "        [-0.5520,  0.4507,  1.8357]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(84.7667, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 29.9402, -68.4694,  65.7710],\n",
      "        [-36.1187, -20.6826,  87.9903]])\n",
      "tensor([0.6850, 0.3214])\n",
      "Epoch: 343\n",
      "Loss: tensor(84.7667, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5074,  0.4866,  1.4355],\n",
      "        [-0.5516,  0.4509,  1.8348]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(84.5731, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 29.6595, -68.1856,  65.7358],\n",
      "        [-36.0018, -20.7356,  87.8996]])\n",
      "tensor([0.6826, 0.3217])\n",
      "Epoch: 344\n",
      "Loss: tensor(84.5731, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5077,  0.4873,  1.4348],\n",
      "        [-0.5513,  0.4511,  1.8339]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(84.3803, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 29.3808, -67.9032,  65.7004],\n",
      "        [-35.8857, -20.7881,  87.8090]])\n",
      "tensor([0.6801, 0.3220])\n",
      "Epoch: 345\n",
      "Loss: tensor(84.3803, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5080,  0.4879,  1.4342],\n",
      "        [-0.5509,  0.4514,  1.8330]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(84.1883, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 29.1038, -67.6229,  65.6648],\n",
      "        [-35.7695, -20.8393,  87.7191]])\n",
      "tensor([0.6777, 0.3223])\n",
      "Epoch: 346\n",
      "Loss: tensor(84.1883, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5083,  0.4886,  1.4335],\n",
      "        [-0.5506,  0.4516,  1.8322]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(83.9971, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 28.8282, -67.3445,  65.6289],\n",
      "        [-35.6545, -20.8910,  87.6287]])\n",
      "tensor([0.6753, 0.3226])\n",
      "Epoch: 347\n",
      "Loss: tensor(83.9971, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5086,  0.4893,  1.4329],\n",
      "        [-0.5502,  0.4518,  1.8313]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(83.8067, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 28.5545, -67.0678,  65.5928],\n",
      "        [-35.5399, -20.9417,  87.5387]])\n",
      "tensor([0.6729, 0.3229])\n",
      "Epoch: 348\n",
      "Loss: tensor(83.8067, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5089,  0.4900,  1.4322],\n",
      "        [-0.5498,  0.4520,  1.8304]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(83.6170, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 28.2826, -66.7925,  65.5565],\n",
      "        [-35.4263, -20.9923,  87.4486]])\n",
      "tensor([0.6705, 0.3232])\n",
      "Epoch: 349\n",
      "Loss: tensor(83.6170, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5091,  0.4906,  1.4315],\n",
      "        [-0.5495,  0.4522,  1.8295]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(83.4282, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 28.0128, -66.5187,  65.5204],\n",
      "        [-35.3129, -21.0420,  87.3589]])\n",
      "tensor([0.6682, 0.3235])\n",
      "Epoch: 350\n",
      "Loss: tensor(83.4282, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5094,  0.4913,  1.4309],\n",
      "        [-0.5491,  0.4524,  1.8287]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(83.2402, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 27.7445, -66.2467,  65.4840],\n",
      "        [-35.2003, -21.0914,  87.2693]])\n",
      "tensor([0.6658, 0.3238])\n",
      "Epoch: 351\n",
      "Loss: tensor(83.2402, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5097,  0.4920,  1.4302],\n",
      "        [-0.5488,  0.4526,  1.8278]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(83.0529, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 27.4781, -65.9763,  65.4474],\n",
      "        [-35.0883, -21.1404,  87.1797]])\n",
      "tensor([0.6635, 0.3241])\n",
      "Epoch: 352\n",
      "Loss: tensor(83.0529, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5100,  0.4926,  1.4296],\n",
      "        [-0.5484,  0.4528,  1.8269]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(82.8663, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 27.2140, -65.7067,  65.4111],\n",
      "        [-34.9766, -21.1885,  87.0905]])\n",
      "tensor([0.6612, 0.3244])\n",
      "Epoch: 353\n",
      "Loss: tensor(82.8663, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5103,  0.4933,  1.4289],\n",
      "        [-0.5481,  0.4530,  1.8260]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(82.6806, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 26.9505, -65.4400,  65.3740],\n",
      "        [-34.8667, -21.2373,  87.0006]])\n",
      "tensor([0.6588, 0.3247])\n",
      "Epoch: 354\n",
      "Loss: tensor(82.6806, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5105,  0.4939,  1.4283],\n",
      "        [-0.5477,  0.4533,  1.8252]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0331,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(82.4956, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 26.6894, -65.1742,  65.3371],\n",
      "        [-34.7560, -21.2843,  86.9118]])\n",
      "tensor([0.6565, 0.3250])\n",
      "Epoch: 355\n",
      "Loss: tensor(82.4956, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5108,  0.4946,  1.4276],\n",
      "        [-0.5474,  0.4535,  1.8243]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(82.3113, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 26.4296, -64.9103,  65.2999],\n",
      "        [-34.6469, -21.3319,  86.8224]])\n",
      "tensor([0.6542, 0.3252])\n",
      "Epoch: 356\n",
      "Loss: tensor(82.3113, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5111,  0.4952,  1.4270],\n",
      "        [-0.5470,  0.4537,  1.8234]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(82.1279, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 26.1717, -64.6480,  65.2626],\n",
      "        [-34.5376, -21.3782,  86.7338]])\n",
      "tensor([0.6520, 0.3255])\n",
      "Epoch: 357\n",
      "Loss: tensor(82.1279, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5113,  0.4959,  1.4263],\n",
      "        [-0.5467,  0.4539,  1.8226]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(81.9450, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 25.9157, -64.3869,  65.2253],\n",
      "        [-34.4303, -21.4254,  86.6442]])\n",
      "tensor([0.6497, 0.3257])\n",
      "Epoch: 358\n",
      "Loss: tensor(81.9450, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5116,  0.4965,  1.4257],\n",
      "        [-0.5464,  0.4541,  1.8217]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(81.7630, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 25.6618, -64.1270,  65.1880],\n",
      "        [-34.3220, -21.4704,  86.5561]])\n",
      "tensor([0.6475, 0.3260])\n",
      "Epoch: 359\n",
      "Loss: tensor(81.7630, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5118,  0.4972,  1.4250],\n",
      "        [-0.5460,  0.4543,  1.8208]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(81.5817, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 25.4102, -63.8677,  65.1513],\n",
      "        [-34.2149, -21.5157,  86.4675]])\n",
      "tensor([0.6452, 0.3263])\n",
      "Epoch: 360\n",
      "Loss: tensor(81.5817, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5121,  0.4978,  1.4244],\n",
      "        [-0.5457,  0.4545,  1.8200]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(81.4011, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 25.1591, -63.6112,  65.1136],\n",
      "        [-34.1084, -21.5605,  86.3791]])\n",
      "tensor([0.6430, 0.3265])\n",
      "Epoch: 361\n",
      "Loss: tensor(81.4011, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5123,  0.4984,  1.4237],\n",
      "        [-0.5453,  0.4547,  1.8191]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(81.2211, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 24.9099, -63.3560,  65.0758],\n",
      "        [-34.0024, -21.6050,  86.2907]])\n",
      "tensor([0.6408, 0.3268])\n",
      "Epoch: 362\n",
      "Loss: tensor(81.2211, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5126,  0.4991,  1.4231],\n",
      "        [-0.5450,  0.4550,  1.8183]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4663], grad_fn=<SubBackward0>)\n",
      "tensor(81.0419, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 24.6622, -63.1026,  65.0379],\n",
      "        [-33.8970, -21.6490,  86.2025]])\n",
      "tensor([0.6386, 0.3270])\n",
      "Epoch: 363\n",
      "Loss: tensor(81.0419, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5128,  0.4997,  1.4224],\n",
      "        [-0.5447,  0.4552,  1.8174]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(80.8634, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 24.4163, -62.8503,  65.0000],\n",
      "        [-33.7916, -21.6919,  86.1148]])\n",
      "tensor([0.6364, 0.3273])\n",
      "Epoch: 364\n",
      "Loss: tensor(80.8634, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5131,  0.5003,  1.4218],\n",
      "        [-0.5443,  0.4554,  1.8165]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(80.6856, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 24.1722, -62.5995,  64.9621],\n",
      "        [-33.6877, -21.7352,  86.0268]])\n",
      "tensor([0.6342, 0.3275])\n",
      "Epoch: 365\n",
      "Loss: tensor(80.6856, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5133,  0.5009,  1.4211],\n",
      "        [-0.5440,  0.4556,  1.8157]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(80.5085, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 23.9296, -62.3502,  64.9239],\n",
      "        [-33.5836, -21.7775,  85.9393]])\n",
      "tensor([0.6321, 0.3277])\n",
      "Epoch: 366\n",
      "Loss: tensor(80.5085, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5136,  0.5016,  1.4205],\n",
      "        [-0.5436,  0.4558,  1.8148]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(80.3320, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 23.6893, -62.1014,  64.8862],\n",
      "        [-33.4803, -21.8195,  85.8517]])\n",
      "tensor([0.6299, 0.3280])\n",
      "Epoch: 367\n",
      "Loss: tensor(80.3320, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5138,  0.5022,  1.4198],\n",
      "        [-0.5433,  0.4561,  1.8140]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(80.1562, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 23.4499, -61.8551,  64.8478],\n",
      "        [-33.3781, -21.8618,  85.7638]])\n",
      "tensor([0.6278, 0.3282])\n",
      "Epoch: 368\n",
      "Loss: tensor(80.1562, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5140,  0.5028,  1.4192],\n",
      "        [-0.5430,  0.4563,  1.8131]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(79.9810, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 23.2119, -61.6103,  64.8092],\n",
      "        [-33.2753, -21.9022,  85.6770]])\n",
      "tensor([0.6257, 0.3284])\n",
      "Epoch: 369\n",
      "Loss: tensor(79.9810, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5143,  0.5034,  1.4185],\n",
      "        [-0.5426,  0.4565,  1.8122]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(79.8066, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 22.9754, -61.3671,  64.7704],\n",
      "        [-33.1739, -21.9432,  85.5897]])\n",
      "tensor([0.6236, 0.3286])\n",
      "Epoch: 370\n",
      "Loss: tensor(79.8066, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5145,  0.5040,  1.4179],\n",
      "        [-0.5423,  0.4567,  1.8114]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0332,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(79.6328, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 22.7412, -61.1245,  64.7320],\n",
      "        [-33.0726, -21.9835,  85.5027]])\n",
      "tensor([0.6215, 0.3289])\n",
      "Epoch: 371\n",
      "Loss: tensor(79.6328, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5147,  0.5047,  1.4172],\n",
      "        [-0.5420,  0.4569,  1.8105]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(79.4596, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 22.5084, -60.8833,  64.6935],\n",
      "        [-32.9717, -22.0230,  85.4160]])\n",
      "tensor([0.6194, 0.3291])\n",
      "Epoch: 372\n",
      "Loss: tensor(79.4596, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5149,  0.5053,  1.4166],\n",
      "        [-0.5416,  0.4571,  1.8097]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(79.2871, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 22.2772, -60.6436,  64.6547],\n",
      "        [-32.8713, -22.0620,  85.3294]])\n",
      "tensor([0.6173, 0.3293])\n",
      "Epoch: 373\n",
      "Loss: tensor(79.2871, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5152,  0.5059,  1.4159],\n",
      "        [-0.5413,  0.4574,  1.8088]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(79.1152, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 22.0469, -60.4062,  64.6155],\n",
      "        [-32.7718, -22.1010,  85.2428]])\n",
      "tensor([0.6152, 0.3295])\n",
      "Epoch: 374\n",
      "Loss: tensor(79.1152, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5154,  0.5065,  1.4153],\n",
      "        [-0.5410,  0.4576,  1.8080]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(78.9440, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 21.8183, -60.1697,  64.5763],\n",
      "        [-32.6735, -22.1405,  85.1558]])\n",
      "tensor([0.6132, 0.3297])\n",
      "Epoch: 375\n",
      "Loss: tensor(78.9440, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5156,  0.5071,  1.4146],\n",
      "        [-0.5407,  0.4578,  1.8071]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(78.7734, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 21.5911, -59.9348,  64.5369],\n",
      "        [-32.5746, -22.1783,  85.0696]])\n",
      "tensor([0.6111, 0.3299])\n",
      "Epoch: 376\n",
      "Loss: tensor(78.7734, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5158,  0.5077,  1.4140],\n",
      "        [-0.5403,  0.4580,  1.8063]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(78.6034, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 21.3664, -59.7000,  64.4981],\n",
      "        [-32.4772, -22.2166,  84.9830]])\n",
      "tensor([0.6091, 0.3301])\n",
      "Epoch: 377\n",
      "Loss: tensor(78.6034, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5160,  0.5083,  1.4133],\n",
      "        [-0.5400,  0.4583,  1.8054]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(78.4341, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 21.1422, -59.4680,  64.4585],\n",
      "        [-32.3795, -22.2536,  84.8970]])\n",
      "tensor([0.6071, 0.3303])\n",
      "Epoch: 378\n",
      "Loss: tensor(78.4341, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5162,  0.5089,  1.4127],\n",
      "        [-0.5397,  0.4585,  1.8046]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(78.2653, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 20.9199, -59.2366,  64.4191],\n",
      "        [-32.2831, -22.2911,  84.8107]])\n",
      "tensor([0.6050, 0.3305])\n",
      "Epoch: 379\n",
      "Loss: tensor(78.2653, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5165,  0.5095,  1.4121],\n",
      "        [-0.5394,  0.4587,  1.8037]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(78.0972, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 20.6991, -59.0066,  64.3796],\n",
      "        [-32.1864, -22.3273,  84.7251]])\n",
      "tensor([0.6030, 0.3307])\n",
      "Epoch: 380\n",
      "Loss: tensor(78.0972, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5167,  0.5100,  1.4114],\n",
      "        [-0.5390,  0.4589,  1.8029]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(77.9296, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 20.4794, -58.7784,  64.3397],\n",
      "        [-32.0902, -22.3633,  84.6394]])\n",
      "tensor([0.6011, 0.3309])\n",
      "Epoch: 381\n",
      "Loss: tensor(77.9296, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5169,  0.5106,  1.4108],\n",
      "        [-0.5387,  0.4591,  1.8020]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(77.7627, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 20.2616, -58.5509,  64.3001],\n",
      "        [-31.9953, -22.3997,  84.5534]])\n",
      "tensor([0.5991, 0.3310])\n",
      "Epoch: 382\n",
      "Loss: tensor(77.7627, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5171,  0.5112,  1.4101],\n",
      "        [-0.5384,  0.4594,  1.8012]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(77.5964, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 20.0452, -58.3250,  64.2602],\n",
      "        [-31.9003, -22.4348,  84.4680]])\n",
      "tensor([0.5971, 0.3312])\n",
      "Epoch: 383\n",
      "Loss: tensor(77.5964, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5173,  0.5118,  1.4095],\n",
      "        [-0.5381,  0.4596,  1.8003]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(77.4307, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 19.8298, -58.1008,  64.2200],\n",
      "        [-31.8064, -22.4704,  84.3822]])\n",
      "tensor([0.5951, 0.3314])\n",
      "Epoch: 384\n",
      "Loss: tensor(77.4307, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5175,  0.5124,  1.4088],\n",
      "        [-0.5378,  0.4598,  1.7995]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(77.2654, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 19.6166, -57.8770,  64.1802],\n",
      "        [-31.7124, -22.5049,  84.2969]])\n",
      "tensor([0.5932, 0.3316])\n",
      "Epoch: 385\n",
      "Loss: tensor(77.2654, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5177,  0.5130,  1.4082],\n",
      "        [-0.5375,  0.4600,  1.7986]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(77.1009, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 19.4045, -57.6549,  64.1401],\n",
      "        [-31.6192, -22.5393,  84.2117]])\n",
      "tensor([0.5913, 0.3317])\n",
      "Epoch: 386\n",
      "Loss: tensor(77.1009, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5179,  0.5135,  1.4076],\n",
      "        [-0.5371,  0.4603,  1.7978]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(76.9369, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 19.1943, -57.4335,  64.1003],\n",
      "        [-31.5264, -22.5732,  84.1265]])\n",
      "tensor([0.5894, 0.3319])\n",
      "Epoch: 387\n",
      "Loss: tensor(76.9369, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5181,  0.5141,  1.4069],\n",
      "        [-0.5368,  0.4605,  1.7970]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0333,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(76.7736, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 18.9852, -57.2137,  64.0602],\n",
      "        [-31.4336, -22.6063,  84.0419]])\n",
      "tensor([0.5874, 0.3321])\n",
      "Epoch: 388\n",
      "Loss: tensor(76.7736, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5182,  0.5147,  1.4063],\n",
      "        [-0.5365,  0.4607,  1.7961]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(76.6107, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 18.7772, -56.9955,  64.0197],\n",
      "        [-31.3423, -22.6400,  83.9568]])\n",
      "tensor([0.5855, 0.3322])\n",
      "Epoch: 389\n",
      "Loss: tensor(76.6107, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5184,  0.5153,  1.4056],\n",
      "        [-0.5362,  0.4610,  1.7953]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(76.4483, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 18.5708, -56.7785,  63.9793],\n",
      "        [-31.2510, -22.6729,  83.8718]])\n",
      "tensor([0.5836, 0.3324])\n",
      "Epoch: 390\n",
      "Loss: tensor(76.4483, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5186,  0.5158,  1.4050],\n",
      "        [-0.5359,  0.4612,  1.7944]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(76.2866, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 18.3661, -56.5621,  63.9390],\n",
      "        [-31.1604, -22.7057,  83.7872]])\n",
      "tensor([0.5818, 0.3325])\n",
      "Epoch: 391\n",
      "Loss: tensor(76.2866, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5188,  0.5164,  1.4044],\n",
      "        [-0.5356,  0.4614,  1.7936]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(76.1254, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 18.1626, -56.3474,  63.8985],\n",
      "        [-31.0700, -22.7377,  83.7026]])\n",
      "tensor([0.5799, 0.3327])\n",
      "Epoch: 392\n",
      "Loss: tensor(76.1254, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5190,  0.5170,  1.4037],\n",
      "        [-0.5353,  0.4616,  1.7928]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4662], grad_fn=<SubBackward0>)\n",
      "tensor(75.9648, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 17.9604, -56.1339,  63.8579],\n",
      "        [-30.9796, -22.7690,  83.6185]])\n",
      "tensor([0.5780, 0.3328])\n",
      "Epoch: 393\n",
      "Loss: tensor(75.9648, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5192,  0.5175,  1.4031],\n",
      "        [-0.5349,  0.4619,  1.7919]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(75.8047, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 17.7593, -55.9219,  63.8170],\n",
      "        [-30.8895, -22.7997,  83.5345]])\n",
      "tensor([0.5762, 0.3330])\n",
      "Epoch: 394\n",
      "Loss: tensor(75.8047, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5193,  0.5181,  1.4024],\n",
      "        [-0.5346,  0.4621,  1.7911]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(75.6452, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 17.5600, -55.7105,  63.7764],\n",
      "        [-30.8010, -22.8312,  83.4501]])\n",
      "tensor([0.5743, 0.3331])\n",
      "Epoch: 395\n",
      "Loss: tensor(75.6452, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5195,  0.5186,  1.4018],\n",
      "        [-0.5343,  0.4623,  1.7903]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(75.4861, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 17.3615, -55.5011,  63.7352],\n",
      "        [-30.7118, -22.8611,  83.3665]])\n",
      "tensor([0.5725, 0.3333])\n",
      "Epoch: 396\n",
      "Loss: tensor(75.4861, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5197,  0.5192,  1.4012],\n",
      "        [-0.5340,  0.4625,  1.7894]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(75.3277, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 17.1652, -55.2917,  63.6947],\n",
      "        [-30.6230, -22.8906,  83.2830]])\n",
      "tensor([0.5707, 0.3334])\n",
      "Epoch: 397\n",
      "Loss: tensor(75.3277, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5199,  0.5197,  1.4005],\n",
      "        [-0.5337,  0.4628,  1.7886]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(75.1697, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 16.9691, -55.0850,  63.6532],\n",
      "        [-30.5358, -22.9209,  83.1990]])\n",
      "tensor([0.5689, 0.3335])\n",
      "Epoch: 398\n",
      "Loss: tensor(75.1697, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5200,  0.5203,  1.3999],\n",
      "        [-0.5334,  0.4630,  1.7878]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(75.0123, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 16.7750, -54.8786,  63.6122],\n",
      "        [-30.4486, -22.9504,  83.1153]])\n",
      "tensor([0.5671, 0.3337])\n",
      "Epoch: 399\n",
      "Loss: tensor(75.0123, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5202,  0.5208,  1.3993],\n",
      "        [-0.5331,  0.4632,  1.7869]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(74.8554, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 16.5820, -54.6738,  63.5709],\n",
      "        [-30.3620, -22.9798,  83.0317]])\n",
      "tensor([0.5653, 0.3338])\n",
      "Epoch: 400\n",
      "Loss: tensor(74.8554, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5204,  0.5214,  1.3986],\n",
      "        [-0.5328,  0.4635,  1.7861]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(74.6990, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 16.3902, -54.4700,  63.5295],\n",
      "        [-30.2756, -23.0085,  82.9483]])\n",
      "tensor([0.5635, 0.3339])\n",
      "Epoch: 401\n",
      "Loss: tensor(74.6990, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5205,  0.5219,  1.3980],\n",
      "        [-0.5325,  0.4637,  1.7853]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(74.5433, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 16.2000, -54.2672,  63.4882],\n",
      "        [-30.1904, -23.0375,  82.8647]])\n",
      "tensor([0.5617, 0.3340])\n",
      "Epoch: 402\n",
      "Loss: tensor(74.5433, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5207,  0.5225,  1.3973],\n",
      "        [-0.5322,  0.4639,  1.7844]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(74.3879, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 16.0113, -54.0651,  63.4470],\n",
      "        [-30.1048, -23.0656,  82.7814]])\n",
      "tensor([0.5600, 0.3342])\n",
      "Epoch: 403\n",
      "Loss: tensor(74.3879, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5208,  0.5230,  1.3967],\n",
      "        [-0.5319,  0.4642,  1.7836]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(74.2330, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 15.8238, -53.8644,  63.4056],\n",
      "        [-30.0197, -23.0931,  82.6985]])\n",
      "tensor([0.5582, 0.3343])\n",
      "Epoch: 404\n",
      "Loss: tensor(74.2330, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5210,  0.5236,  1.3961],\n",
      "        [-0.5316,  0.4644,  1.7828]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0334,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(74.0787, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 15.6367, -53.6658,  63.3636],\n",
      "        [-29.9353, -23.1207,  82.6155]])\n",
      "tensor([0.5565, 0.3344])\n",
      "Epoch: 405\n",
      "Loss: tensor(74.0787, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5212,  0.5241,  1.3954],\n",
      "        [-0.5313,  0.4646,  1.7820]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(73.9249, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 15.4519, -53.4673,  63.3222],\n",
      "        [-29.8513, -23.1478,  82.5326]])\n",
      "tensor([0.5547, 0.3345])\n",
      "Epoch: 406\n",
      "Loss: tensor(73.9249, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5213,  0.5246,  1.3948],\n",
      "        [-0.5310,  0.4648,  1.7811]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(73.7715, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 15.2680, -53.2702,  63.2804],\n",
      "        [-29.7678, -23.1748,  82.4497]])\n",
      "tensor([0.5530, 0.3346])\n",
      "Epoch: 407\n",
      "Loss: tensor(73.7715, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5215,  0.5252,  1.3942],\n",
      "        [-0.5307,  0.4651,  1.7803]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(73.6187, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 15.0850, -53.0744,  63.2385],\n",
      "        [-29.6846, -23.2013,  82.3671]])\n",
      "tensor([0.5513, 0.3347])\n",
      "Epoch: 408\n",
      "Loss: tensor(73.6187, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5216,  0.5257,  1.3935],\n",
      "        [-0.5304,  0.4653,  1.7795]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(73.4664, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 14.9029, -52.8803,  63.1962],\n",
      "        [-29.6020, -23.2275,  82.2845]])\n",
      "tensor([0.5496, 0.3348])\n",
      "Epoch: 409\n",
      "Loss: tensor(73.4664, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5218,  0.5262,  1.3929],\n",
      "        [-0.5301,  0.4655,  1.7787]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(73.3145, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 14.7232, -52.6860,  63.1546],\n",
      "        [-29.5196, -23.2533,  82.2021]])\n",
      "tensor([0.5479, 0.3349])\n",
      "Epoch: 410\n",
      "Loss: tensor(73.3145, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5219,  0.5267,  1.3923],\n",
      "        [-0.5298,  0.4658,  1.7778]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(73.1631, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 14.5440, -52.4936,  63.1124],\n",
      "        [-29.4380, -23.2792,  82.1195]])\n",
      "tensor([0.5462, 0.3350])\n",
      "Epoch: 411\n",
      "Loss: tensor(73.1631, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5221,  0.5273,  1.3917],\n",
      "        [-0.5295,  0.4660,  1.7770]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(73.0122, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 14.3661, -52.3020,  63.0703],\n",
      "        [-29.3564, -23.3041,  82.0375]])\n",
      "tensor([0.5445, 0.3351])\n",
      "Epoch: 412\n",
      "Loss: tensor(73.0122, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5222,  0.5278,  1.3910],\n",
      "        [-0.5292,  0.4662,  1.7762]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(72.8617, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 14.1895, -52.1117,  63.0281],\n",
      "        [-29.2755, -23.3292,  81.9552]])\n",
      "tensor([0.5429, 0.3352])\n",
      "Epoch: 413\n",
      "Loss: tensor(72.8617, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5223,  0.5283,  1.3904],\n",
      "        [-0.5289,  0.4665,  1.7754]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(72.7118, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 14.0141, -51.9222,  62.9859],\n",
      "        [-29.1948, -23.3536,  81.8733]])\n",
      "tensor([0.5412, 0.3353])\n",
      "Epoch: 414\n",
      "Loss: tensor(72.7118, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5225,  0.5288,  1.3898],\n",
      "        [-0.5286,  0.4667,  1.7746]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(72.5623, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 13.8397, -51.7341,  62.9436],\n",
      "        [-29.1144, -23.3777,  81.7915]])\n",
      "tensor([0.5395, 0.3354])\n",
      "Epoch: 415\n",
      "Loss: tensor(72.5623, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5226,  0.5293,  1.3891],\n",
      "        [-0.5283,  0.4669,  1.7737]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(72.4133, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 13.6665, -51.5471,  62.9011],\n",
      "        [-29.0345, -23.4016,  81.7099]])\n",
      "tensor([0.5379, 0.3355])\n",
      "Epoch: 416\n",
      "Loss: tensor(72.4133, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5228,  0.5299,  1.3885],\n",
      "        [-0.5281,  0.4672,  1.7729]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(72.2646, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 13.4945, -51.3610,  62.8586],\n",
      "        [-28.9551, -23.4252,  81.6281]])\n",
      "tensor([0.5363, 0.3356])\n",
      "Epoch: 417\n",
      "Loss: tensor(72.2646, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5229,  0.5304,  1.3879],\n",
      "        [-0.5278,  0.4674,  1.7721]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(72.1166, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 13.3237, -51.1759,  62.8160],\n",
      "        [-28.8758, -23.4482,  81.5468]])\n",
      "tensor([0.5346, 0.3356])\n",
      "Epoch: 418\n",
      "Loss: tensor(72.1166, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5230,  0.5309,  1.3872],\n",
      "        [-0.5275,  0.4676,  1.7713]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(71.9690, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 13.1544, -50.9916,  62.7736],\n",
      "        [-28.7972, -23.4713,  81.4654]])\n",
      "tensor([0.5330, 0.3357])\n",
      "Epoch: 419\n",
      "Loss: tensor(71.9690, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5232,  0.5314,  1.3866],\n",
      "        [-0.5272,  0.4679,  1.7705]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(71.8218, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 12.9860, -50.8085,  62.7310],\n",
      "        [-28.7189, -23.4937,  81.3842]])\n",
      "tensor([0.5314, 0.3358])\n",
      "Epoch: 420\n",
      "Loss: tensor(71.8218, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5233,  0.5319,  1.3860],\n",
      "        [-0.5269,  0.4681,  1.7697]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(71.6751, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 12.8189, -50.6263,  62.6885],\n",
      "        [-28.6414, -23.5164,  81.3028]])\n",
      "tensor([0.5298, 0.3359])\n",
      "Epoch: 421\n",
      "Loss: tensor(71.6751, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5234,  0.5324,  1.3854],\n",
      "        [-0.5266,  0.4683,  1.7689]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(71.5287, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 12.6524, -50.4457,  62.6455],\n",
      "        [-28.5642, -23.5388,  81.2214]])\n",
      "tensor([0.5282, 0.3359])\n",
      "Epoch: 422\n",
      "Loss: tensor(71.5287, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5235,  0.5329,  1.3847],\n",
      "        [-0.5263,  0.4686,  1.7680]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4661], grad_fn=<SubBackward0>)\n",
      "tensor(71.3828, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 12.4872, -50.2659,  62.6025],\n",
      "        [-28.4872, -23.5606,  81.1405]])\n",
      "tensor([0.5266, 0.3360])\n",
      "Epoch: 423\n",
      "Loss: tensor(71.3828, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5237,  0.5334,  1.3841],\n",
      "        [-0.5260,  0.4688,  1.7672]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0335,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(71.2374, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 12.3240, -50.0864,  62.5601],\n",
      "        [-28.4106, -23.5819,  81.0596]])\n",
      "tensor([0.5251, 0.3361])\n",
      "Epoch: 424\n",
      "Loss: tensor(71.2374, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5238,  0.5339,  1.3835],\n",
      "        [-0.5258,  0.4691,  1.7664]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(71.0925, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 12.1609, -49.9087,  62.5169],\n",
      "        [-28.3343, -23.6031,  80.9789]])\n",
      "tensor([0.5235, 0.3361])\n",
      "Epoch: 425\n",
      "Loss: tensor(71.0925, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5239,  0.5344,  1.3829],\n",
      "        [-0.5255,  0.4693,  1.7656]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(70.9479, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 11.9993, -49.7316,  62.4740],\n",
      "        [-28.2582, -23.6239,  80.8983]])\n",
      "tensor([0.5219, 0.3362])\n",
      "Epoch: 426\n",
      "Loss: tensor(70.9479, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5240,  0.5349,  1.3822],\n",
      "        [-0.5252,  0.4695,  1.7648]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(70.8038, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 11.8392, -49.5553,  62.4312],\n",
      "        [-28.1824, -23.6440,  80.8180]])\n",
      "tensor([0.5204, 0.3363])\n",
      "Epoch: 427\n",
      "Loss: tensor(70.8038, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5242,  0.5354,  1.3816],\n",
      "        [-0.5249,  0.4698,  1.7640]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(70.6601, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 11.6797, -49.3802,  62.3881],\n",
      "        [-28.1075, -23.6646,  80.7374]])\n",
      "tensor([0.5189, 0.3363])\n",
      "Epoch: 428\n",
      "Loss: tensor(70.6601, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5243,  0.5359,  1.3810],\n",
      "        [-0.5246,  0.4700,  1.7632]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(70.5169, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 11.5217, -49.2060,  62.3451],\n",
      "        [-28.0325, -23.6841,  80.6573]])\n",
      "tensor([0.5173, 0.3364])\n",
      "Epoch: 429\n",
      "Loss: tensor(70.5169, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5244,  0.5364,  1.3804],\n",
      "        [-0.5244,  0.4702,  1.7624]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(70.3741, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 11.3642, -49.0330,  62.3018],\n",
      "        [-27.9585, -23.7042,  80.5769]])\n",
      "tensor([0.5158, 0.3364])\n",
      "Epoch: 430\n",
      "Loss: tensor(70.3741, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5245,  0.5369,  1.3797],\n",
      "        [-0.5241,  0.4705,  1.7616]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(70.2316, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 11.2077, -48.8614,  62.2584],\n",
      "        [-27.8845, -23.7238,  80.4966]])\n",
      "tensor([0.5143, 0.3365])\n",
      "Epoch: 431\n",
      "Loss: tensor(70.2316, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5246,  0.5374,  1.3791],\n",
      "        [-0.5238,  0.4707,  1.7608]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(70.0896, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 11.0526, -48.6902,  62.2150],\n",
      "        [-27.8112, -23.7431,  80.4165]])\n",
      "tensor([0.5128, 0.3365])\n",
      "Epoch: 432\n",
      "Loss: tensor(70.0896, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5247,  0.5379,  1.3785],\n",
      "        [-0.5235,  0.4710,  1.7600]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(69.9481, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 10.8989, -48.5197,  62.1719],\n",
      "        [-27.7376, -23.7618,  80.3367]])\n",
      "tensor([0.5113, 0.3366])\n",
      "Epoch: 433\n",
      "Loss: tensor(69.9481, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5248,  0.5384,  1.3779],\n",
      "        [-0.5232,  0.4712,  1.7592]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(69.8069, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 10.7456, -48.3507,  62.1283],\n",
      "        [-27.6650, -23.7806,  80.2569]])\n",
      "tensor([0.5098, 0.3366])\n",
      "Epoch: 434\n",
      "Loss: tensor(69.8069, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5249,  0.5388,  1.3773],\n",
      "        [-0.5230,  0.4714,  1.7584]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(69.6661, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 10.5934, -48.1828,  62.0846],\n",
      "        [-27.5925, -23.7990,  80.1770]])\n",
      "tensor([0.5083, 0.3367])\n",
      "Epoch: 435\n",
      "Loss: tensor(69.6661, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5250,  0.5393,  1.3766],\n",
      "        [-0.5227,  0.4717,  1.7576]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(69.5258, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 10.4430, -48.0149,  62.0415],\n",
      "        [-27.5205, -23.8171,  80.0974]])\n",
      "tensor([0.5068, 0.3367])\n",
      "Epoch: 436\n",
      "Loss: tensor(69.5258, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5251,  0.5398,  1.3760],\n",
      "        [-0.5224,  0.4719,  1.7568]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(69.3859, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 10.2937, -47.8477,  61.9983],\n",
      "        [-27.4484, -23.8344,  80.0182]])\n",
      "tensor([0.5054, 0.3367])\n",
      "Epoch: 437\n",
      "Loss: tensor(69.3859, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5253,  0.5403,  1.3754],\n",
      "        [-0.5221,  0.4721,  1.7560]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(69.2463, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 10.1445, -47.6827,  61.9545],\n",
      "        [-27.3764, -23.8513,  79.9392]])\n",
      "tensor([0.5039, 0.3368])\n",
      "Epoch: 438\n",
      "Loss: tensor(69.2463, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5254,  0.5408,  1.3748],\n",
      "        [-0.5219,  0.4724,  1.7552]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(69.1072, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  9.9967, -47.5180,  61.9109],\n",
      "        [-27.3059, -23.8691,  79.8595]])\n",
      "tensor([0.5025, 0.3368])\n",
      "Epoch: 439\n",
      "Loss: tensor(69.1072, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5255,  0.5412,  1.3742],\n",
      "        [-0.5216,  0.4726,  1.7544]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(68.9684, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  9.8502, -47.3541,  61.8674],\n",
      "        [-27.2350, -23.8860,  79.7804]])\n",
      "tensor([0.5010, 0.3368])\n",
      "Epoch: 440\n",
      "Loss: tensor(68.9684, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5256,  0.5417,  1.3735],\n",
      "        [-0.5213,  0.4729,  1.7536]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(68.8301, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  9.7037, -47.1921,  61.8231],\n",
      "        [-27.1653, -23.9033,  79.7010]])\n",
      "tensor([0.4996, 0.3369])\n",
      "Epoch: 441\n",
      "Loss: tensor(68.8301, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5256,  0.5422,  1.3729],\n",
      "        [-0.5210,  0.4731,  1.7528]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(68.6921, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  9.5597, -47.0294,  61.7798],\n",
      "        [-27.0946, -23.9190,  79.6224]])\n",
      "tensor([0.4981, 0.3369])\n",
      "Epoch: 442\n",
      "Loss: tensor(68.6921, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5257,  0.5426,  1.3723],\n",
      "        [-0.5208,  0.4733,  1.7520]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0336,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(68.5546, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  9.4156, -46.8687,  61.7358],\n",
      "        [-27.0247, -23.9349,  79.5438]])\n",
      "tensor([0.4967, 0.3369])\n",
      "Epoch: 443\n",
      "Loss: tensor(68.5546, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5258,  0.5431,  1.3717],\n",
      "        [-0.5205,  0.4736,  1.7512]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(68.4174, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  9.2723, -46.7092,  61.6916],\n",
      "        [-26.9555, -23.9510,  79.4649]])\n",
      "tensor([0.4953, 0.3369])\n",
      "Epoch: 444\n",
      "Loss: tensor(68.4174, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5259,  0.5436,  1.3711],\n",
      "        [-0.5202,  0.4738,  1.7504]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(68.2805, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  9.1301, -46.5502,  61.6474],\n",
      "        [-26.8869, -23.9670,  79.3860]])\n",
      "tensor([0.4939, 0.3370])\n",
      "Epoch: 445\n",
      "Loss: tensor(68.2805, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5260,  0.5440,  1.3704],\n",
      "        [-0.5200,  0.4741,  1.7496]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(68.1442, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  8.9893, -46.3920,  61.6035],\n",
      "        [-26.8180, -23.9821,  79.3076]])\n",
      "tensor([0.4925, 0.3370])\n",
      "Epoch: 446\n",
      "Loss: tensor(68.1442, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5261,  0.5445,  1.3698],\n",
      "        [-0.5197,  0.4743,  1.7488]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(68.0081, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  8.8491, -46.2350,  61.5592],\n",
      "        [-26.7496, -23.9971,  79.2292]])\n",
      "tensor([0.4911, 0.3370])\n",
      "Epoch: 447\n",
      "Loss: tensor(68.0081, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5262,  0.5450,  1.3692],\n",
      "        [-0.5194,  0.4745,  1.7480]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(67.8725, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  8.7105, -46.0779,  61.5154],\n",
      "        [-26.6816, -24.0120,  79.1509]])\n",
      "tensor([0.4897, 0.3370])\n",
      "Epoch: 448\n",
      "Loss: tensor(67.8725, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5263,  0.5454,  1.3686],\n",
      "        [-0.5192,  0.4748,  1.7472]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(67.7372, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  8.5729, -45.9220,  61.4714],\n",
      "        [-26.6148, -24.0275,  79.0721]])\n",
      "tensor([0.4883, 0.3370])\n",
      "Epoch: 449\n",
      "Loss: tensor(67.7372, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5264,  0.5459,  1.3680],\n",
      "        [-0.5189,  0.4750,  1.7464]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(67.6024, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  8.4353, -45.7678,  61.4269],\n",
      "        [-26.5475, -24.0419,  78.9940]])\n",
      "tensor([0.4870, 0.3370])\n",
      "Epoch: 450\n",
      "Loss: tensor(67.6024, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5265,  0.5463,  1.3674],\n",
      "        [-0.5186,  0.4753,  1.7456]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(67.4678, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  8.2999, -45.6131,  61.3831],\n",
      "        [-26.4800, -24.0555,  78.9163]])\n",
      "tensor([0.4856, 0.3370])\n",
      "Epoch: 451\n",
      "Loss: tensor(67.4678, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5265,  0.5468,  1.3668],\n",
      "        [-0.5184,  0.4755,  1.7448]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4660], grad_fn=<SubBackward0>)\n",
      "tensor(67.3336, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  8.1651, -45.4596,  61.3391],\n",
      "        [-26.4133, -24.0693,  78.8384]])\n",
      "tensor([0.4842, 0.3371])\n",
      "Epoch: 452\n",
      "Loss: tensor(67.3336, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5266,  0.5473,  1.3661],\n",
      "        [-0.5181,  0.4757,  1.7441]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(67.1998, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  8.0309, -45.3073,  61.2948],\n",
      "        [-26.3471, -24.0830,  78.7604]])\n",
      "tensor([0.4829, 0.3371])\n",
      "Epoch: 453\n",
      "Loss: tensor(67.1998, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5267,  0.5477,  1.3655],\n",
      "        [-0.5178,  0.4760,  1.7433]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(67.0664, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  7.8976, -45.1559,  61.2505],\n",
      "        [-26.2812, -24.0966,  78.6826]])\n",
      "tensor([0.4816, 0.3371])\n",
      "Epoch: 454\n",
      "Loss: tensor(67.0664, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5268,  0.5482,  1.3649],\n",
      "        [-0.5176,  0.4762,  1.7425]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(66.9334, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  7.7651, -45.0056,  61.2059],\n",
      "        [-26.2157, -24.1098,  78.6049]])\n",
      "tensor([0.4802, 0.3371])\n",
      "Epoch: 455\n",
      "Loss: tensor(66.9334, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5269,  0.5486,  1.3643],\n",
      "        [-0.5173,  0.4765,  1.7417]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(66.8007, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  7.6340, -44.8554,  61.1618],\n",
      "        [-26.1504, -24.1227,  78.5273]])\n",
      "tensor([0.4789, 0.3371])\n",
      "Epoch: 456\n",
      "Loss: tensor(66.8007, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5269,  0.5491,  1.3637],\n",
      "        [-0.5171,  0.4767,  1.7409]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(66.6683, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  7.5026, -44.7072,  61.1168],\n",
      "        [-26.0856, -24.1357,  78.4498]])\n",
      "tensor([0.4776, 0.3371])\n",
      "Epoch: 457\n",
      "Loss: tensor(66.6683, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5270,  0.5495,  1.3631],\n",
      "        [-0.5168,  0.4769,  1.7401]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(66.5363, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  7.3729, -44.5593,  61.0722],\n",
      "        [-26.0213, -24.1484,  78.3722]])\n",
      "tensor([0.4762, 0.3370])\n",
      "Epoch: 458\n",
      "Loss: tensor(66.5363, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5271,  0.5500,  1.3625],\n",
      "        [-0.5165,  0.4772,  1.7393]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(66.4046, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  7.2446, -44.4113,  61.0280],\n",
      "        [-25.9563, -24.1601,  78.2953]])\n",
      "tensor([0.4749, 0.3371])\n",
      "Epoch: 459\n",
      "Loss: tensor(66.4046, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5272,  0.5504,  1.3619],\n",
      "        [-0.5163,  0.4774,  1.7386]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(66.2734, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  7.1169, -44.2648,  60.9835],\n",
      "        [-25.8919, -24.1718,  78.2183]])\n",
      "tensor([0.4736, 0.3370])\n",
      "Epoch: 460\n",
      "Loss: tensor(66.2734, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5272,  0.5508,  1.3613],\n",
      "        [-0.5160,  0.4777,  1.7378]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(66.1424, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  6.9895, -44.1196,  60.9385],\n",
      "        [-25.8282, -24.1838,  78.1412]])\n",
      "tensor([0.4723, 0.3370])\n",
      "Epoch: 461\n",
      "Loss: tensor(66.1424, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5273,  0.5513,  1.3606],\n",
      "        [-0.5158,  0.4779,  1.7370]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(66.0119, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  6.8635, -43.9745,  60.8939],\n",
      "        [-25.7647, -24.1951,  78.0644]])\n",
      "tensor([0.4710, 0.3370])\n",
      "Epoch: 462\n",
      "Loss: tensor(66.0119, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5274,  0.5517,  1.3600],\n",
      "        [-0.5155,  0.4781,  1.7362]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(65.8817, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  6.7383, -43.8304,  60.8493],\n",
      "        [-25.7016, -24.2064,  77.9875]])\n",
      "tensor([0.4698, 0.3370])\n",
      "Epoch: 463\n",
      "Loss: tensor(65.8817, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5274,  0.5522,  1.3594],\n",
      "        [-0.5152,  0.4784,  1.7354]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0337,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(65.7518, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  6.6143, -43.6868,  60.8048],\n",
      "        [-25.6389, -24.2177,  77.9106]])\n",
      "tensor([0.4685, 0.3370])\n",
      "Epoch: 464\n",
      "Loss: tensor(65.7518, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5275,  0.5526,  1.3588],\n",
      "        [-0.5150,  0.4786,  1.7347]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(65.6222, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  6.4903, -43.5447,  60.7597],\n",
      "        [-25.5764, -24.2284,  77.8340]])\n",
      "tensor([0.4672, 0.3370])\n",
      "Epoch: 465\n",
      "Loss: tensor(65.6222, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5276,  0.5530,  1.3582],\n",
      "        [-0.5147,  0.4789,  1.7339]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(65.4930, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  6.3677, -43.4030,  60.7149],\n",
      "        [-25.5143, -24.2393,  77.7573]])\n",
      "tensor([0.4660, 0.3370])\n",
      "Epoch: 466\n",
      "Loss: tensor(65.4930, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5276,  0.5535,  1.3576],\n",
      "        [-0.5145,  0.4791,  1.7331]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(65.3641, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  6.2467, -43.2611,  60.6706],\n",
      "        [-25.4525, -24.2498,  77.6807]])\n",
      "tensor([0.4647, 0.3369])\n",
      "Epoch: 467\n",
      "Loss: tensor(65.3641, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5277,  0.5539,  1.3570],\n",
      "        [-0.5142,  0.4794,  1.7323]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(65.2355, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  6.1257, -43.1210,  60.6256],\n",
      "        [-25.3910, -24.2602,  77.6042]])\n",
      "tensor([0.4635, 0.3369])\n",
      "Epoch: 468\n",
      "Loss: tensor(65.2355, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5278,  0.5543,  1.3564],\n",
      "        [-0.5140,  0.4796,  1.7315]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(65.1074, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  6.0057, -42.9814,  60.5809],\n",
      "        [-25.3292, -24.2697,  77.5283]])\n",
      "tensor([0.4622, 0.3369])\n",
      "Epoch: 469\n",
      "Loss: tensor(65.1074, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5278,  0.5548,  1.3558],\n",
      "        [-0.5137,  0.4798,  1.7308]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(64.9795, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  5.8859, -42.8434,  60.5355],\n",
      "        [-25.2685, -24.2799,  77.4518]])\n",
      "tensor([0.4610, 0.3369])\n",
      "Epoch: 470\n",
      "Loss: tensor(64.9795, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5279,  0.5552,  1.3552],\n",
      "        [-0.5135,  0.4801,  1.7300]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(64.8520, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  5.7676, -42.7053,  60.4906],\n",
      "        [-25.2076, -24.2892,  77.3759]])\n",
      "tensor([0.4597, 0.3368])\n",
      "Epoch: 471\n",
      "Loss: tensor(64.8520, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5279,  0.5556,  1.3546],\n",
      "        [-0.5132,  0.4803,  1.7292]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(64.7248, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  5.6505, -42.5676,  60.4460],\n",
      "        [-25.1475, -24.2989,  77.2996]])\n",
      "tensor([0.4585, 0.3368])\n",
      "Epoch: 472\n",
      "Loss: tensor(64.7248, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5280,  0.5560,  1.3540],\n",
      "        [-0.5130,  0.4806,  1.7284]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(64.5979, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  5.5334, -42.4315,  60.4007],\n",
      "        [-25.0874, -24.3080,  77.2237]])\n",
      "tensor([0.4573, 0.3368])\n",
      "Epoch: 473\n",
      "Loss: tensor(64.5979, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5280,  0.5565,  1.3534],\n",
      "        [-0.5127,  0.4808,  1.7277]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(64.4713, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  5.4176, -42.2955,  60.3558],\n",
      "        [-25.0274, -24.3168,  77.1480]])\n",
      "tensor([0.4561, 0.3368])\n",
      "Epoch: 474\n",
      "Loss: tensor(64.4713, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5281,  0.5569,  1.3528],\n",
      "        [-0.5125,  0.4811,  1.7269]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(64.3451, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  5.3026, -42.1604,  60.3108],\n",
      "        [-24.9683, -24.3260,  77.0720]])\n",
      "tensor([0.4549, 0.3367])\n",
      "Epoch: 475\n",
      "Loss: tensor(64.3451, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5281,  0.5573,  1.3522],\n",
      "        [-0.5122,  0.4813,  1.7261]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(64.2191, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  5.1878, -42.0267,  60.2653],\n",
      "        [-24.9090, -24.3347,  76.9962]])\n",
      "tensor([0.4537, 0.3367])\n",
      "Epoch: 476\n",
      "Loss: tensor(64.2191, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5282,  0.5577,  1.3516],\n",
      "        [-0.5120,  0.4815,  1.7254]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(64.0936, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  5.0748, -41.8926,  60.2206],\n",
      "        [-24.8500, -24.3429,  76.9208]])\n",
      "tensor([0.4525, 0.3366])\n",
      "Epoch: 477\n",
      "Loss: tensor(64.0936, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5283,  0.5581,  1.3510],\n",
      "        [-0.5117,  0.4818,  1.7246]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(63.9683, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  4.9617, -41.7603,  60.1752],\n",
      "        [-24.7911, -24.3507,  76.8455]])\n",
      "tensor([0.4513, 0.3366])\n",
      "Epoch: 478\n",
      "Loss: tensor(63.9683, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5283,  0.5586,  1.3504],\n",
      "        [-0.5115,  0.4820,  1.7238]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(63.8434, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  4.8499, -41.6279,  60.1301],\n",
      "        [-24.7327, -24.3587,  76.7701]])\n",
      "tensor([0.4501, 0.3366])\n",
      "Epoch: 479\n",
      "Loss: tensor(63.8434, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5284,  0.5590,  1.3498],\n",
      "        [-0.5112,  0.4823,  1.7231]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(63.7188, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  4.7386, -41.4969,  60.0847],\n",
      "        [-24.6748, -24.3666,  76.6947]])\n",
      "tensor([0.4490, 0.3365])\n",
      "Epoch: 480\n",
      "Loss: tensor(63.7188, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5284,  0.5594,  1.3492],\n",
      "        [-0.5110,  0.4825,  1.7223]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(63.5944, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  4.6282, -41.3662,  60.0395],\n",
      "        [-24.6171, -24.3744,  76.6194]])\n",
      "tensor([0.4478, 0.3365])\n",
      "Epoch: 481\n",
      "Loss: tensor(63.5944, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5284,  0.5598,  1.3486],\n",
      "        [-0.5107,  0.4828,  1.7215]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4659], grad_fn=<SubBackward0>)\n",
      "tensor(63.4705, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  4.5193, -41.2355,  59.9947],\n",
      "        [-24.5592, -24.3813,  76.5446]])\n",
      "tensor([0.4466, 0.3364])\n",
      "Epoch: 482\n",
      "Loss: tensor(63.4705, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5285,  0.5602,  1.3480],\n",
      "        [-0.5105,  0.4830,  1.7208]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(63.3467, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  4.4098, -41.1070,  59.9489],\n",
      "        [-24.5015, -24.3879,  76.4698]])\n",
      "tensor([0.4455, 0.3364])\n",
      "Epoch: 483\n",
      "Loss: tensor(63.3467, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5285,  0.5606,  1.3474],\n",
      "        [-0.5102,  0.4833,  1.7200]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(63.2234, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  4.3023, -40.9777,  59.9040],\n",
      "        [-24.4449, -24.3955,  76.3946]])\n",
      "tensor([0.4443, 0.3363])\n",
      "Epoch: 484\n",
      "Loss: tensor(63.2234, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5286,  0.5610,  1.3468],\n",
      "        [-0.5100,  0.4835,  1.7192]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(63.1003, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  4.1947, -40.8501,  59.8585],\n",
      "        [-24.3876, -24.4017,  76.3201]])\n",
      "tensor([0.4432, 0.3363])\n",
      "Epoch: 485\n",
      "Loss: tensor(63.1003, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5286,  0.5615,  1.3462],\n",
      "        [-0.5097,  0.4837,  1.7185]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0338,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(62.9775, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  4.0880, -40.7232,  59.8130],\n",
      "        [-24.3308, -24.4078,  76.2456]])\n",
      "tensor([0.4420, 0.3362])\n",
      "Epoch: 486\n",
      "Loss: tensor(62.9775, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5287,  0.5619,  1.3456],\n",
      "        [-0.5095,  0.4840,  1.7177]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(62.8551, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  3.9826, -40.5961,  59.7679],\n",
      "        [-24.2744, -24.4140,  76.1711]])\n",
      "tensor([0.4409, 0.3362])\n",
      "Epoch: 487\n",
      "Loss: tensor(62.8551, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5287,  0.5623,  1.3450],\n",
      "        [-0.5093,  0.4842,  1.7169]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(62.7329, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  3.8773, -40.4707,  59.7223],\n",
      "        [-24.2185, -24.4202,  76.0965]])\n",
      "tensor([0.4398, 0.3361])\n",
      "Epoch: 488\n",
      "Loss: tensor(62.7329, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5287,  0.5627,  1.3444],\n",
      "        [-0.5090,  0.4845,  1.7162]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(62.6110, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  3.7733, -40.3451,  59.6771],\n",
      "        [-24.1629, -24.4263,  76.0220]])\n",
      "tensor([0.4387, 0.3361])\n",
      "Epoch: 489\n",
      "Loss: tensor(62.6110, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5288,  0.5631,  1.3438],\n",
      "        [-0.5088,  0.4847,  1.7154]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(62.4895, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  3.6696, -40.2207,  59.6316],\n",
      "        [-24.1071, -24.4318,  75.9479]])\n",
      "tensor([0.4375, 0.3360])\n",
      "Epoch: 490\n",
      "Loss: tensor(62.4895, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5288,  0.5635,  1.3432],\n",
      "        [-0.5085,  0.4850,  1.7147]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(62.3682, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  3.5668, -40.0968,  59.5861],\n",
      "        [-24.0526, -24.4380,  75.8732]])\n",
      "tensor([0.4364, 0.3360])\n",
      "Epoch: 491\n",
      "Loss: tensor(62.3682, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5288,  0.5639,  1.3426],\n",
      "        [-0.5083,  0.4852,  1.7139]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(62.2473, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  3.4649, -39.9734,  59.5407],\n",
      "        [-23.9976, -24.4435,  75.7991]])\n",
      "tensor([0.4353, 0.3359])\n",
      "Epoch: 492\n",
      "Loss: tensor(62.2473, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5289,  0.5643,  1.3420],\n",
      "        [-0.5081,  0.4855,  1.7131]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(62.1266, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  3.3629, -39.8515,  59.4949],\n",
      "        [-23.9429, -24.4487,  75.7250]])\n",
      "tensor([0.4342, 0.3358])\n",
      "Epoch: 493\n",
      "Loss: tensor(62.1266, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5289,  0.5647,  1.3414],\n",
      "        [-0.5078,  0.4857,  1.7124]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(62.0062, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  3.2625, -39.7294,  59.4495],\n",
      "        [-23.8879, -24.4530,  75.6514]])\n",
      "tensor([0.4331, 0.3358])\n",
      "Epoch: 494\n",
      "Loss: tensor(62.0062, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5289,  0.5651,  1.3408],\n",
      "        [-0.5076,  0.4859,  1.7116]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(61.8861, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  3.1621, -39.6088,  59.4036],\n",
      "        [-23.8340, -24.4582,  75.5774]])\n",
      "tensor([0.4320, 0.3357])\n",
      "Epoch: 495\n",
      "Loss: tensor(61.8861, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5290,  0.5655,  1.3402],\n",
      "        [-0.5073,  0.4862,  1.7109]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(61.7664, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  3.0630, -39.4879,  59.3581],\n",
      "        [-23.7797, -24.4625,  75.5038]])\n",
      "tensor([0.4310, 0.3357])\n",
      "Epoch: 496\n",
      "Loss: tensor(61.7664, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5290,  0.5659,  1.3396],\n",
      "        [-0.5071,  0.4864,  1.7101]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(61.6468, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  2.9642, -39.3683,  59.3123],\n",
      "        [-23.7256, -24.4664,  75.4304]])\n",
      "tensor([0.4299, 0.3356])\n",
      "Epoch: 497\n",
      "Loss: tensor(61.6468, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5290,  0.5663,  1.3390],\n",
      "        [-0.5069,  0.4867,  1.7094]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(61.5277, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  2.8670, -39.2483,  59.2672],\n",
      "        [-23.6733, -24.4720,  75.3560]])\n",
      "tensor([0.4288, 0.3355])\n",
      "Epoch: 498\n",
      "Loss: tensor(61.5277, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5291,  0.5667,  1.3384],\n",
      "        [-0.5066,  0.4869,  1.7086]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(61.4087, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  2.7694, -39.1301,  59.2213],\n",
      "        [-23.6198, -24.4759,  75.2826]])\n",
      "tensor([0.4277, 0.3355])\n",
      "Epoch: 499\n",
      "Loss: tensor(61.4087, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5291,  0.5670,  1.3378],\n",
      "        [-0.5064,  0.4872,  1.7079]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(61.2901, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  2.6728, -39.0122,  59.1755],\n",
      "        [-23.5667, -24.4796,  75.2093]])\n",
      "tensor([0.4267, 0.3354])\n",
      "Epoch: 500\n",
      "Loss: tensor(61.2901, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5291,  0.5674,  1.3372],\n",
      "        [-0.5062,  0.4874,  1.7071]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(61.1717, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  2.5769, -38.8951,  59.1297],\n",
      "        [-23.5135, -24.4828,  75.1364]])\n",
      "tensor([0.4256, 0.3353])\n",
      "Epoch: 501\n",
      "Loss: tensor(61.1717, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5291,  0.5678,  1.3366],\n",
      "        [-0.5059,  0.4877,  1.7064]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(61.0537, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  2.4824, -38.7775,  59.0845],\n",
      "        [-23.4616, -24.4870,  75.0628]])\n",
      "tensor([0.4246, 0.3352])\n",
      "Epoch: 502\n",
      "Loss: tensor(61.0537, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5292,  0.5682,  1.3360],\n",
      "        [-0.5057,  0.4879,  1.7056]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(60.9359, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  2.3883, -38.6610,  59.0390],\n",
      "        [-23.4100, -24.4911,  74.9891]])\n",
      "tensor([0.4235, 0.3352])\n",
      "Epoch: 503\n",
      "Loss: tensor(60.9359, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5292,  0.5686,  1.3355],\n",
      "        [-0.5054,  0.4881,  1.7049]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(60.8184, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  2.2939, -38.5461,  58.9928],\n",
      "        [-23.3579, -24.4944,  74.9161]])\n",
      "tensor([0.4225, 0.3351])\n",
      "Epoch: 504\n",
      "Loss: tensor(60.8184, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5292,  0.5690,  1.3349],\n",
      "        [-0.5052,  0.4884,  1.7041]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(60.7011, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  2.2007, -38.4314,  58.9470],\n",
      "        [-23.3058, -24.4971,  74.8433]])\n",
      "tensor([0.4214, 0.3350])\n",
      "Epoch: 505\n",
      "Loss: tensor(60.7011, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5292,  0.5694,  1.3343],\n",
      "        [-0.5050,  0.4886,  1.7034]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(60.5842, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  2.1079, -38.3174,  58.9010],\n",
      "        [-23.2536, -24.4992,  74.7709]])\n",
      "tensor([0.4204, 0.3349])\n",
      "Epoch: 506\n",
      "Loss: tensor(60.5842, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5293,  0.5697,  1.3337],\n",
      "        [-0.5047,  0.4889,  1.7026]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(60.4675, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  2.0167, -38.2030,  58.8556],\n",
      "        [-23.2027, -24.5022,  74.6980]])\n",
      "tensor([0.4194, 0.3349])\n",
      "Epoch: 507\n",
      "Loss: tensor(60.4675, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5293,  0.5701,  1.3331],\n",
      "        [-0.5045,  0.4891,  1.7019]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(60.3511, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  1.9251, -38.0904,  58.8095],\n",
      "        [-23.1517, -24.5050,  74.6251]])\n",
      "tensor([0.4184, 0.3348])\n",
      "Epoch: 508\n",
      "Loss: tensor(60.3511, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5293,  0.5705,  1.3325],\n",
      "        [-0.5043,  0.4894,  1.7011]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0339,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(60.2350, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  1.8353, -37.9771,  58.7642],\n",
      "        [-23.1008, -24.5073,  74.5526]])\n",
      "tensor([0.4174, 0.3347])\n",
      "Epoch: 509\n",
      "Loss: tensor(60.2350, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5293,  0.5709,  1.3319],\n",
      "        [-0.5041,  0.4896,  1.7004]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(60.1192, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  1.7452, -37.8656,  58.7181],\n",
      "        [-23.0502, -24.5093,  74.4801]])\n",
      "tensor([0.4163, 0.3346])\n",
      "Epoch: 510\n",
      "Loss: tensor(60.1192, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5293,  0.5713,  1.3313],\n",
      "        [-0.5038,  0.4899,  1.6996]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(60.0036, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  1.6556, -37.7548,  58.6720],\n",
      "        [-23.0003, -24.5121,  74.4073]])\n",
      "tensor([0.4153, 0.3345])\n",
      "Epoch: 511\n",
      "Loss: tensor(60.0036, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5716,  1.3308],\n",
      "        [-0.5036,  0.4901,  1.6989]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(59.8883, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  1.5668, -37.6442,  58.6260],\n",
      "        [-22.9503, -24.5141,  74.3348]])\n",
      "tensor([0.4143, 0.3344])\n",
      "Epoch: 512\n",
      "Loss: tensor(59.8883, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5720,  1.3302],\n",
      "        [-0.5034,  0.4903,  1.6981]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(59.7732, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  1.4788, -37.5341,  58.5801],\n",
      "        [-22.9005, -24.5157,  74.2626]])\n",
      "tensor([0.4133, 0.3343])\n",
      "Epoch: 513\n",
      "Loss: tensor(59.7732, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5724,  1.3296],\n",
      "        [-0.5031,  0.4906,  1.6974]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(59.6584, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  1.3917, -37.4243,  58.5343],\n",
      "        [-22.8516, -24.5183,  74.1898]])\n",
      "tensor([0.4123, 0.3342])\n",
      "Epoch: 514\n",
      "Loss: tensor(59.6584, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5728,  1.3290],\n",
      "        [-0.5029,  0.4908,  1.6967]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(59.5440, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  1.3055, -37.3150,  58.4887],\n",
      "        [-22.8014, -24.5189,  74.1182]])\n",
      "tensor([0.4114, 0.3342])\n",
      "Epoch: 515\n",
      "Loss: tensor(59.5440, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5731,  1.3284],\n",
      "        [-0.5027,  0.4911,  1.6959]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(59.4298, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  1.2196, -37.2062,  58.4429],\n",
      "        [-22.7524, -24.5204,  74.0462]])\n",
      "tensor([0.4104, 0.3341])\n",
      "Epoch: 516\n",
      "Loss: tensor(59.4298, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5735,  1.3278],\n",
      "        [-0.5025,  0.4913,  1.6952]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(59.3158, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  1.1335, -37.0992,  58.3965],\n",
      "        [-22.7030, -24.5211,  73.9744]])\n",
      "tensor([0.4094, 0.3340])\n",
      "Epoch: 517\n",
      "Loss: tensor(59.3158, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5739,  1.3272],\n",
      "        [-0.5022,  0.4916,  1.6944]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(59.2021, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  1.0488, -36.9917,  58.3507],\n",
      "        [-22.6543, -24.5221,  73.9026]])\n",
      "tensor([0.4084, 0.3339])\n",
      "Epoch: 518\n",
      "Loss: tensor(59.2021, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5743,  1.3267],\n",
      "        [-0.5020,  0.4918,  1.6937]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(59.0887, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  0.9641, -36.8856,  58.3044],\n",
      "        [-22.6052, -24.5224,  73.8311]])\n",
      "tensor([0.4074, 0.3338])\n",
      "Epoch: 519\n",
      "Loss: tensor(59.0887, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5746,  1.3261],\n",
      "        [-0.5018,  0.4921,  1.6930]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(58.9755, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  0.8806, -36.7792,  58.2585],\n",
      "        [-22.5571, -24.5235,  73.7593]])\n",
      "tensor([0.4065, 0.3337])\n",
      "Epoch: 520\n",
      "Loss: tensor(58.9755, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5750,  1.3255],\n",
      "        [-0.5015,  0.4923,  1.6922]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(58.8626, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  0.7976, -36.6735,  58.2126],\n",
      "        [-22.5088, -24.5236,  73.6879]])\n",
      "tensor([0.4055, 0.3336])\n",
      "Epoch: 521\n",
      "Loss: tensor(58.8626, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5754,  1.3249],\n",
      "        [-0.5013,  0.4926,  1.6915]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(58.7499, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  0.7155, -36.5680,  58.1668],\n",
      "        [-22.4609, -24.5240,  73.6163]])\n",
      "tensor([0.4046, 0.3335])\n",
      "Epoch: 522\n",
      "Loss: tensor(58.7499, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5757,  1.3243],\n",
      "        [-0.5011,  0.4928,  1.6907]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(58.6375, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  0.6339, -36.4634,  58.1209],\n",
      "        [-22.4135, -24.5245,  73.5448]])\n",
      "tensor([0.4036, 0.3334])\n",
      "Epoch: 523\n",
      "Loss: tensor(58.6375, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5761,  1.3237],\n",
      "        [-0.5009,  0.4930,  1.6900]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(58.5254, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  0.5525, -36.3596,  58.0747],\n",
      "        [-22.3663, -24.5249,  73.4732]])\n",
      "tensor([0.4027, 0.3333])\n",
      "Epoch: 524\n",
      "Loss: tensor(58.5254, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5765,  1.3232],\n",
      "        [-0.5006,  0.4933,  1.6893]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(58.4135, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  0.4719, -36.2561,  58.0288],\n",
      "        [-22.3193, -24.5251,  73.4018]])\n",
      "tensor([0.4017, 0.3332])\n",
      "Epoch: 525\n",
      "Loss: tensor(58.4135, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5768,  1.3226],\n",
      "        [-0.5004,  0.4935,  1.6885]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(58.3018, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  0.3916, -36.1534,  57.9826],\n",
      "        [-22.2719, -24.5245,  73.3308]])\n",
      "tensor([0.4008, 0.3331])\n",
      "Epoch: 526\n",
      "Loss: tensor(58.3018, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5772,  1.3220],\n",
      "        [-0.5002,  0.4938,  1.6878]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(58.1905, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  0.3127, -36.0504,  57.9369],\n",
      "        [-22.2250, -24.5241,  73.2598]])\n",
      "tensor([0.3999, 0.3330])\n",
      "Epoch: 527\n",
      "Loss: tensor(58.1905, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5775,  1.3214],\n",
      "        [-0.5000,  0.4940,  1.6871]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(58.0793, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  0.2337, -35.9488,  57.8908],\n",
      "        [-22.1780, -24.5233,  73.1890]])\n",
      "tensor([0.3990, 0.3329])\n",
      "Epoch: 528\n",
      "Loss: tensor(58.0793, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5779,  1.3208],\n",
      "        [-0.4998,  0.4943,  1.6863]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(57.9685, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  0.1556, -35.8472,  57.8449],\n",
      "        [-22.1318, -24.5228,  73.1180]])\n",
      "tensor([0.3980, 0.3328])\n",
      "Epoch: 529\n",
      "Loss: tensor(57.9685, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5783,  1.3203],\n",
      "        [-0.4995,  0.4945,  1.6856]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(57.8579, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[  0.0779, -35.7463,  57.7989],\n",
      "        [-22.0863, -24.5229,  73.0466]])\n",
      "tensor([0.3971, 0.3327])\n",
      "Epoch: 530\n",
      "Loss: tensor(57.8579, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5786,  1.3197],\n",
      "        [-0.4993,  0.4948,  1.6849]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(57.7474, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ 3.1281e-04, -3.5646e+01,  5.7753e+01],\n",
      "        [-2.2041e+01, -2.4522e+01,  7.2976e+01]])\n",
      "tensor([0.3962, 0.3326])\n",
      "Epoch: 531\n",
      "Loss: tensor(57.7474, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5790,  1.3191],\n",
      "        [-0.4991,  0.4950,  1.6842]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(57.6373, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -0.0768, -35.5473,  57.7062],\n",
      "        [-21.9951, -24.5215,  72.9048]])\n",
      "tensor([0.3953, 0.3325])\n",
      "Epoch: 532\n",
      "Loss: tensor(57.6373, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5793,  1.3185],\n",
      "        [-0.4989,  0.4953,  1.6834]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(57.5274, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -0.1524, -35.4475,  57.6604],\n",
      "        [-21.9493, -24.5201,  72.8343]])\n",
      "tensor([0.3944, 0.3324])\n",
      "Epoch: 533\n",
      "Loss: tensor(57.5274, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5797,  1.3180],\n",
      "        [-0.4987,  0.4955,  1.6827]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0340,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(57.4178, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -0.2281, -35.3490,  57.6142],\n",
      "        [-21.9045, -24.5195,  72.7633]])\n",
      "tensor([0.3935, 0.3322])\n",
      "Epoch: 534\n",
      "Loss: tensor(57.4178, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5800,  1.3174],\n",
      "        [-0.4984,  0.4957,  1.6820]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(57.3084, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -0.3026, -35.2502,  57.5684],\n",
      "        [-21.8591, -24.5179,  72.6930]])\n",
      "tensor([0.3926, 0.3321])\n",
      "Epoch: 535\n",
      "Loss: tensor(57.3084, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5804,  1.3168],\n",
      "        [-0.4982,  0.4960,  1.6812]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(57.1993, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -0.3769, -35.1524,  57.5224],\n",
      "        [-21.8142, -24.5163,  72.6226]])\n",
      "tensor([0.3917, 0.3320])\n",
      "Epoch: 536\n",
      "Loss: tensor(57.1993, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5807,  1.3162],\n",
      "        [-0.4980,  0.4962,  1.6805]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(57.0904, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -0.4507, -35.0551,  57.4764],\n",
      "        [-21.7692, -24.5145,  72.5524]])\n",
      "tensor([0.3908, 0.3319])\n",
      "Epoch: 537\n",
      "Loss: tensor(57.0904, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5811,  1.3157],\n",
      "        [-0.4978,  0.4965,  1.6798]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(56.9817, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -0.5238, -34.9582,  57.4304],\n",
      "        [-21.7240, -24.5120,  72.4826]])\n",
      "tensor([0.3899, 0.3318])\n",
      "Epoch: 538\n",
      "Loss: tensor(56.9817, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5814,  1.3151],\n",
      "        [-0.4976,  0.4967,  1.6791]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(56.8733, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -0.5965, -34.8618,  57.3844],\n",
      "        [-21.6798, -24.5101,  72.4125]])\n",
      "tensor([0.3891, 0.3317])\n",
      "Epoch: 539\n",
      "Loss: tensor(56.8733, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5818,  1.3145],\n",
      "        [-0.4973,  0.4970,  1.6783]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(56.7651, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -0.6691, -34.7665,  57.3380],\n",
      "        [-21.6353, -24.5077,  72.3426]])\n",
      "tensor([0.3882, 0.3316])\n",
      "Epoch: 540\n",
      "Loss: tensor(56.7651, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5821,  1.3139],\n",
      "        [-0.4971,  0.4972,  1.6776]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(56.6572, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -0.7411, -34.6715,  57.2918],\n",
      "        [-21.5920, -24.5063,  72.2721]])\n",
      "tensor([0.3873, 0.3314])\n",
      "Epoch: 541\n",
      "Loss: tensor(56.6572, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5825,  1.3134],\n",
      "        [-0.4969,  0.4975,  1.6769]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4657], grad_fn=<SubBackward0>)\n",
      "tensor(56.5495, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -0.8125, -34.5768,  57.2456],\n",
      "        [-21.5482, -24.5042,  72.2022]])\n",
      "tensor([0.3864, 0.3313])\n",
      "Epoch: 542\n",
      "Loss: tensor(56.5495, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5828,  1.3128],\n",
      "        [-0.4967,  0.4977,  1.6762]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(56.4421, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -0.8830, -34.4822,  57.1996],\n",
      "        [-21.5047, -24.5017,  72.1323]])\n",
      "tensor([0.3856, 0.3312])\n",
      "Epoch: 543\n",
      "Loss: tensor(56.4421, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5295,  0.5832,  1.3122],\n",
      "        [-0.4965,  0.4979,  1.6754]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(56.3348, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -0.9535, -34.3888,  57.1532],\n",
      "        [-21.4615, -24.4993,  72.0625]])\n",
      "tensor([0.3847, 0.3311])\n",
      "Epoch: 544\n",
      "Loss: tensor(56.3348, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5835,  1.3116],\n",
      "        [-0.4963,  0.4982,  1.6747]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(56.2279, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.0229, -34.2952,  57.1073],\n",
      "        [-21.4178, -24.4961,  71.9931]])\n",
      "tensor([0.3839, 0.3310])\n",
      "Epoch: 545\n",
      "Loss: tensor(56.2279, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5839,  1.3111],\n",
      "        [-0.4961,  0.4984,  1.6740]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(56.1211, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.0924, -34.2028,  57.0609],\n",
      "        [-21.3746, -24.4931,  71.9237]])\n",
      "tensor([0.3830, 0.3308])\n",
      "Epoch: 546\n",
      "Loss: tensor(56.1211, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5842,  1.3105],\n",
      "        [-0.4958,  0.4987,  1.6733]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(56.0146, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.1613, -34.1107,  57.0146],\n",
      "        [-21.3314, -24.4896,  71.8544]])\n",
      "tensor([0.3822, 0.3307])\n",
      "Epoch: 547\n",
      "Loss: tensor(56.0146, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5845,  1.3099],\n",
      "        [-0.4956,  0.4989,  1.6726]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(55.9083, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.2290, -34.0184,  56.9687],\n",
      "        [-21.2888, -24.4867,  71.7849]])\n",
      "tensor([0.3813, 0.3306])\n",
      "Epoch: 548\n",
      "Loss: tensor(55.9083, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5849,  1.3094],\n",
      "        [-0.4954,  0.4992,  1.6719]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(55.8022, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.2970, -33.9273,  56.9223],\n",
      "        [-21.2465, -24.4837,  71.7154]])\n",
      "tensor([0.3805, 0.3305])\n",
      "Epoch: 549\n",
      "Loss: tensor(55.8022, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5852,  1.3088],\n",
      "        [-0.4952,  0.4994,  1.6711]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(55.6964, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.3639, -33.8362,  56.8763],\n",
      "        [-21.2046, -24.4808,  71.6459]])\n",
      "tensor([0.3797, 0.3303])\n",
      "Epoch: 550\n",
      "Loss: tensor(55.6964, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5856,  1.3082],\n",
      "        [-0.4950,  0.4997,  1.6704]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(55.5909, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.4303, -33.7453,  56.8304],\n",
      "        [-21.1625, -24.4774,  71.5768]])\n",
      "tensor([0.3788, 0.3302])\n",
      "Epoch: 551\n",
      "Loss: tensor(55.5909, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5294,  0.5859,  1.3077],\n",
      "        [-0.4948,  0.4999,  1.6697]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(55.4855, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.4964, -33.6552,  56.7842],\n",
      "        [-21.1201, -24.4732,  71.5080]])\n",
      "tensor([0.3780, 0.3301])\n",
      "Epoch: 552\n",
      "Loss: tensor(55.4855, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5293,  0.5862,  1.3071],\n",
      "        [-0.4946,  0.5002,  1.6690]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(55.3804, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.5616, -33.5651,  56.7385],\n",
      "        [-21.0787, -24.4699,  71.4388]])\n",
      "tensor([0.3772, 0.3300])\n",
      "Epoch: 553\n",
      "Loss: tensor(55.3804, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5293,  0.5866,  1.3065],\n",
      "        [-0.4944,  0.5004,  1.6683]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(55.2755, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.6272, -33.4766,  56.6919],\n",
      "        [-21.0373, -24.4664,  71.3697]])\n",
      "tensor([0.3764, 0.3298])\n",
      "Epoch: 554\n",
      "Loss: tensor(55.2755, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5293,  0.5869,  1.3060],\n",
      "        [-0.4941,  0.5006,  1.6676]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(55.1709, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.6923, -33.3883,  56.6456],\n",
      "        [-20.9959, -24.4624,  71.3008]])\n",
      "tensor([0.3755, 0.3297])\n",
      "Epoch: 555\n",
      "Loss: tensor(55.1709, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5293,  0.5872,  1.3054],\n",
      "        [-0.4939,  0.5009,  1.6668]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(55.0664, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.7563, -33.2998,  56.5996],\n",
      "        [-20.9543, -24.4581,  71.2322]])\n",
      "tensor([0.3747, 0.3296])\n",
      "Epoch: 556\n",
      "Loss: tensor(55.0664, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5293,  0.5876,  1.3048],\n",
      "        [-0.4937,  0.5011,  1.6661]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(54.9622, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.8197, -33.2115,  56.5537],\n",
      "        [-20.9134, -24.4540,  71.1635]])\n",
      "tensor([0.3739, 0.3294])\n",
      "Epoch: 557\n",
      "Loss: tensor(54.9622, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5293,  0.5879,  1.3043],\n",
      "        [-0.4935,  0.5014,  1.6654]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(54.8582, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.8832, -33.1246,  56.5073],\n",
      "        [-20.8727, -24.4499,  71.0947]])\n",
      "tensor([0.3731, 0.3293])\n",
      "Epoch: 558\n",
      "Loss: tensor(54.8582, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5292,  0.5882,  1.3037],\n",
      "        [-0.4933,  0.5016,  1.6647]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(54.7544, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -1.9460, -33.0376,  56.4612],\n",
      "        [-20.8320, -24.4456,  71.0261]])\n",
      "tensor([0.3723, 0.3292])\n",
      "Epoch: 559\n",
      "Loss: tensor(54.7544, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5292,  0.5886,  1.3031],\n",
      "        [-0.4931,  0.5019,  1.6640]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0341,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(54.6509, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.0083, -32.9510,  56.4151],\n",
      "        [-20.7914, -24.4409,  70.9578]])\n",
      "tensor([0.3715, 0.3290])\n",
      "Epoch: 560\n",
      "Loss: tensor(54.6509, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5292,  0.5889,  1.3026],\n",
      "        [-0.4929,  0.5021,  1.6633]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(54.5476, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.0698, -32.8646,  56.3691],\n",
      "        [-20.7504, -24.4356,  70.8898]])\n",
      "tensor([0.3707, 0.3289])\n",
      "Epoch: 561\n",
      "Loss: tensor(54.5476, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5292,  0.5892,  1.3020],\n",
      "        [-0.4927,  0.5024,  1.6626]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(54.4445, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.1316, -32.7794,  56.3228],\n",
      "        [-20.7101, -24.4308,  70.8216]])\n",
      "tensor([0.3699, 0.3288])\n",
      "Epoch: 562\n",
      "Loss: tensor(54.4445, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5292,  0.5896,  1.3014],\n",
      "        [-0.4925,  0.5026,  1.6619]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(54.3416, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.1927, -32.6944,  56.2765],\n",
      "        [-20.6700, -24.4259,  70.7533]])\n",
      "tensor([0.3692, 0.3286])\n",
      "Epoch: 563\n",
      "Loss: tensor(54.3416, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5291,  0.5899,  1.3009],\n",
      "        [-0.4923,  0.5028,  1.6612]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(54.2389, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.2533, -32.6098,  56.2303],\n",
      "        [-20.6302, -24.4211,  70.6851]])\n",
      "tensor([0.3684, 0.3285])\n",
      "Epoch: 564\n",
      "Loss: tensor(54.2389, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5291,  0.5902,  1.3003],\n",
      "        [-0.4921,  0.5031,  1.6605]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(54.1365, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.3131, -32.5251,  56.1844],\n",
      "        [-20.5901, -24.4155,  70.6174]])\n",
      "tensor([0.3676, 0.3283])\n",
      "Epoch: 565\n",
      "Loss: tensor(54.1365, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5291,  0.5905,  1.2998],\n",
      "        [-0.4919,  0.5033,  1.6598]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(54.0343, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.3726, -32.4411,  56.1383],\n",
      "        [-20.5513, -24.4111,  70.5489]])\n",
      "tensor([0.3668, 0.3282])\n",
      "Epoch: 566\n",
      "Loss: tensor(54.0343, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5291,  0.5909,  1.2992],\n",
      "        [-0.4917,  0.5036,  1.6590]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(53.9323, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.4314, -32.3573,  56.0923],\n",
      "        [-20.5117, -24.4056,  70.4811]])\n",
      "tensor([0.3661, 0.3281])\n",
      "Epoch: 567\n",
      "Loss: tensor(53.9323, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5290,  0.5912,  1.2986],\n",
      "        [-0.4915,  0.5038,  1.6583]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(53.8305, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.4899, -32.2740,  56.0464],\n",
      "        [-20.4722, -24.3999,  70.4134]])\n",
      "tensor([0.3653, 0.3279])\n",
      "Epoch: 568\n",
      "Loss: tensor(53.8305, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5290,  0.5915,  1.2981],\n",
      "        [-0.4912,  0.5041,  1.6576]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(53.7290, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.5481, -32.1913,  56.0003],\n",
      "        [-20.4336, -24.3948,  70.3454]])\n",
      "tensor([0.3645, 0.3278])\n",
      "Epoch: 569\n",
      "Loss: tensor(53.7290, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5290,  0.5918,  1.2975],\n",
      "        [-0.4910,  0.5043,  1.6569]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(53.6276, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.6060, -32.1091,  55.9541],\n",
      "        [-20.3942, -24.3885,  70.2782]])\n",
      "tensor([0.3638, 0.3276])\n",
      "Epoch: 570\n",
      "Loss: tensor(53.6276, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5290,  0.5921,  1.2969],\n",
      "        [-0.4908,  0.5046,  1.6562]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(53.5265, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.6637, -32.0275,  55.9078],\n",
      "        [-20.3559, -24.3833,  70.2103]])\n",
      "tensor([0.3630, 0.3275])\n",
      "Epoch: 571\n",
      "Loss: tensor(53.5265, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5289,  0.5925,  1.2964],\n",
      "        [-0.4906,  0.5048,  1.6555]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4656], grad_fn=<SubBackward0>)\n",
      "tensor(53.4255, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.7207, -31.9463,  55.8616],\n",
      "        [-20.3172, -24.3775,  70.1427]])\n",
      "tensor([0.3622, 0.3273])\n",
      "Epoch: 572\n",
      "Loss: tensor(53.4255, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5289,  0.5928,  1.2958],\n",
      "        [-0.4904,  0.5050,  1.6548]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(53.3248, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.7771, -31.8649,  55.8156],\n",
      "        [-20.2795, -24.3723,  70.0748]])\n",
      "tensor([0.3615, 0.3272])\n",
      "Epoch: 573\n",
      "Loss: tensor(53.3248, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5289,  0.5931,  1.2953],\n",
      "        [-0.4902,  0.5053,  1.6541]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(53.2243, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.8334, -31.7846,  55.7693],\n",
      "        [-20.2407, -24.3657,  70.0078]])\n",
      "tensor([0.3607, 0.3271])\n",
      "Epoch: 574\n",
      "Loss: tensor(53.2243, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5289,  0.5934,  1.2947],\n",
      "        [-0.4900,  0.5055,  1.6534]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(53.1241, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.8887, -31.7038,  55.7236],\n",
      "        [-20.2025, -24.3593,  69.9407]])\n",
      "tensor([0.3600, 0.3269])\n",
      "Epoch: 575\n",
      "Loss: tensor(53.1241, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5288,  0.5937,  1.2942],\n",
      "        [-0.4898,  0.5058,  1.6527]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(53.0240, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.9433, -31.6233,  55.6779],\n",
      "        [-20.1644, -24.3530,  69.8735]])\n",
      "tensor([0.3593, 0.3268])\n",
      "Epoch: 576\n",
      "Loss: tensor(53.0240, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5288,  0.5941,  1.2936],\n",
      "        [-0.4896,  0.5060,  1.6520]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(52.9241, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -2.9983, -31.5440,  55.6317],\n",
      "        [-20.1265, -24.3467,  69.8063]])\n",
      "tensor([0.3585, 0.3266])\n",
      "Epoch: 577\n",
      "Loss: tensor(52.9241, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5288,  0.5944,  1.2930],\n",
      "        [-0.4894,  0.5063,  1.6513]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(52.8245, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.0530, -31.4652,  55.5854],\n",
      "        [-20.0890, -24.3402,  69.7393]])\n",
      "tensor([0.3578, 0.3265])\n",
      "Epoch: 578\n",
      "Loss: tensor(52.8245, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5287,  0.5947,  1.2925],\n",
      "        [-0.4892,  0.5065,  1.6506]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(52.7251, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.1074, -31.3870,  55.5390],\n",
      "        [-20.0514, -24.3336,  69.6724]])\n",
      "tensor([0.3571, 0.3263])\n",
      "Epoch: 579\n",
      "Loss: tensor(52.7251, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5287,  0.5950,  1.2919],\n",
      "        [-0.4890,  0.5067,  1.6499]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(52.6258, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.1608, -31.3084,  55.4932],\n",
      "        [-20.0152, -24.3283,  69.6046]])\n",
      "tensor([0.3563, 0.3262])\n",
      "Epoch: 580\n",
      "Loss: tensor(52.6258, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5287,  0.5953,  1.2914],\n",
      "        [-0.4888,  0.5070,  1.6492]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(52.5269, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.2143, -31.2309,  55.4469],\n",
      "        [-19.9774, -24.3206,  69.5384]])\n",
      "tensor([0.3556, 0.3260])\n",
      "Epoch: 581\n",
      "Loss: tensor(52.5269, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5286,  0.5956,  1.2908],\n",
      "        [-0.4886,  0.5072,  1.6485]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(52.4280, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.2666, -31.1527,  55.4012],\n",
      "        [-19.9403, -24.3139,  69.4715]])\n",
      "tensor([0.3549, 0.3259])\n",
      "Epoch: 582\n",
      "Loss: tensor(52.4280, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5286,  0.5959,  1.2903],\n",
      "        [-0.4884,  0.5075,  1.6479]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(52.3294, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.3189, -31.0756,  55.3551],\n",
      "        [-19.9043, -24.3079,  69.4043]])\n",
      "tensor([0.3542, 0.3257])\n",
      "Epoch: 583\n",
      "Loss: tensor(52.3294, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5286,  0.5962,  1.2897],\n",
      "        [-0.4882,  0.5077,  1.6472]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(52.2310, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.3705, -30.9982,  55.3094],\n",
      "        [-19.8674, -24.3008,  69.3377]])\n",
      "tensor([0.3535, 0.3255])\n",
      "Epoch: 584\n",
      "Loss: tensor(52.2310, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5285,  0.5966,  1.2892],\n",
      "        [-0.4880,  0.5080,  1.6465]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(52.1328, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.4229, -30.9229,  55.2628],\n",
      "        [-19.8306, -24.2933,  69.2714]])\n",
      "tensor([0.3527, 0.3254])\n",
      "Epoch: 585\n",
      "Loss: tensor(52.1328, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5285,  0.5969,  1.2886],\n",
      "        [-0.4878,  0.5082,  1.6458]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(52.0348, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.4740, -30.8466,  55.2169],\n",
      "        [-19.7942, -24.2863,  69.2048]])\n",
      "tensor([0.3520, 0.3252])\n",
      "Epoch: 586\n",
      "Loss: tensor(52.0348, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5285,  0.5972,  1.2881],\n",
      "        [-0.4876,  0.5084,  1.6451]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(51.9370, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.5250, -30.7713,  55.1706],\n",
      "        [-19.7577, -24.2787,  69.1386]])\n",
      "tensor([0.3513, 0.3251])\n",
      "Epoch: 587\n",
      "Loss: tensor(51.9370, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5284,  0.5975,  1.2875],\n",
      "        [-0.4874,  0.5087,  1.6444]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0342,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(51.8394, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.5750, -30.6955,  55.1249],\n",
      "        [-19.7214, -24.2711,  69.0724]])\n",
      "tensor([0.3506, 0.3249])\n",
      "Epoch: 588\n",
      "Loss: tensor(51.8394, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5284,  0.5978,  1.2870],\n",
      "        [-0.4872,  0.5089,  1.6437]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(51.7421, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.6251, -30.6207,  55.0789],\n",
      "        [-19.6855, -24.2637,  69.0061]])\n",
      "tensor([0.3499, 0.3248])\n",
      "Epoch: 589\n",
      "Loss: tensor(51.7421, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5284,  0.5981,  1.2864],\n",
      "        [-0.4870,  0.5092,  1.6430]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(51.6449, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.6745, -30.5457,  55.0331],\n",
      "        [-19.6503, -24.2568,  68.9396]])\n",
      "tensor([0.3492, 0.3246])\n",
      "Epoch: 590\n",
      "Loss: tensor(51.6449, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5283,  0.5984,  1.2859],\n",
      "        [-0.4868,  0.5094,  1.6423]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(51.5480, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.7239, -30.4718,  54.9870],\n",
      "        [-19.6142, -24.2488,  68.8737]])\n",
      "tensor([0.3485, 0.3245])\n",
      "Epoch: 591\n",
      "Loss: tensor(51.5480, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5283,  0.5987,  1.2853],\n",
      "        [-0.4866,  0.5097,  1.6416]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(51.4511, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.7735, -30.3987,  54.9405],\n",
      "        [-19.5793, -24.2418,  68.8072]])\n",
      "tensor([0.3479, 0.3243])\n",
      "Epoch: 592\n",
      "Loss: tensor(51.4511, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5283,  0.5990,  1.2848],\n",
      "        [-0.4864,  0.5099,  1.6409]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(51.3546, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.8221, -30.3253,  54.8945],\n",
      "        [-19.5436, -24.2337,  68.7414]])\n",
      "tensor([0.3472, 0.3241])\n",
      "Epoch: 593\n",
      "Loss: tensor(51.3546, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5282,  0.5993,  1.2842],\n",
      "        [-0.4863,  0.5101,  1.6403]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(51.2582, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.8699, -30.2519,  54.8487],\n",
      "        [-19.5078, -24.2251,  68.6759]])\n",
      "tensor([0.3465, 0.3240])\n",
      "Epoch: 594\n",
      "Loss: tensor(51.2582, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5282,  0.5996,  1.2837],\n",
      "        [-0.4861,  0.5104,  1.6396]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(51.1620, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.9176, -30.1790,  54.8028],\n",
      "        [-19.4732, -24.2177,  68.6097]])\n",
      "tensor([0.3458, 0.3238])\n",
      "Epoch: 595\n",
      "Loss: tensor(51.1620, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5281,  0.5999,  1.2831],\n",
      "        [-0.4859,  0.5106,  1.6389]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(51.0660, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -3.9652, -30.1068,  54.7567],\n",
      "        [-19.4379, -24.2093,  68.5442]])\n",
      "tensor([0.3451, 0.3237])\n",
      "Epoch: 596\n",
      "Loss: tensor(51.0660, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5281,  0.6002,  1.2826],\n",
      "        [-0.4857,  0.5109,  1.6382]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(50.9702, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.0119, -30.0343,  54.7110],\n",
      "        [-19.4035, -24.2016,  68.4782]])\n",
      "tensor([0.3445, 0.3235])\n",
      "Epoch: 597\n",
      "Loss: tensor(50.9702, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5281,  0.6005,  1.2820],\n",
      "        [-0.4855,  0.5111,  1.6375]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(50.8747, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.0585, -29.9626,  54.6651],\n",
      "        [-19.3681, -24.1927,  68.4131]])\n",
      "tensor([0.3438, 0.3233])\n",
      "Epoch: 598\n",
      "Loss: tensor(50.8747, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5280,  0.6008,  1.2815],\n",
      "        [-0.4853,  0.5114,  1.6368]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(50.7793, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.1045, -29.8908,  54.6194],\n",
      "        [-19.3341, -24.1851,  68.3471]])\n",
      "tensor([0.3431, 0.3232])\n",
      "Epoch: 599\n",
      "Loss: tensor(50.7793, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5280,  0.6011,  1.2809],\n",
      "        [-0.4851,  0.5116,  1.6361]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(50.6841, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.1504, -29.8197,  54.5735],\n",
      "        [-19.2994, -24.1764,  68.2818]])\n",
      "tensor([0.3425, 0.3230])\n",
      "Epoch: 600\n",
      "Loss: tensor(50.6841, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5279,  0.6014,  1.2804],\n",
      "        [-0.4849,  0.5118,  1.6355]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(50.5892, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.1962, -29.7494,  54.5275],\n",
      "        [-19.2649, -24.1677,  68.2166]])\n",
      "tensor([0.3418, 0.3229])\n",
      "Epoch: 601\n",
      "Loss: tensor(50.5892, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5279,  0.6017,  1.2798],\n",
      "        [-0.4847,  0.5121,  1.6348]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(50.4943, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.2411, -29.6787,  54.4818],\n",
      "        [-19.2310, -24.1592,  68.1512]])\n",
      "tensor([0.3411, 0.3227])\n",
      "Epoch: 602\n",
      "Loss: tensor(50.4943, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5278,  0.6020,  1.2793],\n",
      "        [-0.4845,  0.5123,  1.6341]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4655], grad_fn=<SubBackward0>)\n",
      "tensor(50.3997, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.2861, -29.6087,  54.4358],\n",
      "        [-19.1967, -24.1504,  68.0861]])\n",
      "tensor([0.3405, 0.3225])\n",
      "Epoch: 603\n",
      "Loss: tensor(50.3997, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5278,  0.6023,  1.2787],\n",
      "        [-0.4843,  0.5126,  1.6334]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(50.3053, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.3299, -29.5382,  54.3904],\n",
      "        [-19.1630, -24.1419,  68.0208]])\n",
      "tensor([0.3398, 0.3224])\n",
      "Epoch: 604\n",
      "Loss: tensor(50.3053, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5278,  0.6026,  1.2782],\n",
      "        [-0.4841,  0.5128,  1.6327]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(50.2111, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.3745, -29.4693,  54.3443],\n",
      "        [-19.1295, -24.1334,  67.9555]])\n",
      "tensor([0.3392, 0.3222])\n",
      "Epoch: 605\n",
      "Loss: tensor(50.2111, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5277,  0.6029,  1.2777],\n",
      "        [-0.4839,  0.5130,  1.6321]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(50.1171, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.4185, -29.4005,  54.2984],\n",
      "        [-19.0961, -24.1248,  67.8903]])\n",
      "tensor([0.3385, 0.3220])\n",
      "Epoch: 606\n",
      "Loss: tensor(50.1171, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5277,  0.6032,  1.2771],\n",
      "        [-0.4837,  0.5133,  1.6314]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(50.0232, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.4619, -29.3317,  54.2525],\n",
      "        [-19.0624, -24.1156,  67.8254]])\n",
      "tensor([0.3379, 0.3219])\n",
      "Epoch: 607\n",
      "Loss: tensor(50.0232, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5276,  0.6035,  1.2766],\n",
      "        [-0.4836,  0.5135,  1.6307]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(49.9296, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.5048, -29.2632,  54.2068],\n",
      "        [-19.0293, -24.1068,  67.7604]])\n",
      "tensor([0.3372, 0.3217])\n",
      "Epoch: 608\n",
      "Loss: tensor(49.9296, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5276,  0.6038,  1.2760],\n",
      "        [-0.4834,  0.5138,  1.6300]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(49.8361, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.5476, -29.1951,  54.1611],\n",
      "        [-18.9968, -24.0984,  67.6951]])\n",
      "tensor([0.3366, 0.3215])\n",
      "Epoch: 609\n",
      "Loss: tensor(49.8361, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5275,  0.6041,  1.2755],\n",
      "        [-0.4832,  0.5140,  1.6293]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(49.7429, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.5896, -29.1268,  54.1156],\n",
      "        [-18.9635, -24.0891,  67.6305]])\n",
      "tensor([0.3360, 0.3213])\n",
      "Epoch: 610\n",
      "Loss: tensor(49.7429, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5275,  0.6044,  1.2749],\n",
      "        [-0.4830,  0.5142,  1.6287]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(49.6498, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.6319, -29.0596,  54.0697],\n",
      "        [-18.9307, -24.0802,  67.5656]])\n",
      "tensor([0.3353, 0.3212])\n",
      "Epoch: 611\n",
      "Loss: tensor(49.6498, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5274,  0.6046,  1.2744],\n",
      "        [-0.4828,  0.5145,  1.6280]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(49.5569, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.6741, -28.9930,  54.0236],\n",
      "        [-18.8976, -24.0703,  67.5013]])\n",
      "tensor([0.3347, 0.3210])\n",
      "Epoch: 612\n",
      "Loss: tensor(49.5569, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5274,  0.6049,  1.2739],\n",
      "        [-0.4826,  0.5147,  1.6273]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(49.4642, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.7156, -28.9262,  53.9778],\n",
      "        [-18.8652, -24.0613,  67.4366]])\n",
      "tensor([0.3341, 0.3208])\n",
      "Epoch: 613\n",
      "Loss: tensor(49.4642, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5274,  0.6052,  1.2733],\n",
      "        [-0.4824,  0.5150,  1.6266]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(49.3717, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.7570, -28.8601,  53.9319],\n",
      "        [-18.8320, -24.0512,  67.3724]])\n",
      "tensor([0.3334, 0.3207])\n",
      "Epoch: 614\n",
      "Loss: tensor(49.3717, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5273,  0.6055,  1.2728],\n",
      "        [-0.4822,  0.5152,  1.6260]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(49.2794, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.7974, -28.7934,  53.8865],\n",
      "        [-18.7999, -24.0420,  67.3077]])\n",
      "tensor([0.3328, 0.3205])\n",
      "Epoch: 615\n",
      "Loss: tensor(49.2794, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5273,  0.6058,  1.2722],\n",
      "        [-0.4820,  0.5155,  1.6253]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(49.1872, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.8378, -28.7276,  53.8408],\n",
      "        [-18.7674, -24.0322,  67.2435]])\n",
      "tensor([0.3322, 0.3203])\n",
      "Epoch: 616\n",
      "Loss: tensor(49.1872, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5272,  0.6061,  1.2717],\n",
      "        [-0.4818,  0.5157,  1.6246]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0343,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(49.0953, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.8774, -28.6615,  53.7955],\n",
      "        [-18.7349, -24.0223,  67.1794]])\n",
      "tensor([0.3316, 0.3201])\n",
      "Epoch: 617\n",
      "Loss: tensor(49.0953, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5272,  0.6064,  1.2712],\n",
      "        [-0.4817,  0.5159,  1.6240]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(49.0036, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.9169, -28.5958,  53.7500],\n",
      "        [-18.7031, -24.0127,  67.1151]])\n",
      "tensor([0.3310, 0.3200])\n",
      "Epoch: 618\n",
      "Loss: tensor(49.0036, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5271,  0.6067,  1.2706],\n",
      "        [-0.4815,  0.5162,  1.6233]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(48.9119, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.9567, -28.5311,  53.7042],\n",
      "        [-18.6709, -24.0027,  67.0510]])\n",
      "tensor([0.3303, 0.3198])\n",
      "Epoch: 619\n",
      "Loss: tensor(48.9119, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5271,  0.6070,  1.2701],\n",
      "        [-0.4813,  0.5164,  1.6226]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(48.8206, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -4.9955, -28.4661,  53.6588],\n",
      "        [-18.6391, -23.9928,  66.9870]])\n",
      "tensor([0.3297, 0.3196])\n",
      "Epoch: 620\n",
      "Loss: tensor(48.8206, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5270,  0.6072,  1.2696],\n",
      "        [-0.4811,  0.5167,  1.6219]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(48.7294, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.0346, -28.4019,  53.6130],\n",
      "        [-18.6077, -23.9832,  66.9228]])\n",
      "tensor([0.3291, 0.3194])\n",
      "Epoch: 621\n",
      "Loss: tensor(48.7294, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5270,  0.6075,  1.2690],\n",
      "        [-0.4809,  0.5169,  1.6213]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(48.6384, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.0728, -28.3376,  53.5676],\n",
      "        [-18.5758, -23.9728,  66.8591]])\n",
      "tensor([0.3285, 0.3193])\n",
      "Epoch: 622\n",
      "Loss: tensor(48.6384, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5269,  0.6078,  1.2685],\n",
      "        [-0.4807,  0.5171,  1.6206]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(48.5476, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.1120, -28.2749,  53.5214],\n",
      "        [-18.5443, -23.9628,  66.7952]])\n",
      "tensor([0.3279, 0.3191])\n",
      "Epoch: 623\n",
      "Loss: tensor(48.5476, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5269,  0.6081,  1.2680],\n",
      "        [-0.4805,  0.5174,  1.6199]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(48.4569, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.1495, -28.2110,  53.4761],\n",
      "        [-18.5132, -23.9529,  66.7313]])\n",
      "tensor([0.3273, 0.3189])\n",
      "Epoch: 624\n",
      "Loss: tensor(48.4569, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5268,  0.6084,  1.2674],\n",
      "        [-0.4804,  0.5176,  1.6193]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(48.3664, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.1869, -28.1474,  53.4307],\n",
      "        [-18.4821, -23.9427,  66.6674]])\n",
      "tensor([0.3267, 0.3187])\n",
      "Epoch: 625\n",
      "Loss: tensor(48.3664, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5268,  0.6086,  1.2669],\n",
      "        [-0.4802,  0.5179,  1.6186]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(48.2761, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.2251, -28.0856,  53.3845],\n",
      "        [-18.4506, -23.9320,  66.6041]])\n",
      "tensor([0.3261, 0.3186])\n",
      "Epoch: 626\n",
      "Loss: tensor(48.2761, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5267,  0.6089,  1.2663],\n",
      "        [-0.4800,  0.5181,  1.6179]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(48.1860, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.2616, -28.0225,  53.3393],\n",
      "        [-18.4191, -23.9209,  66.5409]])\n",
      "tensor([0.3255, 0.3184])\n",
      "Epoch: 627\n",
      "Loss: tensor(48.1860, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5267,  0.6092,  1.2658],\n",
      "        [-0.4798,  0.5183,  1.6173]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(48.0961, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.2984, -27.9603,  53.2938],\n",
      "        [-18.3887, -23.9110,  66.4770]])\n",
      "tensor([0.3249, 0.3182])\n",
      "Epoch: 628\n",
      "Loss: tensor(48.0961, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5266,  0.6095,  1.2653],\n",
      "        [-0.4796,  0.5186,  1.6166]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(48.0063, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.3350, -27.8986,  53.2481],\n",
      "        [-18.3572, -23.8998,  66.4140]])\n",
      "tensor([0.3243, 0.3180])\n",
      "Epoch: 629\n",
      "Loss: tensor(48.0063, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5265,  0.6098,  1.2647],\n",
      "        [-0.4794,  0.5188,  1.6159]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(47.9167, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.3712, -27.8371,  53.2025],\n",
      "        [-18.3267, -23.8895,  66.3504]])\n",
      "tensor([0.3237, 0.3179])\n",
      "Epoch: 630\n",
      "Loss: tensor(47.9167, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5265,  0.6100,  1.2642],\n",
      "        [-0.4793,  0.5190,  1.6153]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(47.8274, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.4071, -27.7756,  53.1570],\n",
      "        [-18.2962, -23.8788,  66.2872]])\n",
      "tensor([0.3232, 0.3177])\n",
      "Epoch: 631\n",
      "Loss: tensor(47.8274, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5264,  0.6103,  1.2637],\n",
      "        [-0.4791,  0.5193,  1.6146]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(47.7382, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.4425, -27.7142,  53.1116],\n",
      "        [-18.2662, -23.8685,  66.2237]])\n",
      "tensor([0.3226, 0.3175])\n",
      "Epoch: 632\n",
      "Loss: tensor(47.7382, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5264,  0.6106,  1.2632],\n",
      "        [-0.4789,  0.5195,  1.6140]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(47.6491, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.4777, -27.6533,  53.0663],\n",
      "        [-18.2363, -23.8582,  66.1602]])\n",
      "tensor([0.3220, 0.3173])\n",
      "Epoch: 633\n",
      "Loss: tensor(47.6491, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5263,  0.6109,  1.2626],\n",
      "        [-0.4787,  0.5198,  1.6133]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4654], grad_fn=<SubBackward0>)\n",
      "tensor(47.5602, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.5129, -27.5929,  53.0207],\n",
      "        [-18.2057, -23.8470,  66.0973]])\n",
      "tensor([0.3214, 0.3171])\n",
      "Epoch: 634\n",
      "Loss: tensor(47.5602, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5263,  0.6112,  1.2621],\n",
      "        [-0.4785,  0.5200,  1.6126]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(47.4716, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.5482, -27.5333,  52.9748],\n",
      "        [-18.1763, -23.8369,  66.0338]])\n",
      "tensor([0.3208, 0.3169])\n",
      "Epoch: 635\n",
      "Loss: tensor(47.4716, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5262,  0.6114,  1.2616],\n",
      "        [-0.4783,  0.5202,  1.6120]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(47.3831, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.5824, -27.4731,  52.9295],\n",
      "        [-18.1456, -23.8251,  65.9714]])\n",
      "tensor([0.3203, 0.3168])\n",
      "Epoch: 636\n",
      "Loss: tensor(47.3831, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5262,  0.6117,  1.2610],\n",
      "        [-0.4782,  0.5205,  1.6113]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(47.2948, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.6163, -27.4132,  52.8842],\n",
      "        [-18.1161, -23.8145,  65.9083]])\n",
      "tensor([0.3197, 0.3166])\n",
      "Epoch: 637\n",
      "Loss: tensor(47.2948, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5261,  0.6120,  1.2605],\n",
      "        [-0.4780,  0.5207,  1.6107]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(47.2066, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.6503, -27.3539,  52.8388],\n",
      "        [-18.0862, -23.8033,  65.8454]])\n",
      "tensor([0.3191, 0.3164])\n",
      "Epoch: 638\n",
      "Loss: tensor(47.2066, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5260,  0.6123,  1.2600],\n",
      "        [-0.4778,  0.5210,  1.6100]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(47.1186, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.6833, -27.2939,  52.7939],\n",
      "        [-18.0565, -23.7921,  65.7827]])\n",
      "tensor([0.3186, 0.3162])\n",
      "Epoch: 639\n",
      "Loss: tensor(47.1186, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5260,  0.6125,  1.2595],\n",
      "        [-0.4776,  0.5212,  1.6093]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(47.0308, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.7175, -27.2361,  52.7479],\n",
      "        [-18.0269, -23.7808,  65.7201]])\n",
      "tensor([0.3180, 0.3160])\n",
      "Epoch: 640\n",
      "Loss: tensor(47.0308, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5259,  0.6128,  1.2589],\n",
      "        [-0.4774,  0.5214,  1.6087]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(46.9432, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.7503, -27.1771,  52.7027],\n",
      "        [-17.9968, -23.7688,  65.6579]])\n",
      "tensor([0.3174, 0.3159])\n",
      "Epoch: 641\n",
      "Loss: tensor(46.9432, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5259,  0.6131,  1.2584],\n",
      "        [-0.4773,  0.5217,  1.6080]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(46.8558, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.7828, -27.1185,  52.6575],\n",
      "        [-17.9680, -23.7581,  65.5949]])\n",
      "tensor([0.3169, 0.3157])\n",
      "Epoch: 642\n",
      "Loss: tensor(46.8558, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5258,  0.6133,  1.2579],\n",
      "        [-0.4771,  0.5219,  1.6074]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(46.7685, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.8150, -27.0601,  52.6124],\n",
      "        [-17.9387, -23.7467,  65.5324]])\n",
      "tensor([0.3163, 0.3155])\n",
      "Epoch: 643\n",
      "Loss: tensor(46.7685, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5258,  0.6136,  1.2573],\n",
      "        [-0.4769,  0.5221,  1.6067]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(46.6814, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.8463, -27.0012,  52.5678],\n",
      "        [-17.9090, -23.7346,  65.4704]])\n",
      "tensor([0.3158, 0.3153])\n",
      "Epoch: 644\n",
      "Loss: tensor(46.6814, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5257,  0.6139,  1.2568],\n",
      "        [-0.4767,  0.5224,  1.6061]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(46.5944, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.8790, -26.9444,  52.5219],\n",
      "        [-17.8803, -23.7234,  65.4079]])\n",
      "tensor([0.3152, 0.3151])\n",
      "Epoch: 645\n",
      "Loss: tensor(46.5944, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5256,  0.6142,  1.2563],\n",
      "        [-0.4765,  0.5226,  1.6054]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(46.5077, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.9103, -26.8866,  52.4770],\n",
      "        [-17.8516, -23.7121,  65.3454]])\n",
      "tensor([0.3147, 0.3149])\n",
      "Epoch: 646\n",
      "Loss: tensor(46.5077, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5256,  0.6144,  1.2558],\n",
      "        [-0.4764,  0.5229,  1.6047]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(46.4212, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.9417, -26.8295,  52.4318],\n",
      "        [-17.8233, -23.7011,  65.2828]])\n",
      "tensor([0.3141, 0.3147])\n",
      "Epoch: 647\n",
      "Loss: tensor(46.4212, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5255,  0.6147,  1.2552],\n",
      "        [-0.4762,  0.5231,  1.6041]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0344,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(46.3347, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -5.9725, -26.7723,  52.3868],\n",
      "        [-17.7943, -23.6891,  65.2208]])\n",
      "tensor([0.3136, 0.3146])\n",
      "Epoch: 648\n",
      "Loss: tensor(46.3347, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5255,  0.6150,  1.2547],\n",
      "        [-0.4760,  0.5233,  1.6034]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(46.2485, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.0038, -26.7162,  52.3413],\n",
      "        [-17.7661, -23.6780,  65.1584]])\n",
      "tensor([0.3131, 0.3144])\n",
      "Epoch: 649\n",
      "Loss: tensor(46.2485, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5254,  0.6152,  1.2542],\n",
      "        [-0.4758,  0.5236,  1.6028]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(46.1624, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.0348, -26.6604,  52.2959],\n",
      "        [-17.7372, -23.6656,  65.0966]])\n",
      "tensor([0.3125, 0.3142])\n",
      "Epoch: 650\n",
      "Loss: tensor(46.1624, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5253,  0.6155,  1.2537],\n",
      "        [-0.4757,  0.5238,  1.6021]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(46.0765, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.0649, -26.6039,  52.2510],\n",
      "        [-17.7090, -23.6540,  65.0345]])\n",
      "tensor([0.3120, 0.3140])\n",
      "Epoch: 651\n",
      "Loss: tensor(46.0765, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5253,  0.6158,  1.2532],\n",
      "        [-0.4755,  0.5240,  1.6015]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(45.9908, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.0953, -26.5484,  52.2056],\n",
      "        [-17.6808, -23.6422,  64.9726]])\n",
      "tensor([0.3114, 0.3138])\n",
      "Epoch: 652\n",
      "Loss: tensor(45.9908, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5252,  0.6160,  1.2526],\n",
      "        [-0.4753,  0.5243,  1.6008]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(45.9052, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.1244, -26.4921,  52.1610],\n",
      "        [-17.6519, -23.6295,  64.9112]])\n",
      "tensor([0.3109, 0.3136])\n",
      "Epoch: 653\n",
      "Loss: tensor(45.9052, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5252,  0.6163,  1.2521],\n",
      "        [-0.4751,  0.5245,  1.6002]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(45.8198, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.1542, -26.4371,  52.1157],\n",
      "        [-17.6242, -23.6182,  64.8491]])\n",
      "tensor([0.3104, 0.3134])\n",
      "Epoch: 654\n",
      "Loss: tensor(45.8198, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5251,  0.6165,  1.2516],\n",
      "        [-0.4749,  0.5247,  1.5995]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(45.7346, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.1834, -26.3818,  52.0708],\n",
      "        [-17.5963, -23.6062,  64.7874]])\n",
      "tensor([0.3098, 0.3132])\n",
      "Epoch: 655\n",
      "Loss: tensor(45.7346, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5250,  0.6168,  1.2511],\n",
      "        [-0.4748,  0.5250,  1.5989]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(45.6495, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.2127, -26.3270,  52.0256],\n",
      "        [-17.5686, -23.5941,  64.7256]])\n",
      "tensor([0.3093, 0.3130])\n",
      "Epoch: 656\n",
      "Loss: tensor(45.6495, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5250,  0.6171,  1.2505],\n",
      "        [-0.4746,  0.5252,  1.5982]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(45.5646, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.2416, -26.2725,  51.9806],\n",
      "        [-17.5415, -23.5828,  64.6636]])\n",
      "tensor([0.3088, 0.3128])\n",
      "Epoch: 657\n",
      "Loss: tensor(45.5646, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5249,  0.6173,  1.2500],\n",
      "        [-0.4744,  0.5255,  1.5976]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(45.4799, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.2699, -26.2177,  51.9358],\n",
      "        [-17.5130, -23.5698,  64.6025]])\n",
      "tensor([0.3083, 0.3127])\n",
      "Epoch: 658\n",
      "Loss: tensor(45.4799, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5249,  0.6176,  1.2495],\n",
      "        [-0.4742,  0.5257,  1.5970]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(45.3953, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.2984, -26.1638,  51.8906],\n",
      "        [-17.4857, -23.5579,  64.5409]])\n",
      "tensor([0.3078, 0.3125])\n",
      "Epoch: 659\n",
      "Loss: tensor(45.3953, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5248,  0.6179,  1.2490],\n",
      "        [-0.4741,  0.5259,  1.5963]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(45.3110, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.3260, -26.1094,  51.8460],\n",
      "        [-17.4581, -23.5454,  64.4796]])\n",
      "tensor([0.3072, 0.3123])\n",
      "Epoch: 660\n",
      "Loss: tensor(45.3110, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5247,  0.6181,  1.2485],\n",
      "        [-0.4739,  0.5262,  1.5957]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(45.2267, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.3539, -26.0558,  51.8010],\n",
      "        [-17.4305, -23.5328,  64.4184]])\n",
      "tensor([0.3067, 0.3121])\n",
      "Epoch: 661\n",
      "Loss: tensor(45.2267, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5247,  0.6184,  1.2479],\n",
      "        [-0.4737,  0.5264,  1.5950]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(45.1427, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.3821, -26.0030,  51.7557],\n",
      "        [-17.4038, -23.5211,  64.3568]])\n",
      "tensor([0.3062, 0.3119])\n",
      "Epoch: 662\n",
      "Loss: tensor(45.1427, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5246,  0.6186,  1.2474],\n",
      "        [-0.4735,  0.5266,  1.5944]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(45.0588, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.4093, -25.9496,  51.7110],\n",
      "        [-17.3764, -23.5085,  64.2957]])\n",
      "tensor([0.3057, 0.3117])\n",
      "Epoch: 663\n",
      "Loss: tensor(45.0588, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5245,  0.6189,  1.2469],\n",
      "        [-0.4734,  0.5269,  1.5937]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(44.9750, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.4367, -25.8970,  51.6659],\n",
      "        [-17.3497, -23.4965,  64.2342]])\n",
      "tensor([0.3052, 0.3115])\n",
      "Epoch: 664\n",
      "Loss: tensor(44.9750, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5245,  0.6192,  1.2464],\n",
      "        [-0.4732,  0.5271,  1.5931]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(44.8915, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.4632, -25.8439,  51.6213],\n",
      "        [-17.3221, -23.4834,  64.1735]])\n",
      "tensor([0.3047, 0.3113])\n",
      "Epoch: 665\n",
      "Loss: tensor(44.8915, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5244,  0.6194,  1.2459],\n",
      "        [-0.4730,  0.5273,  1.5924]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4653], grad_fn=<SubBackward0>)\n",
      "tensor(44.8081, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.4897, -25.7911,  51.5766],\n",
      "        [-17.2946, -23.4702,  64.1130]])\n",
      "tensor([0.3042, 0.3111])\n",
      "Epoch: 666\n",
      "Loss: tensor(44.8081, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5243,  0.6197,  1.2454],\n",
      "        [-0.4729,  0.5276,  1.5918]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(44.7248, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.5165, -25.7392,  51.5315],\n",
      "        [-17.2679, -23.4576,  64.0520]])\n",
      "tensor([0.3037, 0.3109])\n",
      "Epoch: 667\n",
      "Loss: tensor(44.7248, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5243,  0.6199,  1.2449],\n",
      "        [-0.4727,  0.5278,  1.5912]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(44.6418, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.5433, -25.6877,  51.4864],\n",
      "        [-17.2411, -23.4448,  63.9911]])\n",
      "tensor([0.3031, 0.3108])\n",
      "Epoch: 668\n",
      "Loss: tensor(44.6418, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5242,  0.6202,  1.2443],\n",
      "        [-0.4725,  0.5280,  1.5905]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(44.5588, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.5691, -25.6358,  51.4417],\n",
      "        [-17.2147, -23.4324,  63.9301]])\n",
      "tensor([0.3026, 0.3106])\n",
      "Epoch: 669\n",
      "Loss: tensor(44.5588, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5241,  0.6205,  1.2438],\n",
      "        [-0.4723,  0.5283,  1.5899]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(44.4761, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.5945, -25.5837,  51.3972],\n",
      "        [-17.1882, -23.4197,  63.8694]])\n",
      "tensor([0.3021, 0.3104])\n",
      "Epoch: 670\n",
      "Loss: tensor(44.4761, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5241,  0.6207,  1.2433],\n",
      "        [-0.4722,  0.5285,  1.5893]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(44.3935, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.6205, -25.5328,  51.3522],\n",
      "        [-17.1624, -23.4077,  63.8082]])\n",
      "tensor([0.3016, 0.3102])\n",
      "Epoch: 671\n",
      "Loss: tensor(44.3935, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5240,  0.6210,  1.2428],\n",
      "        [-0.4720,  0.5287,  1.5886]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(44.3110, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.6457, -25.4817,  51.3074],\n",
      "        [-17.1355, -23.3941,  63.7479]])\n",
      "tensor([0.3011, 0.3100])\n",
      "Epoch: 672\n",
      "Loss: tensor(44.3110, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5239,  0.6212,  1.2423],\n",
      "        [-0.4718,  0.5290,  1.5880]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(44.2288, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.6706, -25.4305,  51.2629],\n",
      "        [-17.1093, -23.3814,  63.6872]])\n",
      "tensor([0.3007, 0.3098])\n",
      "Epoch: 673\n",
      "Loss: tensor(44.2288, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5239,  0.6215,  1.2418],\n",
      "        [-0.4716,  0.5292,  1.5873]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(44.1467, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.6954, -25.3798,  51.2183],\n",
      "        [-17.0828, -23.3681,  63.6270]])\n",
      "tensor([0.3002, 0.3096])\n",
      "Epoch: 674\n",
      "Loss: tensor(44.1467, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5238,  0.6217,  1.2413],\n",
      "        [-0.4715,  0.5294,  1.5867]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(44.0647, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.7201, -25.3293,  51.1736],\n",
      "        [-17.0561, -23.3544,  63.5670]])\n",
      "tensor([0.2997, 0.3094])\n",
      "Epoch: 675\n",
      "Loss: tensor(44.0647, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5237,  0.6220,  1.2407],\n",
      "        [-0.4713,  0.5297,  1.5861]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(43.9830, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.7446, -25.2791,  51.1289],\n",
      "        [-17.0305, -23.3418,  63.5064]])\n",
      "tensor([0.2992, 0.3092])\n",
      "Epoch: 676\n",
      "Loss: tensor(43.9830, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5237,  0.6222,  1.2402],\n",
      "        [-0.4711,  0.5299,  1.5854]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(43.9014, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.7688, -25.2291,  51.0843],\n",
      "        [-17.0044, -23.3285,  63.4462]])\n",
      "tensor([0.2987, 0.3090])\n",
      "Epoch: 677\n",
      "Loss: tensor(43.9014, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5236,  0.6225,  1.2397],\n",
      "        [-0.4710,  0.5301,  1.5848]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(43.8198, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.7921, -25.1785,  51.0401],\n",
      "        [-16.9784, -23.3153,  63.3860]])\n",
      "tensor([0.2982, 0.3088])\n",
      "Epoch: 678\n",
      "Loss: tensor(43.8198, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5235,  0.6227,  1.2392],\n",
      "        [-0.4708,  0.5304,  1.5842]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(43.7385, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.8165, -25.1295,  50.9951],\n",
      "        [-16.9525, -23.3018,  63.3259]])\n",
      "tensor([0.2977, 0.3086])\n",
      "Epoch: 679\n",
      "Loss: tensor(43.7385, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5235,  0.6230,  1.2387],\n",
      "        [-0.4706,  0.5306,  1.5835]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(43.6574, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.8398, -25.0799,  50.9507],\n",
      "        [-16.9269, -23.2888,  63.2657]])\n",
      "tensor([0.2973, 0.3084])\n",
      "Epoch: 680\n",
      "Loss: tensor(43.6574, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5234,  0.6232,  1.2382],\n",
      "        [-0.4705,  0.5308,  1.5829]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0345,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(43.5764, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.8626, -25.0301,  50.9066],\n",
      "        [-16.9016, -23.2758,  63.2056]])\n",
      "tensor([0.2968, 0.3082])\n",
      "Epoch: 681\n",
      "Loss: tensor(43.5764, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5233,  0.6235,  1.2377],\n",
      "        [-0.4703,  0.5311,  1.5823]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(43.4956, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.8861, -24.9816,  50.8619],\n",
      "        [-16.8761, -23.2624,  63.1456]])\n",
      "tensor([0.2963, 0.3080])\n",
      "Epoch: 682\n",
      "Loss: tensor(43.4956, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5233,  0.6237,  1.2372],\n",
      "        [-0.4701,  0.5313,  1.5816]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(43.4149, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.9093, -24.9330,  50.8172],\n",
      "        [-16.8504, -23.2489,  63.0858]])\n",
      "tensor([0.2958, 0.3078])\n",
      "Epoch: 683\n",
      "Loss: tensor(43.4149, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5232,  0.6240,  1.2367],\n",
      "        [-0.4700,  0.5315,  1.5810]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(43.3343, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.9324, -24.8848,  50.7725],\n",
      "        [-16.8251, -23.2356,  63.0258]])\n",
      "tensor([0.2953, 0.3076])\n",
      "Epoch: 684\n",
      "Loss: tensor(43.3343, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5231,  0.6242,  1.2362],\n",
      "        [-0.4698,  0.5318,  1.5804]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(43.2540, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.9550, -24.8365,  50.7281],\n",
      "        [-16.7999, -23.2221,  62.9661]])\n",
      "tensor([0.2949, 0.3074])\n",
      "Epoch: 685\n",
      "Loss: tensor(43.2540, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5231,  0.6245,  1.2357],\n",
      "        [-0.4696,  0.5320,  1.5797]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(43.1738, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.9767, -24.7876,  50.6841],\n",
      "        [-16.7751, -23.2090,  62.9061]])\n",
      "tensor([0.2944, 0.3072])\n",
      "Epoch: 686\n",
      "Loss: tensor(43.1738, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5230,  0.6247,  1.2351],\n",
      "        [-0.4694,  0.5322,  1.5791]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(43.0937, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -6.9990, -24.7399,  50.6395],\n",
      "        [-16.7495, -23.1950,  62.8468]])\n",
      "tensor([0.2939, 0.3070])\n",
      "Epoch: 687\n",
      "Loss: tensor(43.0937, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5229,  0.6250,  1.2346],\n",
      "        [-0.4693,  0.5325,  1.5785]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(43.0138, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.0208, -24.6920,  50.5953],\n",
      "        [-16.7251, -23.1822,  62.7867]])\n",
      "tensor([0.2935, 0.3068])\n",
      "Epoch: 688\n",
      "Loss: tensor(43.0138, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5229,  0.6252,  1.2341],\n",
      "        [-0.4691,  0.5327,  1.5779]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(42.9341, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.0420, -24.6438,  50.5513],\n",
      "        [-16.7008, -23.1691,  62.7268]])\n",
      "tensor([0.2930, 0.3066])\n",
      "Epoch: 689\n",
      "Loss: tensor(42.9341, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5228,  0.6255,  1.2336],\n",
      "        [-0.4689,  0.5329,  1.5772]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(42.8545, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.0640, -24.5971,  50.5066],\n",
      "        [-16.6754, -23.1550,  62.6677]])\n",
      "tensor([0.2925, 0.3064])\n",
      "Epoch: 690\n",
      "Loss: tensor(42.8545, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5227,  0.6257,  1.2331],\n",
      "        [-0.4688,  0.5332,  1.5766]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(42.7751, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.0853, -24.5498,  50.4623],\n",
      "        [-16.6510, -23.1416,  62.6080]])\n",
      "tensor([0.2921, 0.3062])\n",
      "Epoch: 691\n",
      "Loss: tensor(42.7751, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5226,  0.6260,  1.2326],\n",
      "        [-0.4686,  0.5334,  1.5760]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(42.6958, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.1064, -24.5028,  50.4181],\n",
      "        [-16.6260, -23.1278,  62.5488]])\n",
      "tensor([0.2916, 0.3060])\n",
      "Epoch: 692\n",
      "Loss: tensor(42.6958, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5226,  0.6262,  1.2321],\n",
      "        [-0.4684,  0.5336,  1.5754]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(42.6166, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.1269, -24.4556,  50.3741],\n",
      "        [-16.6013, -23.1137,  62.4896]])\n",
      "tensor([0.2912, 0.3058])\n",
      "Epoch: 693\n",
      "Loss: tensor(42.6166, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5225,  0.6265,  1.2316],\n",
      "        [-0.4683,  0.5339,  1.5747]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(42.5377, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.1477, -24.4090,  50.3299],\n",
      "        [-16.5771, -23.1003,  62.4301]])\n",
      "tensor([0.2907, 0.3056])\n",
      "Epoch: 694\n",
      "Loss: tensor(42.5377, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5224,  0.6267,  1.2311],\n",
      "        [-0.4681,  0.5341,  1.5741]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(42.4588, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.1685, -24.3630,  50.2855],\n",
      "        [-16.5524, -23.0862,  62.3711]])\n",
      "tensor([0.2903, 0.3054])\n",
      "Epoch: 695\n",
      "Loss: tensor(42.4588, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5224,  0.6269,  1.2306],\n",
      "        [-0.4680,  0.5343,  1.5735]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(42.3802, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.1890, -24.3170,  50.2412],\n",
      "        [-16.5283, -23.0726,  62.3119]])\n",
      "tensor([0.2898, 0.3052])\n",
      "Epoch: 696\n",
      "Loss: tensor(42.3802, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5223,  0.6272,  1.2301],\n",
      "        [-0.4678,  0.5346,  1.5729]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(42.3017, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.2094, -24.2713,  50.1969],\n",
      "        [-16.5039, -23.0587,  62.2529]])\n",
      "tensor([0.2893, 0.3050])\n",
      "Epoch: 697\n",
      "Loss: tensor(42.3017, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5222,  0.6274,  1.2296],\n",
      "        [-0.4676,  0.5348,  1.5722]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(42.2232, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.2291, -24.2252,  50.1529],\n",
      "        [-16.4792, -23.0440,  62.1942]])\n",
      "tensor([0.2889, 0.3048])\n",
      "Epoch: 698\n",
      "Loss: tensor(42.2232, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5221,  0.6277,  1.2291],\n",
      "        [-0.4675,  0.5350,  1.5716]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4652], grad_fn=<SubBackward0>)\n",
      "tensor(42.1450, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.2488, -24.1794,  50.1088],\n",
      "        [-16.4557, -23.0309,  62.1348]])\n",
      "tensor([0.2885, 0.3046])\n",
      "Epoch: 699\n",
      "Loss: tensor(42.1450, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5221,  0.6279,  1.2286],\n",
      "        [-0.4673,  0.5352,  1.5710]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(42.0670, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.2682, -24.1339,  50.0649],\n",
      "        [-16.4308, -23.0160,  62.0766]])\n",
      "tensor([0.2880, 0.3044])\n",
      "Epoch: 700\n",
      "Loss: tensor(42.0670, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5220,  0.6282,  1.2281],\n",
      "        [-0.4671,  0.5355,  1.5704]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(41.9891, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.2878, -24.0889,  50.0207],\n",
      "        [-16.4075, -23.0026,  62.0173]])\n",
      "tensor([0.2876, 0.3042])\n",
      "Epoch: 701\n",
      "Loss: tensor(41.9891, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5219,  0.6284,  1.2276],\n",
      "        [-0.4670,  0.5357,  1.5697]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(41.9113, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.3070, -24.0438,  49.9767],\n",
      "        [-16.3837, -22.9886,  61.9585]])\n",
      "tensor([0.2871, 0.3040])\n",
      "Epoch: 702\n",
      "Loss: tensor(41.9113, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5218,  0.6286,  1.2271],\n",
      "        [-0.4668,  0.5359,  1.5691]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(41.8337, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.3258, -23.9986,  49.9328],\n",
      "        [-16.3595, -22.9741,  61.9001]])\n",
      "tensor([0.2867, 0.3038])\n",
      "Epoch: 703\n",
      "Loss: tensor(41.8337, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5218,  0.6289,  1.2266],\n",
      "        [-0.4666,  0.5362,  1.5685]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(41.7563, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.3452, -23.9545,  49.8885],\n",
      "        [-16.3366, -22.9609,  61.8409]])\n",
      "tensor([0.2862, 0.3036])\n",
      "Epoch: 704\n",
      "Loss: tensor(41.7563, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5217,  0.6291,  1.2261],\n",
      "        [-0.4665,  0.5364,  1.5679]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(41.6789, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.3639, -23.9101,  49.8445],\n",
      "        [-16.3128, -22.9466,  61.7823]])\n",
      "tensor([0.2858, 0.3034])\n",
      "Epoch: 705\n",
      "Loss: tensor(41.6789, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5216,  0.6294,  1.2256],\n",
      "        [-0.4663,  0.5366,  1.5673]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(41.6018, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.3824, -23.8657,  49.8006],\n",
      "        [-16.2893, -22.9326,  61.7238]])\n",
      "tensor([0.2854, 0.3032])\n",
      "Epoch: 706\n",
      "Loss: tensor(41.6018, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5216,  0.6296,  1.2251],\n",
      "        [-0.4661,  0.5369,  1.5667]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(41.5248, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.4007, -23.8216,  49.7567],\n",
      "        [-16.2659, -22.9184,  61.6653]])\n",
      "tensor([0.2849, 0.3030])\n",
      "Epoch: 707\n",
      "Loss: tensor(41.5248, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5215,  0.6298,  1.2246],\n",
      "        [-0.4660,  0.5371,  1.5660]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(41.4479, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.4185, -23.7772,  49.7130],\n",
      "        [-16.2426, -22.9044,  61.6067]])\n",
      "tensor([0.2845, 0.3028])\n",
      "Epoch: 708\n",
      "Loss: tensor(41.4479, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5214,  0.6301,  1.2241],\n",
      "        [-0.4658,  0.5373,  1.5654]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(41.3712, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.4361, -23.7331,  49.6694],\n",
      "        [-16.2191, -22.8899,  61.5485]])\n",
      "tensor([0.2841, 0.3026])\n",
      "Epoch: 709\n",
      "Loss: tensor(41.3712, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5213,  0.6303,  1.2236],\n",
      "        [-0.4657,  0.5375,  1.5648]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(41.2946, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.4538, -23.6893,  49.6257],\n",
      "        [-16.1957, -22.8754,  61.4904]])\n",
      "tensor([0.2836, 0.3024])\n",
      "Epoch: 710\n",
      "Loss: tensor(41.2946, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5213,  0.6305,  1.2231],\n",
      "        [-0.4655,  0.5378,  1.5642]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(41.2182, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.4718, -23.6465,  49.5815],\n",
      "        [-16.1728, -22.8614,  61.4319]])\n",
      "tensor([0.2832, 0.3022])\n",
      "Epoch: 711\n",
      "Loss: tensor(41.2182, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5212,  0.6308,  1.2226],\n",
      "        [-0.4653,  0.5380,  1.5636]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(41.1419, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.4888, -23.6027,  49.5380],\n",
      "        [-16.1490, -22.8462,  61.3743]])\n",
      "tensor([0.2828, 0.3020])\n",
      "Epoch: 712\n",
      "Loss: tensor(41.1419, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5211,  0.6310,  1.2221],\n",
      "        [-0.4652,  0.5382,  1.5630]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(41.0657, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.5070, -23.5607,  49.4936],\n",
      "        [-16.1256, -22.8315,  61.3163]])\n",
      "tensor([0.2823, 0.3018])\n",
      "Epoch: 713\n",
      "Loss: tensor(41.0657, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5210,  0.6312,  1.2216],\n",
      "        [-0.4650,  0.5385,  1.5624]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.9898, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.5239, -23.5176,  49.4500],\n",
      "        [-16.1032, -22.8178,  61.2578]])\n",
      "tensor([0.2819, 0.3016])\n",
      "Epoch: 714\n",
      "Loss: tensor(40.9898, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5210,  0.6315,  1.2211],\n",
      "        [-0.4649,  0.5387,  1.5617]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.9139, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.5405, -23.4744,  49.4066],\n",
      "        [-16.0805, -22.8035,  61.1997]])\n",
      "tensor([0.2815, 0.3014])\n",
      "Epoch: 715\n",
      "Loss: tensor(40.9139, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5209,  0.6317,  1.2206],\n",
      "        [-0.4647,  0.5389,  1.5611]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0346,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.8382, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.5579, -23.4326,  49.3624],\n",
      "        [-16.0576, -22.7890,  61.1418]])\n",
      "tensor([0.2811, 0.3012])\n",
      "Epoch: 716\n",
      "Loss: tensor(40.8382, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5208,  0.6320,  1.2201],\n",
      "        [-0.4645,  0.5391,  1.5605]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.7627, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.5746, -23.3903,  49.3187],\n",
      "        [-16.0350, -22.7747,  61.0839]])\n",
      "tensor([0.2806, 0.3010])\n",
      "Epoch: 717\n",
      "Loss: tensor(40.7627, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5207,  0.6322,  1.2197],\n",
      "        [-0.4644,  0.5394,  1.5599]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.6873, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.5909, -23.3479,  49.2752],\n",
      "        [-16.0121, -22.7599,  61.0261]])\n",
      "tensor([0.2802, 0.3008])\n",
      "Epoch: 718\n",
      "Loss: tensor(40.6873, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5207,  0.6324,  1.2192],\n",
      "        [-0.4642,  0.5396,  1.5593]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.6120, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.6069, -23.3056,  49.2317],\n",
      "        [-15.9897, -22.7456,  60.9682]])\n",
      "tensor([0.2798, 0.3005])\n",
      "Epoch: 719\n",
      "Loss: tensor(40.6120, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5206,  0.6327,  1.2187],\n",
      "        [-0.4640,  0.5398,  1.5587]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.5369, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.6234, -23.2640,  49.1879],\n",
      "        [-15.9666, -22.7304,  60.9108]])\n",
      "tensor([0.2794, 0.3003])\n",
      "Epoch: 720\n",
      "Loss: tensor(40.5369, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5205,  0.6329,  1.2182],\n",
      "        [-0.4639,  0.5400,  1.5581]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.4619, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.6388, -23.2218,  49.1447],\n",
      "        [-15.9444, -22.7159,  60.8531]])\n",
      "tensor([0.2790, 0.3001])\n",
      "Epoch: 721\n",
      "Loss: tensor(40.4619, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5204,  0.6331,  1.2177],\n",
      "        [-0.4637,  0.5403,  1.5575]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.3871, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.6549, -23.1806,  49.1009],\n",
      "        [-15.9221, -22.7015,  60.7955]])\n",
      "tensor([0.2786, 0.2999])\n",
      "Epoch: 722\n",
      "Loss: tensor(40.3871, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5203,  0.6334,  1.2172],\n",
      "        [-0.4636,  0.5405,  1.5569]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.3124, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.6703, -23.1389,  49.0576],\n",
      "        [-15.8994, -22.6865,  60.7381]])\n",
      "tensor([0.2782, 0.2997])\n",
      "Epoch: 723\n",
      "Loss: tensor(40.3124, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5203,  0.6336,  1.2167],\n",
      "        [-0.4634,  0.5407,  1.5563]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.2379, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.6862, -23.0982,  49.0138],\n",
      "        [-15.8773, -22.6720,  60.6805]])\n",
      "tensor([0.2777, 0.2995])\n",
      "Epoch: 724\n",
      "Loss: tensor(40.2379, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5202,  0.6338,  1.2162],\n",
      "        [-0.4633,  0.5410,  1.5556]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.1635, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.7010, -23.0566,  48.9707],\n",
      "        [-15.8544, -22.6563,  60.6237]])\n",
      "tensor([0.2773, 0.2993])\n",
      "Epoch: 725\n",
      "Loss: tensor(40.1635, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5201,  0.6340,  1.2157],\n",
      "        [-0.4631,  0.5412,  1.5550]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.0892, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.7163, -23.0158,  48.9272],\n",
      "        [-15.8321, -22.6414,  60.5664]])\n",
      "tensor([0.2769, 0.2991])\n",
      "Epoch: 726\n",
      "Loss: tensor(40.0892, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5200,  0.6343,  1.2152],\n",
      "        [-0.4629,  0.5414,  1.5544]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(40.0151, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.7313, -22.9752,  48.8837],\n",
      "        [-15.8103, -22.6269,  60.5089]])\n",
      "tensor([0.2765, 0.2989])\n",
      "Epoch: 727\n",
      "Loss: tensor(40.0151, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5200,  0.6345,  1.2147],\n",
      "        [-0.4628,  0.5416,  1.5538]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(39.9411, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.7457, -22.9341,  48.8407],\n",
      "        [-15.7887, -22.6125,  60.4515]])\n",
      "tensor([0.2761, 0.2987])\n",
      "Epoch: 728\n",
      "Loss: tensor(39.9411, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5199,  0.6347,  1.2143],\n",
      "        [-0.4626,  0.5419,  1.5532]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(39.8673, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.7601, -22.8933,  48.7975],\n",
      "        [-15.7665, -22.5974,  60.3944]])\n",
      "tensor([0.2757, 0.2985])\n",
      "Epoch: 729\n",
      "Loss: tensor(39.8673, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5198,  0.6350,  1.2138],\n",
      "        [-0.4625,  0.5421,  1.5526]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(39.7936, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.7747, -22.8532,  48.7541],\n",
      "        [-15.7449, -22.5829,  60.3371]])\n",
      "tensor([0.2753, 0.2983])\n",
      "Epoch: 730\n",
      "Loss: tensor(39.7936, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5197,  0.6352,  1.2133],\n",
      "        [-0.4623,  0.5423,  1.5520]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(39.7201, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.7891, -22.8130,  48.7109],\n",
      "        [-15.7226, -22.5674,  60.2804]])\n",
      "tensor([0.2749, 0.2981])\n",
      "Epoch: 731\n",
      "Loss: tensor(39.7201, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5197,  0.6354,  1.2128],\n",
      "        [-0.4621,  0.5425,  1.5514]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4651], grad_fn=<SubBackward0>)\n",
      "tensor(39.6467, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.8033, -22.7731,  48.6676],\n",
      "        [-15.7013, -22.5529,  60.2232]])\n",
      "tensor([0.2745, 0.2979])\n",
      "Epoch: 732\n",
      "Loss: tensor(39.6467, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5196,  0.6356,  1.2123],\n",
      "        [-0.4620,  0.5428,  1.5508]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(39.5734, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.8180, -22.7339,  48.6240],\n",
      "        [-15.6793, -22.5376,  60.1664]])\n",
      "tensor([0.2741, 0.2977])\n",
      "Epoch: 733\n",
      "Loss: tensor(39.5734, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5195,  0.6359,  1.2118],\n",
      "        [-0.4618,  0.5430,  1.5502]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(39.5003, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.8316, -22.6940,  48.5809],\n",
      "        [-15.6581, -22.5231,  60.1093]])\n",
      "tensor([0.2737, 0.2975])\n",
      "Epoch: 734\n",
      "Loss: tensor(39.5003, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5194,  0.6361,  1.2113],\n",
      "        [-0.4617,  0.5432,  1.5496]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(39.4273, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.8457, -22.6549,  48.5375],\n",
      "        [-15.6362, -22.5077,  60.0526]])\n",
      "tensor([0.2733, 0.2973])\n",
      "Epoch: 735\n",
      "Loss: tensor(39.4273, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5193,  0.6363,  1.2108],\n",
      "        [-0.4615,  0.5434,  1.5490]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(39.3544, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.8595, -22.6156,  48.4943],\n",
      "        [-15.6147, -22.4927,  59.9959]])\n",
      "tensor([0.2729, 0.2970])\n",
      "Epoch: 736\n",
      "Loss: tensor(39.3544, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5193,  0.6366,  1.2104],\n",
      "        [-0.4614,  0.5437,  1.5484]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(39.2817, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.8724, -22.5758,  48.4515],\n",
      "        [-15.5936, -22.4780,  59.9390]])\n",
      "tensor([0.2726, 0.2968])\n",
      "Epoch: 737\n",
      "Loss: tensor(39.2817, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5192,  0.6368,  1.2099],\n",
      "        [-0.4612,  0.5439,  1.5478]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(39.2091, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.8857, -22.5368,  48.4084],\n",
      "        [-15.5723, -22.4630,  59.8823]])\n",
      "tensor([0.2722, 0.2966])\n",
      "Epoch: 738\n",
      "Loss: tensor(39.2091, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5191,  0.6370,  1.2094],\n",
      "        [-0.4611,  0.5441,  1.5472]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(39.1367, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.8989, -22.4979,  48.3654],\n",
      "        [-15.5510, -22.4481,  59.8256]])\n",
      "tensor([0.2718, 0.2964])\n",
      "Epoch: 739\n",
      "Loss: tensor(39.1367, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5190,  0.6372,  1.2089],\n",
      "        [-0.4609,  0.5443,  1.5466]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(39.0644, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.9117, -22.4588,  48.3225],\n",
      "        [-15.5298, -22.4328,  59.7691]])\n",
      "tensor([0.2714, 0.2962])\n",
      "Epoch: 740\n",
      "Loss: tensor(39.0644, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5189,  0.6375,  1.2084],\n",
      "        [-0.4607,  0.5446,  1.5460]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.9922, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.9252, -22.4209,  48.2791],\n",
      "        [-15.5087, -22.4177,  59.7126]])\n",
      "tensor([0.2710, 0.2960])\n",
      "Epoch: 741\n",
      "Loss: tensor(38.9922, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5189,  0.6377,  1.2079],\n",
      "        [-0.4606,  0.5448,  1.5454]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.9203, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.9375, -22.3819,  48.2364],\n",
      "        [-15.4874, -22.4024,  59.6563]])\n",
      "tensor([0.2706, 0.2958])\n",
      "Epoch: 742\n",
      "Loss: tensor(38.9203, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5188,  0.6379,  1.2075],\n",
      "        [-0.4604,  0.5450,  1.5448]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.8484, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.9497, -22.3432,  48.1937],\n",
      "        [-15.4663, -22.3874,  59.5999]])\n",
      "tensor([0.2702, 0.2956])\n",
      "Epoch: 743\n",
      "Loss: tensor(38.8484, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5187,  0.6381,  1.2070],\n",
      "        [-0.4603,  0.5452,  1.5442]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.7766, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.9625, -22.3054,  48.1505],\n",
      "        [-15.4457, -22.3724,  59.5434]])\n",
      "tensor([0.2698, 0.2954])\n",
      "Epoch: 744\n",
      "Loss: tensor(38.7766, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5186,  0.6383,  1.2065],\n",
      "        [-0.4601,  0.5455,  1.5436]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.7050, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.9748, -22.2673,  48.1077],\n",
      "        [-15.4247, -22.3571,  59.4872]])\n",
      "tensor([0.2695, 0.2952])\n",
      "Epoch: 745\n",
      "Loss: tensor(38.7050, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5185,  0.6386,  1.2060],\n",
      "        [-0.4600,  0.5457,  1.5430]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.6335, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.9870, -22.2292,  48.0649],\n",
      "        [-15.4035, -22.3414,  59.4313]])\n",
      "tensor([0.2691, 0.2950])\n",
      "Epoch: 746\n",
      "Loss: tensor(38.6335, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5185,  0.6388,  1.2055],\n",
      "        [-0.4598,  0.5459,  1.5424]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.5622, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -7.9997, -22.1924,  48.0215],\n",
      "        [-15.3826, -22.3261,  59.3751]])\n",
      "tensor([0.2687, 0.2948])\n",
      "Epoch: 747\n",
      "Loss: tensor(38.5622, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5184,  0.6390,  1.2051],\n",
      "        [-0.4597,  0.5461,  1.5418]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.4910, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.0115, -22.1546,  47.9789],\n",
      "        [-15.3616, -22.3106,  59.3192]])\n",
      "tensor([0.2683, 0.2946])\n",
      "Epoch: 748\n",
      "Loss: tensor(38.4910, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5183,  0.6392,  1.2046],\n",
      "        [-0.4595,  0.5464,  1.5413]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.4200, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.0232, -22.1171,  47.9361],\n",
      "        [-15.3408, -22.2951,  59.2633]])\n",
      "tensor([0.2679, 0.2943])\n",
      "Epoch: 749\n",
      "Loss: tensor(38.4200, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5182,  0.6395,  1.2041],\n",
      "        [-0.4594,  0.5466,  1.5407]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.3490, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.0351, -22.0799,  47.8932],\n",
      "        [-15.3205, -22.2803,  59.2070]])\n",
      "tensor([0.2676, 0.2941])\n",
      "Epoch: 750\n",
      "Loss: tensor(38.3490, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5181,  0.6397,  1.2036],\n",
      "        [-0.4592,  0.5468,  1.5401]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.2782, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.0468, -22.0430,  47.8503],\n",
      "        [-15.2998, -22.2647,  59.1512]])\n",
      "tensor([0.2672, 0.2939])\n",
      "Epoch: 751\n",
      "Loss: tensor(38.2782, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5181,  0.6399,  1.2031],\n",
      "        [-0.4590,  0.5470,  1.5395]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0347,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.2076, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.0587, -22.0065,  47.8072],\n",
      "        [-15.2797, -22.2498,  59.0951]])\n",
      "tensor([0.2668, 0.2937])\n",
      "Epoch: 752\n",
      "Loss: tensor(38.2076, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5180,  0.6401,  1.2027],\n",
      "        [-0.4589,  0.5472,  1.5389]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.1370, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.0695, -21.9691,  47.7649],\n",
      "        [-15.2589, -22.2339,  59.0395]])\n",
      "tensor([0.2664, 0.2935])\n",
      "Epoch: 753\n",
      "Loss: tensor(38.1370, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5179,  0.6403,  1.2022],\n",
      "        [-0.4587,  0.5475,  1.5383]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(38.0667, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.0803, -21.9319,  47.7225],\n",
      "        [-15.2387, -22.2187,  58.9837]])\n",
      "tensor([0.2661, 0.2933])\n",
      "Epoch: 754\n",
      "Loss: tensor(38.0667, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5178,  0.6406,  1.2017],\n",
      "        [-0.4586,  0.5477,  1.5377]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(37.9964, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.0915, -21.8956,  47.6797],\n",
      "        [-15.2186, -22.2036,  58.9278]])\n",
      "tensor([0.2657, 0.2931])\n",
      "Epoch: 755\n",
      "Loss: tensor(37.9964, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5177,  0.6408,  1.2012],\n",
      "        [-0.4584,  0.5479,  1.5371]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(37.9263, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.1021, -21.8587,  47.6373],\n",
      "        [-15.1979, -22.1878,  58.8725]])\n",
      "tensor([0.2653, 0.2929])\n",
      "Epoch: 756\n",
      "Loss: tensor(37.9263, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5177,  0.6410,  1.2008],\n",
      "        [-0.4583,  0.5481,  1.5365]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(37.8563, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.1133, -21.8229,  47.5944],\n",
      "        [-15.1783, -22.1729,  58.8165]])\n",
      "tensor([0.2650, 0.2927])\n",
      "Epoch: 757\n",
      "Loss: tensor(37.8563, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5176,  0.6412,  1.2003],\n",
      "        [-0.4581,  0.5484,  1.5359]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(37.7865, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.1247, -21.7877,  47.5513],\n",
      "        [-15.1581, -22.1573,  58.7611]])\n",
      "tensor([0.2646, 0.2925])\n",
      "Epoch: 758\n",
      "Loss: tensor(37.7865, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5175,  0.6414,  1.1998],\n",
      "        [-0.4580,  0.5486,  1.5354]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(37.7167, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.1350, -21.7513,  47.5090],\n",
      "        [-15.1379, -22.1417,  58.7056]])\n",
      "tensor([0.2642, 0.2922])\n",
      "Epoch: 759\n",
      "Loss: tensor(37.7167, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5174,  0.6416,  1.1993],\n",
      "        [-0.4578,  0.5488,  1.5348]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(37.6471, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.1453, -21.7152,  47.4666],\n",
      "        [-15.1181, -22.1264,  58.6501]])\n",
      "tensor([0.2639, 0.2920])\n",
      "Epoch: 760\n",
      "Loss: tensor(37.6471, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5173,  0.6419,  1.1989],\n",
      "        [-0.4577,  0.5490,  1.5342]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(37.5777, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.1556, -21.6796,  47.4240],\n",
      "        [-15.0979, -22.1108,  58.5948]])\n",
      "tensor([0.2635, 0.2918])\n",
      "Epoch: 761\n",
      "Loss: tensor(37.5777, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5173,  0.6421,  1.1984],\n",
      "        [-0.4575,  0.5492,  1.5336]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(37.5084, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.1653, -21.6434,  47.3818],\n",
      "        [-15.0775, -22.0946,  58.5399]])\n",
      "tensor([0.2632, 0.2916])\n",
      "Epoch: 762\n",
      "Loss: tensor(37.5084, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5172,  0.6423,  1.1979],\n",
      "        [-0.4574,  0.5495,  1.5330]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(37.4392, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.1754, -21.6079,  47.3394],\n",
      "        [-15.0581, -22.0795,  58.4843]])\n",
      "tensor([0.2628, 0.2914])\n",
      "Epoch: 763\n",
      "Loss: tensor(37.4392, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5171,  0.6425,  1.1974],\n",
      "        [-0.4572,  0.5497,  1.5324]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(37.3701, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.1856, -21.5729,  47.2967],\n",
      "        [-15.0380, -22.0638,  58.4292]])\n",
      "tensor([0.2624, 0.2912])\n",
      "Epoch: 764\n",
      "Loss: tensor(37.3701, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5170,  0.6427,  1.1970],\n",
      "        [-0.4571,  0.5499,  1.5318]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(37.3012, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.1957, -21.5378,  47.2543],\n",
      "        [-15.0182, -22.0482,  58.3741]])\n",
      "tensor([0.2621, 0.2910])\n",
      "Epoch: 765\n",
      "Loss: tensor(37.3012, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5169,  0.6429,  1.1965],\n",
      "        [-0.4569,  0.5501,  1.5313]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4650], grad_fn=<SubBackward0>)\n",
      "tensor(37.2323, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.2053, -21.5027,  47.2120],\n",
      "        [-14.9986, -22.0326,  58.3190]])\n",
      "tensor([0.2617, 0.2908])\n",
      "Epoch: 766\n",
      "Loss: tensor(37.2323, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5168,  0.6432,  1.1960],\n",
      "        [-0.4568,  0.5503,  1.5307]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(37.1637, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.2143, -21.4671,  47.1700],\n",
      "        [-14.9785, -22.0163,  58.2643]])\n",
      "tensor([0.2614, 0.2906])\n",
      "Epoch: 767\n",
      "Loss: tensor(37.1637, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5168,  0.6434,  1.1955],\n",
      "        [-0.4566,  0.5506,  1.5301]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(37.0952, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.2236, -21.4321,  47.1278],\n",
      "        [-14.9593, -22.0013,  58.2091]])\n",
      "tensor([0.2610, 0.2904])\n",
      "Epoch: 768\n",
      "Loss: tensor(37.0952, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5167,  0.6436,  1.1951],\n",
      "        [-0.4565,  0.5508,  1.5295]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(37.0267, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.2326, -21.3969,  47.0858],\n",
      "        [-14.9399, -21.9857,  58.1540]])\n",
      "tensor([0.2607, 0.2901])\n",
      "Epoch: 769\n",
      "Loss: tensor(37.0267, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5166,  0.6438,  1.1946],\n",
      "        [-0.4563,  0.5510,  1.5289]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.9584, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.2419, -21.3624,  47.0435],\n",
      "        [-14.9198, -21.9694,  58.0995]])\n",
      "tensor([0.2603, 0.2899])\n",
      "Epoch: 770\n",
      "Loss: tensor(36.9584, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5165,  0.6440,  1.1941],\n",
      "        [-0.4562,  0.5512,  1.5283]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.8903, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.2506, -21.3275,  47.0016],\n",
      "        [-14.9006, -21.9538,  58.0446]])\n",
      "tensor([0.2600, 0.2897])\n",
      "Epoch: 771\n",
      "Loss: tensor(36.8903, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5164,  0.6442,  1.1937],\n",
      "        [-0.4560,  0.5514,  1.5278]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.8223, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.2600, -21.2935,  46.9591],\n",
      "        [-14.8808, -21.9376,  57.9901]])\n",
      "tensor([0.2596, 0.2895])\n",
      "Epoch: 772\n",
      "Loss: tensor(36.8223, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5164,  0.6444,  1.1932],\n",
      "        [-0.4559,  0.5517,  1.5272]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.7544, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.2691, -21.2596,  46.9168],\n",
      "        [-14.8621, -21.9226,  57.9351]])\n",
      "tensor([0.2592, 0.2893])\n",
      "Epoch: 773\n",
      "Loss: tensor(36.7544, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5163,  0.6447,  1.1927],\n",
      "        [-0.4557,  0.5519,  1.5266]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.6866, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.2777, -21.2254,  46.8748],\n",
      "        [-14.8428, -21.9068,  57.8804]])\n",
      "tensor([0.2589, 0.2891])\n",
      "Epoch: 774\n",
      "Loss: tensor(36.6866, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5162,  0.6449,  1.1923],\n",
      "        [-0.4556,  0.5521,  1.5260]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.6190, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.2863, -21.1913,  46.8328],\n",
      "        [-14.8232, -21.8907,  57.8260]])\n",
      "tensor([0.2586, 0.2889])\n",
      "Epoch: 775\n",
      "Loss: tensor(36.6190, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5161,  0.6451,  1.1918],\n",
      "        [-0.4554,  0.5523,  1.5254]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.5514, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.2954, -21.1580,  46.7903],\n",
      "        [-14.8043, -21.8752,  57.7713]])\n",
      "tensor([0.2582, 0.2887])\n",
      "Epoch: 776\n",
      "Loss: tensor(36.5514, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5160,  0.6453,  1.1913],\n",
      "        [-0.4553,  0.5525,  1.5249]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.4841, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.3035, -21.1238,  46.7485],\n",
      "        [-14.7848, -21.8590,  57.7171]])\n",
      "tensor([0.2579, 0.2885])\n",
      "Epoch: 777\n",
      "Loss: tensor(36.4841, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5159,  0.6455,  1.1908],\n",
      "        [-0.4551,  0.5528,  1.5243]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.4169, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.3119, -21.0903,  46.7065],\n",
      "        [-14.7664, -21.8439,  57.6622]])\n",
      "tensor([0.2575, 0.2882])\n",
      "Epoch: 778\n",
      "Loss: tensor(36.4169, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5159,  0.6457,  1.1904],\n",
      "        [-0.4550,  0.5530,  1.5237]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.3498, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.3202, -21.0571,  46.6643],\n",
      "        [-14.7468, -21.8275,  57.6083]])\n",
      "tensor([0.2572, 0.2880])\n",
      "Epoch: 779\n",
      "Loss: tensor(36.3498, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5158,  0.6459,  1.1899],\n",
      "        [-0.4548,  0.5532,  1.5231]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.2827, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.3277, -21.0229,  46.6229],\n",
      "        [-14.7286, -21.8125,  57.5534]])\n",
      "tensor([0.2568, 0.2878])\n",
      "Epoch: 780\n",
      "Loss: tensor(36.2827, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5157,  0.6461,  1.1894],\n",
      "        [-0.4547,  0.5534,  1.5226]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.2158, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.3356, -20.9895,  46.5810],\n",
      "        [-14.7095, -21.7964,  57.4992]])\n",
      "tensor([0.2565, 0.2876])\n",
      "Epoch: 781\n",
      "Loss: tensor(36.2158, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5156,  0.6463,  1.1890],\n",
      "        [-0.4546,  0.5536,  1.5220]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.1491, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.3440, -20.9569,  46.5388],\n",
      "        [-14.6899, -21.7797,  57.4456]])\n",
      "tensor([0.2562, 0.2874])\n",
      "Epoch: 782\n",
      "Loss: tensor(36.1491, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5155,  0.6466,  1.1885],\n",
      "        [-0.4544,  0.5538,  1.5214]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.0825, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.3515, -20.9236,  46.4970],\n",
      "        [-14.6712, -21.7639,  57.3913]])\n",
      "tensor([0.2558, 0.2872])\n",
      "Epoch: 783\n",
      "Loss: tensor(36.0825, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5154,  0.6468,  1.1881],\n",
      "        [-0.4543,  0.5541,  1.5208]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(36.0160, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.3590, -20.8904,  46.4554],\n",
      "        [-14.6524, -21.7480,  57.3373]])\n",
      "tensor([0.2555, 0.2870])\n",
      "Epoch: 784\n",
      "Loss: tensor(36.0160, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5154,  0.6470,  1.1876],\n",
      "        [-0.4541,  0.5543,  1.5203]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.9496, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.3669, -20.8580,  46.4133],\n",
      "        [-14.6335, -21.7321,  57.2833]])\n",
      "tensor([0.2551, 0.2868])\n",
      "Epoch: 785\n",
      "Loss: tensor(35.9496, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5153,  0.6472,  1.1871],\n",
      "        [-0.4540,  0.5545,  1.5197]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.8834, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.3741, -20.8249,  46.3718],\n",
      "        [-14.6150, -21.7163,  57.2291]])\n",
      "tensor([0.2548, 0.2866])\n",
      "Epoch: 786\n",
      "Loss: tensor(35.8834, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5152,  0.6474,  1.1867],\n",
      "        [-0.4538,  0.5547,  1.5191]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.8173, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.3813, -20.7923,  46.3301],\n",
      "        [-14.5967, -21.7006,  57.1751]])\n",
      "tensor([0.2545, 0.2863])\n",
      "Epoch: 787\n",
      "Loss: tensor(35.8173, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5151,  0.6476,  1.1862],\n",
      "        [-0.4537,  0.5549,  1.5186]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.7513, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.3888, -20.7601,  46.2882],\n",
      "        [-14.5775, -21.6840,  57.1216]])\n",
      "tensor([0.2541, 0.2861])\n",
      "Epoch: 788\n",
      "Loss: tensor(35.7513, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5150,  0.6478,  1.1857],\n",
      "        [-0.4535,  0.5551,  1.5180]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.6854, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.3961, -20.7279,  46.2464],\n",
      "        [-14.5592, -21.6682,  57.0676]])\n",
      "tensor([0.2538, 0.2859])\n",
      "Epoch: 789\n",
      "Loss: tensor(35.6854, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5149,  0.6480,  1.1853],\n",
      "        [-0.4534,  0.5554,  1.5174]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.6197, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4023, -20.6947,  46.2054],\n",
      "        [-14.5411, -21.6527,  57.0136]])\n",
      "tensor([0.2535, 0.2857])\n",
      "Epoch: 790\n",
      "Loss: tensor(35.6197, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5148,  0.6482,  1.1848],\n",
      "        [-0.4532,  0.5556,  1.5168]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0348,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.5541, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4093, -20.6627,  46.1637],\n",
      "        [-14.5230, -21.6370,  56.9597]])\n",
      "tensor([0.2531, 0.2855])\n",
      "Epoch: 791\n",
      "Loss: tensor(35.5541, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5148,  0.6484,  1.1843],\n",
      "        [-0.4531,  0.5558,  1.5163]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.4886, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4159, -20.6304,  46.1222],\n",
      "        [-14.5045, -21.6209,  56.9061]])\n",
      "tensor([0.2528, 0.2853])\n",
      "Epoch: 792\n",
      "Loss: tensor(35.4886, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5147,  0.6486,  1.1839],\n",
      "        [-0.4529,  0.5560,  1.5157]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.4232, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4225, -20.5983,  46.0808],\n",
      "        [-14.4864, -21.6053,  56.8523]])\n",
      "tensor([0.2525, 0.2851])\n",
      "Epoch: 793\n",
      "Loss: tensor(35.4232, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5146,  0.6488,  1.1834],\n",
      "        [-0.4528,  0.5562,  1.5151]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.3580, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4296, -20.5670,  46.0390],\n",
      "        [-14.4676, -21.5886,  56.7991]])\n",
      "tensor([0.2522, 0.2849])\n",
      "Epoch: 794\n",
      "Loss: tensor(35.3580, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5145,  0.6490,  1.1830],\n",
      "        [-0.4527,  0.5564,  1.5146]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.2928, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4362, -20.5353,  45.9975],\n",
      "        [-14.4495, -21.5726,  56.7455]])\n",
      "tensor([0.2518, 0.2847])\n",
      "Epoch: 795\n",
      "Loss: tensor(35.2928, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5144,  0.6492,  1.1825],\n",
      "        [-0.4525,  0.5567,  1.5140]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.2278, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4431, -20.5042,  45.9557],\n",
      "        [-14.4313, -21.5566,  56.6921]])\n",
      "tensor([0.2515, 0.2844])\n",
      "Epoch: 796\n",
      "Loss: tensor(35.2278, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5143,  0.6495,  1.1820],\n",
      "        [-0.4524,  0.5569,  1.5134]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.1630, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4496, -20.4730,  45.9141],\n",
      "        [-14.4133, -21.5407,  56.6385]])\n",
      "tensor([0.2512, 0.2842])\n",
      "Epoch: 797\n",
      "Loss: tensor(35.1630, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5143,  0.6497,  1.1816],\n",
      "        [-0.4522,  0.5571,  1.5129]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.0982, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4557, -20.4414,  45.8728],\n",
      "        [-14.3950, -21.5244,  56.5853]])\n",
      "tensor([0.2509, 0.2840])\n",
      "Epoch: 798\n",
      "Loss: tensor(35.0982, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5142,  0.6499,  1.1811],\n",
      "        [-0.4521,  0.5573,  1.5123]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(35.0335, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4614, -20.4096,  45.8317],\n",
      "        [-14.3771, -21.5084,  56.5319]])\n",
      "tensor([0.2505, 0.2838])\n",
      "Epoch: 799\n",
      "Loss: tensor(35.0335, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5141,  0.6501,  1.1807],\n",
      "        [-0.4519,  0.5575,  1.5117]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(34.9691, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4678, -20.3790,  45.7901],\n",
      "        [-14.3588, -21.4920,  56.4790]])\n",
      "tensor([0.2502, 0.2836])\n",
      "Epoch: 800\n",
      "Loss: tensor(34.9691, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5140,  0.6503,  1.1802],\n",
      "        [-0.4518,  0.5577,  1.5112]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(34.9046, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4734, -20.3474,  45.7490],\n",
      "        [-14.3408, -21.4760,  56.4256]])\n",
      "tensor([0.2499, 0.2834])\n",
      "Epoch: 801\n",
      "Loss: tensor(34.9046, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5139,  0.6505,  1.1798],\n",
      "        [-0.4516,  0.5580,  1.5106]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.8404, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4790, -20.3161,  45.7079],\n",
      "        [-14.3228, -21.4597,  56.3727]])\n",
      "tensor([0.2496, 0.2832])\n",
      "Epoch: 802\n",
      "Loss: tensor(34.8404, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5138,  0.6507,  1.1793],\n",
      "        [-0.4515,  0.5582,  1.5100]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.7763, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4852, -20.2859,  45.6663],\n",
      "        [-14.3049, -21.4436,  56.3195]])\n",
      "tensor([0.2493, 0.2830])\n",
      "Epoch: 803\n",
      "Loss: tensor(34.7763, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5138,  0.6509,  1.1788],\n",
      "        [-0.4514,  0.5584,  1.5095]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.7123, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4908, -20.2550,  45.6252],\n",
      "        [-14.2868, -21.4271,  56.2668]])\n",
      "tensor([0.2489, 0.2828])\n",
      "Epoch: 804\n",
      "Loss: tensor(34.7123, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5137,  0.6511,  1.1784],\n",
      "        [-0.4512,  0.5586,  1.5089]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.6484, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4961, -20.2241,  45.5842],\n",
      "        [-14.2692, -21.4113,  56.2136]])\n",
      "tensor([0.2486, 0.2825])\n",
      "Epoch: 805\n",
      "Loss: tensor(34.6484, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5136,  0.6513,  1.1779],\n",
      "        [-0.4511,  0.5588,  1.5084]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.5846, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5024, -20.1944,  45.5425],\n",
      "        [-14.2514, -21.3950,  56.1607]])\n",
      "tensor([0.2483, 0.2823])\n",
      "Epoch: 806\n",
      "Loss: tensor(34.5846, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5135,  0.6515,  1.1775],\n",
      "        [-0.4509,  0.5590,  1.5078]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.5209, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5073, -20.1634,  45.5017],\n",
      "        [-14.2342, -21.3794,  56.1074]])\n",
      "tensor([0.2480, 0.2821])\n",
      "Epoch: 807\n",
      "Loss: tensor(34.5209, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5134,  0.6517,  1.1770],\n",
      "        [-0.4508,  0.5592,  1.5072]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.4573, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5128, -20.1331,  45.4605],\n",
      "        [-14.2166, -21.3633,  56.0546]])\n",
      "tensor([0.2477, 0.2819])\n",
      "Epoch: 808\n",
      "Loss: tensor(34.4573, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5133,  0.6519,  1.1766],\n",
      "        [-0.4506,  0.5595,  1.5067]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.3939, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5186, -20.1036,  45.4190],\n",
      "        [-14.1987, -21.3468,  56.0021]])\n",
      "tensor([0.2474, 0.2817])\n",
      "Epoch: 809\n",
      "Loss: tensor(34.3939, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5132,  0.6521,  1.1761],\n",
      "        [-0.4505,  0.5597,  1.5061]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.3306, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5235, -20.0732,  45.3781],\n",
      "        [-14.1817, -21.3312,  55.9490]])\n",
      "tensor([0.2470, 0.2815])\n",
      "Epoch: 810\n",
      "Loss: tensor(34.3306, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5132,  0.6523,  1.1757],\n",
      "        [-0.4504,  0.5599,  1.5055]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.2674, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5288, -20.0433,  45.3369],\n",
      "        [-14.1639, -21.3148,  55.8965]])\n",
      "tensor([0.2467, 0.2813])\n",
      "Epoch: 811\n",
      "Loss: tensor(34.2674, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5131,  0.6525,  1.1752],\n",
      "        [-0.4502,  0.5601,  1.5050]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.2044, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5333, -20.0130,  45.2962],\n",
      "        [-14.1462, -21.2983,  55.8440]])\n",
      "tensor([0.2464, 0.2811])\n",
      "Epoch: 812\n",
      "Loss: tensor(34.2044, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5130,  0.6527,  1.1747],\n",
      "        [-0.4501,  0.5603,  1.5044]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.1414, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5381, -19.9830,  45.2553],\n",
      "        [-14.1291, -21.2826,  55.7912]])\n",
      "tensor([0.2461, 0.2808])\n",
      "Epoch: 813\n",
      "Loss: tensor(34.1414, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5129,  0.6529,  1.1743],\n",
      "        [-0.4499,  0.5605,  1.5039]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.0786, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5427, -19.9531,  45.2146],\n",
      "        [-14.1113, -21.2657,  55.7391]])\n",
      "tensor([0.2458, 0.2806])\n",
      "Epoch: 814\n",
      "Loss: tensor(34.0786, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5128,  0.6531,  1.1738],\n",
      "        [-0.4498,  0.5607,  1.5033]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(34.0159, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5477, -19.9237,  45.1734],\n",
      "        [-14.0939, -21.2494,  55.6867]])\n",
      "tensor([0.2455, 0.2804])\n",
      "Epoch: 815\n",
      "Loss: tensor(34.0159, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5127,  0.6533,  1.1734],\n",
      "        [-0.4497,  0.5609,  1.5028]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.9533, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5518, -19.8935,  45.1330],\n",
      "        [-14.0768, -21.2335,  55.6341]])\n",
      "tensor([0.2452, 0.2802])\n",
      "Epoch: 816\n",
      "Loss: tensor(33.9533, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5126,  0.6535,  1.1729],\n",
      "        [-0.4495,  0.5612,  1.5022]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.8908, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5561, -19.8637,  45.0923],\n",
      "        [-14.0597, -21.2175,  55.5815]])\n",
      "tensor([0.2449, 0.2800])\n",
      "Epoch: 817\n",
      "Loss: tensor(33.8908, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5126,  0.6537,  1.1725],\n",
      "        [-0.4494,  0.5614,  1.5016]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.8284, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5612, -19.8352,  45.0510],\n",
      "        [-14.0423, -21.2009,  55.5294]])\n",
      "tensor([0.2446, 0.2798])\n",
      "Epoch: 818\n",
      "Loss: tensor(33.8284, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5125,  0.6539,  1.1720],\n",
      "        [-0.4492,  0.5616,  1.5011]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.7662, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5654, -19.8056,  45.0104],\n",
      "        [-14.0252, -21.1847,  55.4772]])\n",
      "tensor([0.2443, 0.2796])\n",
      "Epoch: 819\n",
      "Loss: tensor(33.7662, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5124,  0.6541,  1.1716],\n",
      "        [-0.4491,  0.5618,  1.5005]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.7041, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5702, -19.7771,  44.9693],\n",
      "        [-14.0082, -21.1687,  55.4248]])\n",
      "tensor([0.2440, 0.2794])\n",
      "Epoch: 820\n",
      "Loss: tensor(33.7041, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5123,  0.6543,  1.1711],\n",
      "        [-0.4490,  0.5620,  1.5000]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.6421, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5741, -19.7478,  44.9286],\n",
      "        [-13.9906, -21.1518,  55.3730]])\n",
      "tensor([0.2437, 0.2792])\n",
      "Epoch: 821\n",
      "Loss: tensor(33.6421, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5122,  0.6545,  1.1707],\n",
      "        [-0.4488,  0.5622,  1.4994]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.5802, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5781, -19.7186,  44.8881],\n",
      "        [-13.9734, -21.1354,  55.3210]])\n",
      "tensor([0.2434, 0.2790])\n",
      "Epoch: 822\n",
      "Loss: tensor(33.5802, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5121,  0.6547,  1.1702],\n",
      "        [-0.4487,  0.5624,  1.4989]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.5184, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5821, -19.6896,  44.8475],\n",
      "        [-13.9566, -21.1193,  55.2688]])\n",
      "tensor([0.2431, 0.2787])\n",
      "Epoch: 823\n",
      "Loss: tensor(33.5184, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5120,  0.6549,  1.1698],\n",
      "        [-0.4485,  0.5626,  1.4983]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.4568, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5864, -19.6613,  44.8066],\n",
      "        [-13.9396, -21.1030,  55.2169]])\n",
      "tensor([0.2428, 0.2785])\n",
      "Epoch: 824\n",
      "Loss: tensor(33.4568, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5120,  0.6551,  1.1693],\n",
      "        [-0.4484,  0.5628,  1.4978]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.3953, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5901, -19.6323,  44.7662],\n",
      "        [-13.9226, -21.0866,  55.1649]])\n",
      "tensor([0.2425, 0.2783])\n",
      "Epoch: 825\n",
      "Loss: tensor(33.3953, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5119,  0.6553,  1.1689],\n",
      "        [-0.4483,  0.5631,  1.4972]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.3338, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5937, -19.6035,  44.7257],\n",
      "        [-13.9064, -21.0709,  55.1127]])\n",
      "tensor([0.2422, 0.2781])\n",
      "Epoch: 826\n",
      "Loss: tensor(33.3338, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5118,  0.6555,  1.1685],\n",
      "        [-0.4481,  0.5633,  1.4967]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.2725, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5976, -19.5753,  44.6850],\n",
      "        [-13.8895, -21.0547,  55.0608]])\n",
      "tensor([0.2419, 0.2779])\n",
      "Epoch: 827\n",
      "Loss: tensor(33.2725, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5117,  0.6557,  1.1680],\n",
      "        [-0.4480,  0.5635,  1.4961]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.2114, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6013, -19.5468,  44.6446],\n",
      "        [-13.8727, -21.0385,  55.0090]])\n",
      "tensor([0.2416, 0.2777])\n",
      "Epoch: 828\n",
      "Loss: tensor(33.2114, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5116,  0.6559,  1.1676],\n",
      "        [-0.4478,  0.5637,  1.4956]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.1503, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6049, -19.5185,  44.6041],\n",
      "        [-13.8552, -21.0213,  54.9577]])\n",
      "tensor([0.2413, 0.2775])\n",
      "Epoch: 829\n",
      "Loss: tensor(33.1503, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5115,  0.6561,  1.1671],\n",
      "        [-0.4477,  0.5639,  1.4950]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.0894, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6084, -19.4903,  44.5636],\n",
      "        [-13.8386, -21.0051,  54.9060]])\n",
      "tensor([0.2410, 0.2773])\n",
      "Epoch: 830\n",
      "Loss: tensor(33.0894, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5114,  0.6562,  1.1667],\n",
      "        [-0.4476,  0.5641,  1.4945]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0349,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(33.0285, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6121, -19.4624,  44.5230],\n",
      "        [-13.8218, -20.9886,  54.8544]])\n",
      "tensor([0.2407, 0.2771])\n",
      "Epoch: 831\n",
      "Loss: tensor(33.0285, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5114,  0.6564,  1.1662],\n",
      "        [-0.4474,  0.5643,  1.4939]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(32.9677, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6153, -19.4342,  44.4827],\n",
      "        [-13.8057, -20.9728,  54.8025]])\n",
      "tensor([0.2404, 0.2768])\n",
      "Epoch: 832\n",
      "Loss: tensor(32.9677, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5113,  0.6566,  1.1658],\n",
      "        [-0.4473,  0.5645,  1.4934]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(32.9071, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6183, -19.4058,  44.4426],\n",
      "        [-13.7889, -20.9564,  54.7510]])\n",
      "tensor([0.2401, 0.2766])\n",
      "Epoch: 833\n",
      "Loss: tensor(32.9071, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5112,  0.6568,  1.1653],\n",
      "        [-0.4472,  0.5647,  1.4928]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(32.8466, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6217, -19.3783,  44.4021],\n",
      "        [-13.7723, -20.9400,  54.6995]])\n",
      "tensor([0.2398, 0.2764])\n",
      "Epoch: 834\n",
      "Loss: tensor(32.8466, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5111,  0.6570,  1.1649],\n",
      "        [-0.4470,  0.5649,  1.4923]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(32.7862, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6250, -19.3507,  44.3616],\n",
      "        [-13.7562, -20.9240,  54.6479]])\n",
      "tensor([0.2395, 0.2762])\n",
      "Epoch: 835\n",
      "Loss: tensor(32.7862, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5110,  0.6572,  1.1644],\n",
      "        [-0.4469,  0.5652,  1.4917]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4648], grad_fn=<SubBackward0>)\n",
      "tensor(32.7259, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6277, -19.3225,  44.3216],\n",
      "        [-13.7393, -20.9073,  54.5967]])\n",
      "tensor([0.2392, 0.2760])\n",
      "Epoch: 836\n",
      "Loss: tensor(32.7259, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5109,  0.6574,  1.1640],\n",
      "        [-0.4467,  0.5654,  1.4912]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(32.6658, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6312, -19.2955,  44.2810],\n",
      "        [-13.7229, -20.8909,  54.5454]])\n",
      "tensor([0.2389, 0.2758])\n",
      "Epoch: 837\n",
      "Loss: tensor(32.6658, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5108,  0.6576,  1.1636],\n",
      "        [-0.4466,  0.5656,  1.4906]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(32.6057, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6343, -19.2681,  44.2407],\n",
      "        [-13.7068, -20.8750,  54.4938]])\n",
      "tensor([0.2386, 0.2756])\n",
      "Epoch: 838\n",
      "Loss: tensor(32.6057, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5108,  0.6578,  1.1631],\n",
      "        [-0.4465,  0.5658,  1.4901]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(32.5458, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6366, -19.2402,  44.2009],\n",
      "        [-13.6900, -20.8580,  54.4429]])\n",
      "tensor([0.2383, 0.2754])\n",
      "Epoch: 839\n",
      "Loss: tensor(32.5458, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5107,  0.6580,  1.1627],\n",
      "        [-0.4463,  0.5660,  1.4895]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(32.4859, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6400, -19.2135,  44.1603],\n",
      "        [-13.6738, -20.8418,  54.3916]])\n",
      "tensor([0.2380, 0.2751])\n",
      "Epoch: 840\n",
      "Loss: tensor(32.4859, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5106,  0.6582,  1.1622],\n",
      "        [-0.4462,  0.5662,  1.4890]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(32.4263, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6421, -19.1856,  44.1206],\n",
      "        [-13.6582, -20.8261,  54.3400]])\n",
      "tensor([0.2378, 0.2749])\n",
      "Epoch: 841\n",
      "Loss: tensor(32.4263, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5105,  0.6584,  1.1618],\n",
      "        [-0.4461,  0.5664,  1.4885]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(32.3667, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6446, -19.1583,  44.0806],\n",
      "        [-13.6413, -20.8092,  54.2893]])\n",
      "tensor([0.2375, 0.2747])\n",
      "Epoch: 842\n",
      "Loss: tensor(32.3667, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5104,  0.6586,  1.1613],\n",
      "        [-0.4459,  0.5666,  1.4879]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(32.3072, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6478, -19.1319,  44.0400],\n",
      "        [-13.6248, -20.7925,  54.2385]])\n",
      "tensor([0.2372, 0.2745])\n",
      "Epoch: 843\n",
      "Loss: tensor(32.3072, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5103,  0.6588,  1.1609],\n",
      "        [-0.4458,  0.5668,  1.4874]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(32.2478, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6494, -19.1039,  44.0006],\n",
      "        [-13.6091, -20.7767,  54.1872]])\n",
      "tensor([0.2369, 0.2743])\n",
      "Epoch: 844\n",
      "Loss: tensor(32.2478, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5102,  0.6589,  1.1605],\n",
      "        [-0.4456,  0.5670,  1.4868]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(32.1885, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6520, -19.0771,  43.9605],\n",
      "        [-13.5928, -20.7599,  54.1364]])\n",
      "tensor([0.2366, 0.2741])\n",
      "Epoch: 845\n",
      "Loss: tensor(32.1885, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5101,  0.6591,  1.1600],\n",
      "        [-0.4455,  0.5672,  1.4863]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(32.1294, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6542, -19.0501,  43.9206],\n",
      "        [-13.5768, -20.7438,  54.0854]])\n",
      "tensor([0.2363, 0.2739])\n",
      "Epoch: 846\n",
      "Loss: tensor(32.1294, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5101,  0.6593,  1.1596],\n",
      "        [-0.4454,  0.5674,  1.4858]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(32.0703, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6566, -19.0235,  43.8806],\n",
      "        [-13.5603, -20.7268,  54.0349]])\n",
      "tensor([0.2361, 0.2737])\n",
      "Epoch: 847\n",
      "Loss: tensor(32.0703, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5100,  0.6595,  1.1592],\n",
      "        [-0.4452,  0.5677,  1.4852]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(32.0114, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6587, -18.9967,  43.8408],\n",
      "        [-13.5446, -20.7108,  53.9838]])\n",
      "tensor([0.2358, 0.2735])\n",
      "Epoch: 848\n",
      "Loss: tensor(32.0114, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5099,  0.6597,  1.1587],\n",
      "        [-0.4451,  0.5679,  1.4847]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.9526, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6610, -18.9703,  43.8008],\n",
      "        [-13.5283, -20.6942,  53.9333]])\n",
      "tensor([0.2355, 0.2733])\n",
      "Epoch: 849\n",
      "Loss: tensor(31.9526, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5098,  0.6599,  1.1583],\n",
      "        [-0.4450,  0.5681,  1.4841]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.8939, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6634, -18.9443,  43.7606],\n",
      "        [-13.5121, -20.6775,  53.8827]])\n",
      "tensor([0.2352, 0.2730])\n",
      "Epoch: 850\n",
      "Loss: tensor(31.8939, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5097,  0.6601,  1.1578],\n",
      "        [-0.4448,  0.5683,  1.4836]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.8353, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6656, -18.9179,  43.7208],\n",
      "        [-13.4962, -20.6611,  53.8321]])\n",
      "tensor([0.2349, 0.2728])\n",
      "Epoch: 851\n",
      "Loss: tensor(31.8353, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5096,  0.6603,  1.1574],\n",
      "        [-0.4447,  0.5685,  1.4831]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.7768, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6675, -18.8914,  43.6810],\n",
      "        [-13.4803, -20.6447,  53.7815]])\n",
      "tensor([0.2347, 0.2726])\n",
      "Epoch: 852\n",
      "Loss: tensor(31.7768, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5095,  0.6605,  1.1570],\n",
      "        [-0.4446,  0.5687,  1.4825]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.7184, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6699, -18.8657,  43.6410],\n",
      "        [-13.4651, -20.6290,  53.7305]])\n",
      "tensor([0.2344, 0.2724])\n",
      "Epoch: 853\n",
      "Loss: tensor(31.7184, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5095,  0.6607,  1.1565],\n",
      "        [-0.4444,  0.5689,  1.4820]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.6602, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6715, -18.8394,  43.6013],\n",
      "        [-13.4486, -20.6118,  53.6805]])\n",
      "tensor([0.2341, 0.2722])\n",
      "Epoch: 854\n",
      "Loss: tensor(31.6602, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5094,  0.6608,  1.1561],\n",
      "        [-0.4443,  0.5691,  1.4814]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.6020, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6731, -18.8131,  43.5617],\n",
      "        [-13.4329, -20.5953,  53.6301]])\n",
      "tensor([0.2338, 0.2720])\n",
      "Epoch: 855\n",
      "Loss: tensor(31.6020, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5093,  0.6610,  1.1557],\n",
      "        [-0.4442,  0.5693,  1.4809]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.5439, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6748, -18.7871,  43.5220],\n",
      "        [-13.4174, -20.5793,  53.5794]])\n",
      "tensor([0.2335, 0.2718])\n",
      "Epoch: 856\n",
      "Loss: tensor(31.5439, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5092,  0.6612,  1.1552],\n",
      "        [-0.4440,  0.5695,  1.4804]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.4860, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6766, -18.7613,  43.4822],\n",
      "        [-13.4022, -20.5635,  53.5288]])\n",
      "tensor([0.2333, 0.2716])\n",
      "Epoch: 857\n",
      "Loss: tensor(31.4860, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5091,  0.6614,  1.1548],\n",
      "        [-0.4439,  0.5697,  1.4798]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.4282, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6781, -18.7353,  43.4427],\n",
      "        [-13.3859, -20.5464,  53.4788]])\n",
      "tensor([0.2330, 0.2714])\n",
      "Epoch: 858\n",
      "Loss: tensor(31.4282, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5090,  0.6616,  1.1544],\n",
      "        [-0.4438,  0.5699,  1.4793]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.3704, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6791, -18.7090,  43.4035],\n",
      "        [-13.3702, -20.5298,  53.4286]])\n",
      "tensor([0.2327, 0.2711])\n",
      "Epoch: 859\n",
      "Loss: tensor(31.3704, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5089,  0.6618,  1.1539],\n",
      "        [-0.4436,  0.5701,  1.4788]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.3128, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6811, -18.6838,  43.3636],\n",
      "        [-13.3549, -20.5138,  53.3782]])\n",
      "tensor([0.2324, 0.2709])\n",
      "Epoch: 860\n",
      "Loss: tensor(31.3128, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5088,  0.6620,  1.1535],\n",
      "        [-0.4435,  0.5703,  1.4782]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.2553, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6823, -18.6580,  43.3241],\n",
      "        [-13.3392, -20.4971,  53.3282]])\n",
      "tensor([0.2322, 0.2707])\n",
      "Epoch: 861\n",
      "Loss: tensor(31.2553, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5088,  0.6622,  1.1531],\n",
      "        [-0.4434,  0.5705,  1.4777]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.1979, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6833, -18.6320,  43.2849],\n",
      "        [-13.3232, -20.4801,  53.2784]])\n",
      "tensor([0.2319, 0.2705])\n",
      "Epoch: 862\n",
      "Loss: tensor(31.1979, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5087,  0.6623,  1.1526],\n",
      "        [-0.4432,  0.5707,  1.4772]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.1406, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6847, -18.6067,  43.2453],\n",
      "        [-13.3076, -20.4638,  53.2283]])\n",
      "tensor([0.2316, 0.2703])\n",
      "Epoch: 863\n",
      "Loss: tensor(31.1406, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5086,  0.6625,  1.1522],\n",
      "        [-0.4431,  0.5709,  1.4766]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.0834, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6858, -18.5812,  43.2060],\n",
      "        [-13.2922, -20.4473,  53.1783]])\n",
      "tensor([0.2314, 0.2701])\n",
      "Epoch: 864\n",
      "Loss: tensor(31.0834, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5085,  0.6627,  1.1518],\n",
      "        [-0.4430,  0.5712,  1.4761]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(31.0264, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6869, -18.5558,  43.1666],\n",
      "        [-13.2769, -20.4311,  53.1282]])\n",
      "tensor([0.2311, 0.2699])\n",
      "Epoch: 865\n",
      "Loss: tensor(31.0264, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5084,  0.6629,  1.1513],\n",
      "        [-0.4428,  0.5714,  1.4756]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(30.9694, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6885, -18.5311,  43.1269],\n",
      "        [-13.2619, -20.4150,  53.0781]])\n",
      "tensor([0.2308, 0.2697])\n",
      "Epoch: 866\n",
      "Loss: tensor(30.9694, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5083,  0.6631,  1.1509],\n",
      "        [-0.4427,  0.5716,  1.4750]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(30.9125, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6891, -18.5054,  43.0878],\n",
      "        [-13.2462, -20.3983,  53.0284]])\n",
      "tensor([0.2305, 0.2695])\n",
      "Epoch: 867\n",
      "Loss: tensor(30.9125, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5082,  0.6633,  1.1505],\n",
      "        [-0.4426,  0.5718,  1.4745]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(30.8558, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6896, -18.4798,  43.0489],\n",
      "        [-13.2306, -20.3815,  52.9788]])\n",
      "tensor([0.2303, 0.2693])\n",
      "Epoch: 868\n",
      "Loss: tensor(30.8558, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5082,  0.6635,  1.1500],\n",
      "        [-0.4424,  0.5720,  1.4740]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(30.7992, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6907, -18.4550,  43.0095],\n",
      "        [-13.2158, -20.3656,  52.9287]])\n",
      "tensor([0.2300, 0.2690])\n",
      "Epoch: 869\n",
      "Loss: tensor(30.7992, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5081,  0.6636,  1.1496],\n",
      "        [-0.4423,  0.5722,  1.4735]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(30.7426, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6917, -18.4302,  42.9701],\n",
      "        [-13.2004, -20.3490,  52.8791]])\n",
      "tensor([0.2297, 0.2688])\n",
      "Epoch: 870\n",
      "Loss: tensor(30.7426, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5080,  0.6638,  1.1492],\n",
      "        [-0.4422,  0.5724,  1.4729]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(30.6862, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6924, -18.4051,  42.9310],\n",
      "        [-13.1852, -20.3326,  52.8294]])\n",
      "tensor([0.2295, 0.2686])\n",
      "Epoch: 871\n",
      "Loss: tensor(30.6862, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5079,  0.6640,  1.1487],\n",
      "        [-0.4420,  0.5726,  1.4724]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(30.6298, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6932, -18.3804,  42.8917],\n",
      "        [-13.1709, -20.3171,  52.7792]])\n",
      "tensor([0.2292, 0.2684])\n",
      "Epoch: 872\n",
      "Loss: tensor(30.6298, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5078,  0.6642,  1.1483],\n",
      "        [-0.4419,  0.5728,  1.4719]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4647], grad_fn=<SubBackward0>)\n",
      "tensor(30.5736, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6944, -18.3562,  42.8522],\n",
      "        [-13.1546, -20.2994,  52.7304]])\n",
      "tensor([0.2289, 0.2682])\n",
      "Epoch: 873\n",
      "Loss: tensor(30.5736, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5077,  0.6644,  1.1479],\n",
      "        [-0.4418,  0.5730,  1.4713]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0350,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(30.5175, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6945, -18.3309,  42.8135],\n",
      "        [-13.1396, -20.2831,  52.6808]])\n",
      "tensor([0.2287, 0.2680])\n",
      "Epoch: 874\n",
      "Loss: tensor(30.5175, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5076,  0.6646,  1.1475],\n",
      "        [-0.4416,  0.5732,  1.4708]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(30.4615, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6949, -18.3062,  42.7745],\n",
      "        [-13.1241, -20.2662,  52.6316]])\n",
      "tensor([0.2284, 0.2678])\n",
      "Epoch: 875\n",
      "Loss: tensor(30.4615, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5075,  0.6647,  1.1470],\n",
      "        [-0.4415,  0.5734,  1.4703]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(30.4056, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6952, -18.2814,  42.7356],\n",
      "        [-13.1085, -20.2493,  52.5825]])\n",
      "tensor([0.2282, 0.2676])\n",
      "Epoch: 876\n",
      "Loss: tensor(30.4056, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5075,  0.6649,  1.1466],\n",
      "        [-0.4414,  0.5736,  1.4698]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(30.3498, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6958, -18.2572,  42.6964],\n",
      "        [-13.0945, -20.2339,  52.5324]])\n",
      "tensor([0.2279, 0.2674])\n",
      "Epoch: 877\n",
      "Loss: tensor(30.3498, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5074,  0.6651,  1.1462],\n",
      "        [-0.4412,  0.5738,  1.4692]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(30.2941, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6960, -18.2325,  42.6576],\n",
      "        [-13.0792, -20.2172,  52.4833]])\n",
      "tensor([0.2276, 0.2672])\n",
      "Epoch: 878\n",
      "Loss: tensor(30.2941, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5073,  0.6653,  1.1457],\n",
      "        [-0.4411,  0.5740,  1.4687]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(30.2385, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6966, -18.2085,  42.6185],\n",
      "        [-13.0641, -20.2005,  52.4341]])\n",
      "tensor([0.2274, 0.2670])\n",
      "Epoch: 879\n",
      "Loss: tensor(30.2385, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5072,  0.6655,  1.1453],\n",
      "        [-0.4410,  0.5742,  1.4682]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(30.1830, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6968, -18.1841,  42.5796],\n",
      "        [-13.0491, -20.1841,  52.3848]])\n",
      "tensor([0.2271, 0.2668])\n",
      "Epoch: 880\n",
      "Loss: tensor(30.1830, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5071,  0.6656,  1.1449],\n",
      "        [-0.4409,  0.5744,  1.4677]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(30.1276, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6970, -18.1598,  42.5407],\n",
      "        [-13.0338, -20.1672,  52.3359]])\n",
      "tensor([0.2269, 0.2665])\n",
      "Epoch: 881\n",
      "Loss: tensor(30.1276, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5070,  0.6658,  1.1445],\n",
      "        [-0.4407,  0.5746,  1.4671]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(30.0723, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6971, -18.1356,  42.5019],\n",
      "        [-13.0187, -20.1505,  52.2870]])\n",
      "tensor([0.2266, 0.2663])\n",
      "Epoch: 882\n",
      "Loss: tensor(30.0723, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5069,  0.6660,  1.1440],\n",
      "        [-0.4406,  0.5748,  1.4666]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(30.0171, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6972, -18.1114,  42.4631],\n",
      "        [-13.0039, -20.1341,  52.2378]])\n",
      "tensor([0.2263, 0.2661])\n",
      "Epoch: 883\n",
      "Loss: tensor(30.0171, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5068,  0.6662,  1.1436],\n",
      "        [-0.4405,  0.5750,  1.4661]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.9621, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6971, -18.0871,  42.4245],\n",
      "        [-12.9890, -20.1176,  52.1888]])\n",
      "tensor([0.2261, 0.2659])\n",
      "Epoch: 884\n",
      "Loss: tensor(29.9621, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5068,  0.6664,  1.1432],\n",
      "        [-0.4403,  0.5752,  1.4656]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.9071, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6969, -18.0631,  42.3857],\n",
      "        [-12.9745, -20.1014,  52.1397]])\n",
      "tensor([0.2258, 0.2657])\n",
      "Epoch: 885\n",
      "Loss: tensor(29.9071, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5067,  0.6666,  1.1428],\n",
      "        [-0.4402,  0.5754,  1.4651]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.8522, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6976, -18.0400,  42.3465],\n",
      "        [-12.9606, -20.0860,  52.0901]])\n",
      "tensor([0.2256, 0.2655])\n",
      "Epoch: 886\n",
      "Loss: tensor(29.8522, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5066,  0.6667,  1.1423],\n",
      "        [-0.4401,  0.5756,  1.4645]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.7975, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6975, -18.0161,  42.3079],\n",
      "        [-12.9456, -20.0692,  52.0414]])\n",
      "tensor([0.2253, 0.2653])\n",
      "Epoch: 887\n",
      "Loss: tensor(29.7975, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5065,  0.6669,  1.1419],\n",
      "        [-0.4399,  0.5758,  1.4640]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.7428, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6971, -17.9921,  42.2693],\n",
      "        [-12.9310, -20.0528,  51.9924]])\n",
      "tensor([0.2251, 0.2651])\n",
      "Epoch: 888\n",
      "Loss: tensor(29.7428, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5064,  0.6671,  1.1415],\n",
      "        [-0.4398,  0.5760,  1.4635]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.6882, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6966, -17.9681,  42.2309],\n",
      "        [-12.9164, -20.0365,  51.9436]])\n",
      "tensor([0.2248, 0.2649])\n",
      "Epoch: 889\n",
      "Loss: tensor(29.6882, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5063,  0.6673,  1.1411],\n",
      "        [-0.4397,  0.5762,  1.4630]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.6338, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6969, -17.9450,  42.1920],\n",
      "        [-12.9009, -20.0191,  51.8954]])\n",
      "tensor([0.2245, 0.2647])\n",
      "Epoch: 890\n",
      "Loss: tensor(29.6338, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5062,  0.6675,  1.1407],\n",
      "        [-0.4396,  0.5764,  1.4625]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.5794, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6963, -17.9211,  42.1536],\n",
      "        [-12.8859, -20.0023,  51.8469]])\n",
      "tensor([0.2243, 0.2645])\n",
      "Epoch: 891\n",
      "Loss: tensor(29.5794, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5062,  0.6676,  1.1402],\n",
      "        [-0.4394,  0.5766,  1.4619]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.5252, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6954, -17.8970,  42.1154],\n",
      "        [-12.8716, -19.9861,  51.7981]])\n",
      "tensor([0.2240, 0.2643])\n",
      "Epoch: 892\n",
      "Loss: tensor(29.5252, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5061,  0.6678,  1.1398],\n",
      "        [-0.4393,  0.5768,  1.4614]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.4710, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6953, -17.8739,  42.0767],\n",
      "        [-12.8570, -19.9697,  51.7495]])\n",
      "tensor([0.2238, 0.2640])\n",
      "Epoch: 893\n",
      "Loss: tensor(29.4710, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5060,  0.6680,  1.1394],\n",
      "        [-0.4392,  0.5770,  1.4609]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.4169, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6949, -17.8505,  42.0383],\n",
      "        [-12.8428, -19.9535,  51.7007]])\n",
      "tensor([0.2235, 0.2638])\n",
      "Epoch: 894\n",
      "Loss: tensor(29.4169, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5059,  0.6682,  1.1390],\n",
      "        [-0.4390,  0.5772,  1.4604]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.3630, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6941, -17.8269,  42.0000],\n",
      "        [-12.8285, -19.9373,  51.6521]])\n",
      "tensor([0.2233, 0.2636])\n",
      "Epoch: 895\n",
      "Loss: tensor(29.3630, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5058,  0.6683,  1.1386],\n",
      "        [-0.4389,  0.5774,  1.4599]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.3091, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6936, -17.8038,  41.9615],\n",
      "        [-12.8136, -19.9204,  51.6039]])\n",
      "tensor([0.2230, 0.2634])\n",
      "Epoch: 896\n",
      "Loss: tensor(29.3091, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5057,  0.6685,  1.1381],\n",
      "        [-0.4388,  0.5776,  1.4593]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.2554, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6930, -17.7807,  41.9231],\n",
      "        [-12.7996, -19.9044,  51.5552]])\n",
      "tensor([0.2228, 0.2632])\n",
      "Epoch: 897\n",
      "Loss: tensor(29.2554, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5056,  0.6687,  1.1377],\n",
      "        [-0.4387,  0.5778,  1.4588]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.2018, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6925, -17.7577,  41.8847],\n",
      "        [-12.7855, -19.8883,  51.5066]])\n",
      "tensor([0.2225, 0.2630])\n",
      "Epoch: 898\n",
      "Loss: tensor(29.2018, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5055,  0.6689,  1.1373],\n",
      "        [-0.4385,  0.5780,  1.4583]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.1482, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6927, -17.7355,  41.8458],\n",
      "        [-12.7707, -19.8715,  51.4585]])\n",
      "tensor([0.2223, 0.2628])\n",
      "Epoch: 899\n",
      "Loss: tensor(29.1482, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5055,  0.6691,  1.1369],\n",
      "        [-0.4384,  0.5782,  1.4578]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.0947, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6919, -17.7125,  41.8075],\n",
      "        [-12.7569, -19.8556,  51.4099]])\n",
      "tensor([0.2220, 0.2626])\n",
      "Epoch: 900\n",
      "Loss: tensor(29.0947, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5054,  0.6692,  1.1365],\n",
      "        [-0.4383,  0.5784,  1.4573]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(29.0414, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6908, -17.6893,  41.7694],\n",
      "        [-12.7427, -19.8393,  51.3615]])\n",
      "tensor([0.2218, 0.2624])\n",
      "Epoch: 901\n",
      "Loss: tensor(29.0414, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5053,  0.6694,  1.1360],\n",
      "        [-0.4381,  0.5786,  1.4568]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(28.9882, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6901, -17.6664,  41.7312],\n",
      "        [-12.7284, -19.8228,  51.3134]])\n",
      "tensor([0.2215, 0.2622])\n",
      "Epoch: 902\n",
      "Loss: tensor(28.9882, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5052,  0.6696,  1.1356],\n",
      "        [-0.4380,  0.5788,  1.4563]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(28.9350, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6896, -17.6441,  41.6927],\n",
      "        [-12.7141, -19.8065,  51.2652]])\n",
      "tensor([0.2213, 0.2620])\n",
      "Epoch: 903\n",
      "Loss: tensor(28.9350, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5051,  0.6698,  1.1352],\n",
      "        [-0.4379,  0.5790,  1.4557]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(28.8820, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6885, -17.6211,  41.6546],\n",
      "        [-12.6992, -19.7892,  51.2177]])\n",
      "tensor([0.2210, 0.2618])\n",
      "Epoch: 904\n",
      "Loss: tensor(28.8820, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5050,  0.6699,  1.1348],\n",
      "        [-0.4378,  0.5792,  1.4552]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(28.8290, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6870, -17.5978,  41.6169],\n",
      "        [-12.6849, -19.7726,  51.1697]])\n",
      "tensor([0.2208, 0.2616])\n",
      "Epoch: 905\n",
      "Loss: tensor(28.8290, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5049,  0.6701,  1.1344],\n",
      "        [-0.4376,  0.5794,  1.4547]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(28.7762, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6864, -17.5756,  41.5786],\n",
      "        [-12.6711, -19.7567,  51.1214]])\n",
      "tensor([0.2206, 0.2613])\n",
      "Epoch: 906\n",
      "Loss: tensor(28.7762, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5048,  0.6703,  1.1340],\n",
      "        [-0.4375,  0.5796,  1.4542]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(28.7234, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6858, -17.5536,  41.5401],\n",
      "        [-12.6563, -19.7395,  51.0738]])\n",
      "tensor([0.2203, 0.2611])\n",
      "Epoch: 907\n",
      "Loss: tensor(28.7234, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5048,  0.6705,  1.1335],\n",
      "        [-0.4374,  0.5798,  1.4537]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(28.6708, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6849, -17.5313,  41.5019],\n",
      "        [-12.6415, -19.7224,  51.0264]])\n",
      "tensor([0.2201, 0.2609])\n",
      "Epoch: 908\n",
      "Loss: tensor(28.6708, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5047,  0.6706,  1.1331],\n",
      "        [-0.4373,  0.5800,  1.4532]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(28.6182, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6834, -17.5084,  41.4642],\n",
      "        [-12.6278, -19.7065,  50.9783]])\n",
      "tensor([0.2198, 0.2607])\n",
      "Epoch: 909\n",
      "Loss: tensor(28.6182, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5046,  0.6708,  1.1327],\n",
      "        [-0.4371,  0.5802,  1.4527]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(28.5658, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6825, -17.4865,  41.4260],\n",
      "        [-12.6139, -19.6902,  50.9304]])\n",
      "tensor([0.2196, 0.2605])\n",
      "Epoch: 910\n",
      "Loss: tensor(28.5658, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5045,  0.6710,  1.1323],\n",
      "        [-0.4370,  0.5804,  1.4522]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4646], grad_fn=<SubBackward0>)\n",
      "tensor(28.5134, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6810, -17.4639,  41.3882],\n",
      "        [-12.5993, -19.6732,  50.8829]])\n",
      "tensor([0.2193, 0.2603])\n",
      "Epoch: 911\n",
      "Loss: tensor(28.5134, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5044,  0.6712,  1.1319],\n",
      "        [-0.4369,  0.5806,  1.4517]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(28.4611, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6797, -17.4415,  41.3503],\n",
      "        [-12.5854, -19.6570,  50.8351]])\n",
      "tensor([0.2191, 0.2601])\n",
      "Epoch: 912\n",
      "Loss: tensor(28.4611, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5043,  0.6713,  1.1315],\n",
      "        [-0.4368,  0.5808,  1.4512]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(28.4090, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6786, -17.4195,  41.3123],\n",
      "        [-12.5714, -19.6404,  50.7875]])\n",
      "tensor([0.2189, 0.2599])\n",
      "Epoch: 913\n",
      "Loss: tensor(28.4090, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5042,  0.6715,  1.1311],\n",
      "        [-0.4366,  0.5810,  1.4506]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(28.3569, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6776, -17.3977,  41.2742],\n",
      "        [-12.5572, -19.6238,  50.7400]])\n",
      "tensor([0.2186, 0.2597])\n",
      "Epoch: 914\n",
      "Loss: tensor(28.3569, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5042,  0.6717,  1.1306],\n",
      "        [-0.4365,  0.5812,  1.4501]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(28.3050, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6756, -17.3750,  41.2368],\n",
      "        [-12.5433, -19.6075,  50.6923]])\n",
      "tensor([0.2184, 0.2595])\n",
      "Epoch: 915\n",
      "Loss: tensor(28.3050, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5041,  0.6719,  1.1302],\n",
      "        [-0.4364,  0.5814,  1.4496]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(28.2531, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6740, -17.3528,  41.1990],\n",
      "        [-12.5294, -19.5910,  50.6448]])\n",
      "tensor([0.2181, 0.2593])\n",
      "Epoch: 916\n",
      "Loss: tensor(28.2531, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5040,  0.6720,  1.1298],\n",
      "        [-0.4363,  0.5816,  1.4491]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(28.2013, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6729, -17.3312,  41.1611],\n",
      "        [-12.5154, -19.5745,  50.5975]])\n",
      "tensor([0.2179, 0.2591])\n",
      "Epoch: 917\n",
      "Loss: tensor(28.2013, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5039,  0.6722,  1.1294],\n",
      "        [-0.4361,  0.5818,  1.4486]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(28.1497, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6715, -17.3095,  41.1232],\n",
      "        [-12.5018, -19.5584,  50.5498]])\n",
      "tensor([0.2177, 0.2589])\n",
      "Epoch: 918\n",
      "Loss: tensor(28.1497, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5038,  0.6724,  1.1290],\n",
      "        [-0.4360,  0.5820,  1.4481]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0351,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(28.0981, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6699, -17.2875,  41.0856],\n",
      "        [-12.4881, -19.5421,  50.5023]])\n",
      "tensor([0.2174, 0.2587])\n",
      "Epoch: 919\n",
      "Loss: tensor(28.0981, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5037,  0.6726,  1.1286],\n",
      "        [-0.4359,  0.5821,  1.4476]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(28.0466, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6683, -17.2657,  41.0479],\n",
      "        [-12.4743, -19.5257,  50.4550]])\n",
      "tensor([0.2172, 0.2585])\n",
      "Epoch: 920\n",
      "Loss: tensor(28.0466, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5036,  0.6727,  1.1282],\n",
      "        [-0.4358,  0.5823,  1.4471]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.9952, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6668, -17.2442,  41.0101],\n",
      "        [-12.4604, -19.5093,  50.4077]])\n",
      "tensor([0.2169, 0.2583])\n",
      "Epoch: 921\n",
      "Loss: tensor(27.9952, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5035,  0.6729,  1.1278],\n",
      "        [-0.4356,  0.5825,  1.4466]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.9440, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6649, -17.2222,  40.9727],\n",
      "        [-12.4471, -19.4934,  50.3602]])\n",
      "tensor([0.2167, 0.2581])\n",
      "Epoch: 922\n",
      "Loss: tensor(27.9440, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5035,  0.6731,  1.1274],\n",
      "        [-0.4355,  0.5827,  1.4461]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.8927, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6632, -17.2005,  40.9351],\n",
      "        [-12.4335, -19.4770,  50.3129]])\n",
      "tensor([0.2165, 0.2579])\n",
      "Epoch: 923\n",
      "Loss: tensor(27.8927, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5034,  0.6732,  1.1269],\n",
      "        [-0.4354,  0.5829,  1.4456]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.8417, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6619, -17.1796,  40.8972],\n",
      "        [-12.4206, -19.4615,  50.2652]])\n",
      "tensor([0.2162, 0.2576])\n",
      "Epoch: 924\n",
      "Loss: tensor(27.8417, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5033,  0.6734,  1.1265],\n",
      "        [-0.4353,  0.5831,  1.4451]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.7906, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6601, -17.1580,  40.8597],\n",
      "        [-12.4068, -19.4450,  50.2181]])\n",
      "tensor([0.2160, 0.2574])\n",
      "Epoch: 925\n",
      "Loss: tensor(27.7906, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5032,  0.6736,  1.1261],\n",
      "        [-0.4351,  0.5833,  1.4446]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.7397, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6584, -17.1367,  40.8222],\n",
      "        [-12.3932, -19.4287,  50.1710]])\n",
      "tensor([0.2158, 0.2572])\n",
      "Epoch: 926\n",
      "Loss: tensor(27.7397, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5031,  0.6738,  1.1257],\n",
      "        [-0.4350,  0.5835,  1.4441]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.6889, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6559, -17.1145,  40.7851],\n",
      "        [-12.3801, -19.4130,  50.1236]])\n",
      "tensor([0.2155, 0.2570])\n",
      "Epoch: 927\n",
      "Loss: tensor(27.6889, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5030,  0.6739,  1.1253],\n",
      "        [-0.4349,  0.5837,  1.4436]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.6382, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6541, -17.0933,  40.7476],\n",
      "        [-12.3667, -19.3968,  50.0764]])\n",
      "tensor([0.2153, 0.2568])\n",
      "Epoch: 928\n",
      "Loss: tensor(27.6382, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5029,  0.6741,  1.1249],\n",
      "        [-0.4348,  0.5839,  1.4431]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.5876, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6520, -17.0719,  40.7102],\n",
      "        [-12.3528, -19.3801,  50.0298]])\n",
      "tensor([0.2151, 0.2566])\n",
      "Epoch: 929\n",
      "Loss: tensor(27.5876, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5029,  0.6743,  1.1245],\n",
      "        [-0.4346,  0.5841,  1.4426]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.5371, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6500, -17.0506,  40.6729],\n",
      "        [-12.3397, -19.3643,  49.9825]])\n",
      "tensor([0.2148, 0.2564])\n",
      "Epoch: 930\n",
      "Loss: tensor(27.5371, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5028,  0.6744,  1.1241],\n",
      "        [-0.4345,  0.5843,  1.4421]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.4866, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6479, -17.0293,  40.6356],\n",
      "        [-12.3258, -19.3475,  49.9359]])\n",
      "tensor([0.2146, 0.2562])\n",
      "Epoch: 931\n",
      "Loss: tensor(27.4866, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5027,  0.6746,  1.1237],\n",
      "        [-0.4344,  0.5845,  1.4416]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.4363, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6463, -17.0086,  40.5981],\n",
      "        [-12.3120, -19.3308,  49.8893]])\n",
      "tensor([0.2144, 0.2560])\n",
      "Epoch: 932\n",
      "Loss: tensor(27.4363, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5026,  0.6748,  1.1233],\n",
      "        [-0.4343,  0.5847,  1.4411]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.3860, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6436, -16.9869,  40.5612],\n",
      "        [-12.2990, -19.3150,  49.8422]])\n",
      "tensor([0.2141, 0.2558])\n",
      "Epoch: 933\n",
      "Loss: tensor(27.3860, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5025,  0.6750,  1.1229],\n",
      "        [-0.4341,  0.5849,  1.4406]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.3359, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6419, -16.9662,  40.5237],\n",
      "        [-12.2849, -19.2980,  49.7959]])\n",
      "tensor([0.2139, 0.2556])\n",
      "Epoch: 934\n",
      "Loss: tensor(27.3359, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5024,  0.6751,  1.1225],\n",
      "        [-0.4340,  0.5851,  1.4401]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.2858, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6398, -16.9453,  40.4864],\n",
      "        [-12.2712, -19.2813,  49.7494]])\n",
      "tensor([0.2137, 0.2554])\n",
      "Epoch: 935\n",
      "Loss: tensor(27.2858, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5023,  0.6753,  1.1221],\n",
      "        [-0.4339,  0.5853,  1.4396]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.2359, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6375, -16.9243,  40.4493],\n",
      "        [-12.2579, -19.2651,  49.7027]])\n",
      "tensor([0.2134, 0.2552])\n",
      "Epoch: 936\n",
      "Loss: tensor(27.2359, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5022,  0.6755,  1.1217],\n",
      "        [-0.4338,  0.5854,  1.4391]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.1860, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6351, -16.9032,  40.4123],\n",
      "        [-12.2442, -19.2484,  49.6564]])\n",
      "tensor([0.2132, 0.2550])\n",
      "Epoch: 937\n",
      "Loss: tensor(27.1860, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5022,  0.6756,  1.1213],\n",
      "        [-0.4337,  0.5856,  1.4386]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.1363, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6331, -16.8828,  40.3750],\n",
      "        [-12.2309, -19.2322,  49.6098]])\n",
      "tensor([0.2130, 0.2548])\n",
      "Epoch: 938\n",
      "Loss: tensor(27.1363, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5021,  0.6758,  1.1209],\n",
      "        [-0.4335,  0.5858,  1.4381]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.0866, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6312, -16.8624,  40.3375],\n",
      "        [-12.2181, -19.2163,  49.5630]])\n",
      "tensor([0.2128, 0.2546])\n",
      "Epoch: 939\n",
      "Loss: tensor(27.0866, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5020,  0.6760,  1.1204],\n",
      "        [-0.4334,  0.5860,  1.4376]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(27.0370, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6287, -16.8415,  40.3007],\n",
      "        [-12.2047, -19.2000,  49.5166]])\n",
      "tensor([0.2125, 0.2544])\n",
      "Epoch: 940\n",
      "Loss: tensor(27.0370, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5019,  0.6761,  1.1200],\n",
      "        [-0.4333,  0.5862,  1.4371]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(26.9875, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6264, -16.8208,  40.2636],\n",
      "        [-12.1916, -19.1838,  49.4700]])\n",
      "tensor([0.2123, 0.2542])\n",
      "Epoch: 941\n",
      "Loss: tensor(26.9875, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5018,  0.6763,  1.1196],\n",
      "        [-0.4332,  0.5864,  1.4366]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(26.9381, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6241, -16.8004,  40.2265],\n",
      "        [-12.1785, -19.1678,  49.4236]])\n",
      "tensor([0.2121, 0.2540])\n",
      "Epoch: 942\n",
      "Loss: tensor(26.9381, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5017,  0.6765,  1.1192],\n",
      "        [-0.4330,  0.5866,  1.4361]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(26.8888, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6214, -16.7794,  40.1897],\n",
      "        [-12.1649, -19.1511,  49.3775]])\n",
      "tensor([0.2119, 0.2538])\n",
      "Epoch: 943\n",
      "Loss: tensor(26.8888, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5016,  0.6766,  1.1188],\n",
      "        [-0.4329,  0.5868,  1.4356]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(26.8395, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6189, -16.7589,  40.1528],\n",
      "        [-12.1515, -19.1345,  49.3313]])\n",
      "tensor([0.2116, 0.2536])\n",
      "Epoch: 944\n",
      "Loss: tensor(26.8395, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5016,  0.6768,  1.1184],\n",
      "        [-0.4328,  0.5870,  1.4351]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(26.7904, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6159, -16.7378,  40.1163],\n",
      "        [-12.1388, -19.1188,  49.2848]])\n",
      "tensor([0.2114, 0.2534])\n",
      "Epoch: 945\n",
      "Loss: tensor(26.7904, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5015,  0.6770,  1.1180],\n",
      "        [-0.4327,  0.5872,  1.4346]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(26.7414, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6136, -16.7178,  40.0792],\n",
      "        [-12.1254, -19.1022,  49.2388]])\n",
      "tensor([0.2112, 0.2532])\n",
      "Epoch: 946\n",
      "Loss: tensor(26.7414, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5014,  0.6771,  1.1176],\n",
      "        [-0.4326,  0.5874,  1.4342]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(26.6924, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6108, -16.6971,  40.0425],\n",
      "        [-12.1116, -19.0851,  49.1932]])\n",
      "tensor([0.2110, 0.2530])\n",
      "Epoch: 947\n",
      "Loss: tensor(26.6924, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5013,  0.6773,  1.1172],\n",
      "        [-0.4324,  0.5876,  1.4337]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(26.6436, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6083, -16.6768,  40.0057],\n",
      "        [-12.0992, -19.0698,  49.1465]])\n",
      "tensor([0.2107, 0.2527])\n",
      "Epoch: 948\n",
      "Loss: tensor(26.6436, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5012,  0.6775,  1.1168],\n",
      "        [-0.4323,  0.5877,  1.4332]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(26.5948, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6060, -16.6570,  39.9686],\n",
      "        [-12.0863, -19.0535,  49.1004]])\n",
      "tensor([0.2105, 0.2525])\n",
      "Epoch: 949\n",
      "Loss: tensor(26.5948, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5011,  0.6776,  1.1164],\n",
      "        [-0.4322,  0.5879,  1.4327]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4645], grad_fn=<SubBackward0>)\n",
      "tensor(26.5462, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6034, -16.6368,  39.9318],\n",
      "        [-12.0728, -19.0369,  49.0546]])\n",
      "tensor([0.2103, 0.2523])\n",
      "Epoch: 950\n",
      "Loss: tensor(26.5462, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5010,  0.6778,  1.1160],\n",
      "        [-0.4321,  0.5881,  1.4322]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(26.4976, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.6009, -16.6167,  39.8950],\n",
      "        [-12.0605, -19.0214,  49.0082]])\n",
      "tensor([0.2101, 0.2521])\n",
      "Epoch: 951\n",
      "Loss: tensor(26.4976, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5010,  0.6780,  1.1156],\n",
      "        [-0.4320,  0.5883,  1.4317]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(26.4491, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5980, -16.5963,  39.8585],\n",
      "        [-12.0472, -19.0049,  48.9625]])\n",
      "tensor([0.2098, 0.2519])\n",
      "Epoch: 952\n",
      "Loss: tensor(26.4491, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5009,  0.6781,  1.1152],\n",
      "        [-0.4318,  0.5885,  1.4312]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(26.4007, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5963, -16.5775,  39.8211],\n",
      "        [-12.0341, -18.9886,  48.9166]])\n",
      "tensor([0.2096, 0.2517])\n",
      "Epoch: 953\n",
      "Loss: tensor(26.4007, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5008,  0.6783,  1.1148],\n",
      "        [-0.4317,  0.5887,  1.4307]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(26.3524, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5933, -16.5573,  39.7846],\n",
      "        [-12.0210, -18.9721,  48.8709]])\n",
      "tensor([0.2094, 0.2515])\n",
      "Epoch: 954\n",
      "Loss: tensor(26.3524, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5007,  0.6785,  1.1144],\n",
      "        [-0.4316,  0.5889,  1.4302]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(26.3042, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5895, -16.5362,  39.7486],\n",
      "        [-12.0081, -18.9559,  48.8251]])\n",
      "tensor([0.2092, 0.2513])\n",
      "Epoch: 955\n",
      "Loss: tensor(26.3042, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5006,  0.6786,  1.1140],\n",
      "        [-0.4315,  0.5891,  1.4297]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(26.2561, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5872, -16.5170,  39.7117],\n",
      "        [-11.9955, -18.9400,  48.7791]])\n",
      "tensor([0.2090, 0.2511])\n",
      "Epoch: 956\n",
      "Loss: tensor(26.2561, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5005,  0.6788,  1.1136],\n",
      "        [-0.4313,  0.5893,  1.4293]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(26.2080, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5839, -16.4965,  39.6754],\n",
      "        [-11.9829, -18.9242,  48.7332]])\n",
      "tensor([0.2087, 0.2509])\n",
      "Epoch: 957\n",
      "Loss: tensor(26.2080, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5004,  0.6790,  1.1133],\n",
      "        [-0.4312,  0.5895,  1.4288]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(26.1601, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5809, -16.4767,  39.6390],\n",
      "        [-11.9698, -18.9077,  48.6877]])\n",
      "tensor([0.2085, 0.2507])\n",
      "Epoch: 958\n",
      "Loss: tensor(26.1601, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5004,  0.6791,  1.1129],\n",
      "        [-0.4311,  0.5896,  1.4283]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(26.1122, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5777, -16.4564,  39.6028],\n",
      "        [-11.9568, -18.8913,  48.6423]])\n",
      "tensor([0.2083, 0.2505])\n",
      "Epoch: 959\n",
      "Loss: tensor(26.1122, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5003,  0.6793,  1.1125],\n",
      "        [-0.4310,  0.5898,  1.4278]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(26.0645, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5751, -16.4371,  39.5660],\n",
      "        [-11.9440, -18.8752,  48.5966]])\n",
      "tensor([0.2081, 0.2503])\n",
      "Epoch: 960\n",
      "Loss: tensor(26.0645, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5002,  0.6795,  1.1121],\n",
      "        [-0.4309,  0.5900,  1.4273]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(26.0168, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5716, -16.4168,  39.5299],\n",
      "        [-11.9312, -18.8590,  48.5511]])\n",
      "tensor([0.2079, 0.2501])\n",
      "Epoch: 961\n",
      "Loss: tensor(26.0168, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5001,  0.6796,  1.1117],\n",
      "        [-0.4308,  0.5902,  1.4268]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.9692, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5688, -16.3974,  39.4934],\n",
      "        [-11.9182, -18.8425,  48.5057]])\n",
      "tensor([0.2076, 0.2499])\n",
      "Epoch: 962\n",
      "Loss: tensor(25.9692, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.5000,  0.6798,  1.1113],\n",
      "        [-0.4306,  0.5904,  1.4263]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.9217, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5655, -16.3775,  39.4572],\n",
      "        [-11.9061, -18.8271,  48.4598]])\n",
      "tensor([0.2074, 0.2497])\n",
      "Epoch: 963\n",
      "Loss: tensor(25.9217, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4999,  0.6800,  1.1109],\n",
      "        [-0.4305,  0.5906,  1.4259]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.8743, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5630, -16.3587,  39.4205],\n",
      "        [-11.8931, -18.8107,  48.4146]])\n",
      "tensor([0.2072, 0.2495])\n",
      "Epoch: 964\n",
      "Loss: tensor(25.8743, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4998,  0.6801,  1.1105],\n",
      "        [-0.4304,  0.5908,  1.4254]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.8270, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5597, -16.3390,  39.3843],\n",
      "        [-11.8800, -18.7939,  48.3696]])\n",
      "tensor([0.2070, 0.2493])\n",
      "Epoch: 965\n",
      "Loss: tensor(25.8270, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4998,  0.6803,  1.1101],\n",
      "        [-0.4303,  0.5910,  1.4249]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0352,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.7797, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5567, -16.3196,  39.3480],\n",
      "        [-11.8679, -18.7785,  48.3238]])\n",
      "tensor([0.2068, 0.2491])\n",
      "Epoch: 966\n",
      "Loss: tensor(25.7797, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4997,  0.6804,  1.1097],\n",
      "        [-0.4302,  0.5911,  1.4244]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.7326, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5541, -16.3008,  39.3113],\n",
      "        [-11.8551, -18.7623,  48.2786]])\n",
      "tensor([0.2066, 0.2489])\n",
      "Epoch: 967\n",
      "Loss: tensor(25.7326, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4996,  0.6806,  1.1093],\n",
      "        [-0.4300,  0.5913,  1.4239]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.6855, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5510, -16.2814,  39.2751],\n",
      "        [-11.8420, -18.7456,  48.2337]])\n",
      "tensor([0.2063, 0.2487])\n",
      "Epoch: 968\n",
      "Loss: tensor(25.6855, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4995,  0.6808,  1.1089],\n",
      "        [-0.4299,  0.5915,  1.4234]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.6386, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5476, -16.2620,  39.2390],\n",
      "        [-11.8298, -18.7300,  48.1882]])\n",
      "tensor([0.2061, 0.2485])\n",
      "Epoch: 969\n",
      "Loss: tensor(25.6386, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4994,  0.6809,  1.1085],\n",
      "        [-0.4298,  0.5917,  1.4230]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.5917, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5445, -16.2428,  39.2028],\n",
      "        [-11.8169, -18.7134,  48.1434]])\n",
      "tensor([0.2059, 0.2483])\n",
      "Epoch: 970\n",
      "Loss: tensor(25.5917, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4993,  0.6811,  1.1081],\n",
      "        [-0.4297,  0.5919,  1.4225]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.5449, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5418, -16.2242,  39.1663],\n",
      "        [-11.8042, -18.6971,  48.0983]])\n",
      "tensor([0.2057, 0.2481])\n",
      "Epoch: 971\n",
      "Loss: tensor(25.5449, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4992,  0.6813,  1.1077],\n",
      "        [-0.4296,  0.5921,  1.4220]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.4982, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5386, -16.2051,  39.1301],\n",
      "        [-11.7919, -18.6814,  48.0530]])\n",
      "tensor([0.2055, 0.2479])\n",
      "Epoch: 972\n",
      "Loss: tensor(25.4982, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4992,  0.6814,  1.1073],\n",
      "        [-0.4294,  0.5923,  1.4215]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.4516, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5346, -16.1851,  39.0946],\n",
      "        [-11.7793, -18.6652,  48.0081]])\n",
      "tensor([0.2053, 0.2477])\n",
      "Epoch: 973\n",
      "Loss: tensor(25.4516, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4991,  0.6816,  1.1070],\n",
      "        [-0.4293,  0.5925,  1.4210]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.4050, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5309, -16.1656,  39.0588],\n",
      "        [-11.7665, -18.6487,  47.9633]])\n",
      "tensor([0.2051, 0.2475])\n",
      "Epoch: 974\n",
      "Loss: tensor(25.4050, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4990,  0.6817,  1.1066],\n",
      "        [-0.4292,  0.5926,  1.4206]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.3586, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5277, -16.1468,  39.0227],\n",
      "        [-11.7542, -18.6330,  47.9182]])\n",
      "tensor([0.2049, 0.2473])\n",
      "Epoch: 975\n",
      "Loss: tensor(25.3586, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4989,  0.6819,  1.1062],\n",
      "        [-0.4291,  0.5928,  1.4201]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.3122, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5243, -16.1277,  38.9868],\n",
      "        [-11.7416, -18.6166,  47.8735]])\n",
      "tensor([0.2046, 0.2471])\n",
      "Epoch: 976\n",
      "Loss: tensor(25.3122, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4988,  0.6821,  1.1058],\n",
      "        [-0.4290,  0.5930,  1.4196]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.2660, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5203, -16.1080,  38.9512],\n",
      "        [-11.7294, -18.6007,  47.8285]])\n",
      "tensor([0.2044, 0.2469])\n",
      "Epoch: 977\n",
      "Loss: tensor(25.2660, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4987,  0.6822,  1.1054],\n",
      "        [-0.4289,  0.5932,  1.4191]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.2198, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5167, -16.0889,  38.9154],\n",
      "        [-11.7168, -18.5847,  47.7837]])\n",
      "tensor([0.2042, 0.2467])\n",
      "Epoch: 978\n",
      "Loss: tensor(25.2198, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4986,  0.6824,  1.1050],\n",
      "        [-0.4287,  0.5934,  1.4186]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.1737, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5133, -16.0702,  38.8795],\n",
      "        [-11.7039, -18.5679,  47.7394]])\n",
      "tensor([0.2040, 0.2465])\n",
      "Epoch: 979\n",
      "Loss: tensor(25.1737, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4986,  0.6826,  1.1046],\n",
      "        [-0.4286,  0.5936,  1.4182]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.1277, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5094, -16.0509,  38.8439],\n",
      "        [-11.6919, -18.5523,  47.6944]])\n",
      "tensor([0.2038, 0.2463])\n",
      "Epoch: 980\n",
      "Loss: tensor(25.1277, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4985,  0.6827,  1.1042],\n",
      "        [-0.4285,  0.5938,  1.4177]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.0817, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5059, -16.0320,  38.8081],\n",
      "        [-11.6795, -18.5362,  47.6497]])\n",
      "tensor([0.2036, 0.2461])\n",
      "Epoch: 981\n",
      "Loss: tensor(25.0817, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4984,  0.6829,  1.1038],\n",
      "        [-0.4284,  0.5939,  1.4172]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(25.0359, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.5022, -16.0132,  38.7724],\n",
      "        [-11.6670, -18.5201,  47.6052]])\n",
      "tensor([0.2034, 0.2459])\n",
      "Epoch: 982\n",
      "Loss: tensor(25.0359, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4983,  0.6830,  1.1035],\n",
      "        [-0.4283,  0.5941,  1.4167]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(24.9902, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4985, -15.9944,  38.7367],\n",
      "        [-11.6545, -18.5038,  47.5607]])\n",
      "tensor([0.2032, 0.2457])\n",
      "Epoch: 983\n",
      "Loss: tensor(24.9902, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4982,  0.6832,  1.1031],\n",
      "        [-0.4282,  0.5943,  1.4163]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(24.9445, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4947, -15.9753,  38.7012],\n",
      "        [-11.6432, -18.4888,  47.5155]])\n",
      "tensor([0.2030, 0.2455])\n",
      "Epoch: 984\n",
      "Loss: tensor(24.9445, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4981,  0.6834,  1.1027],\n",
      "        [-0.4280,  0.5945,  1.4158]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(24.8990, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4912, -15.9569,  38.6655],\n",
      "        [-11.6303, -18.4721,  47.4715]])\n",
      "tensor([0.2028, 0.2453])\n",
      "Epoch: 985\n",
      "Loss: tensor(24.8990, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4980,  0.6835,  1.1023],\n",
      "        [-0.4279,  0.5947,  1.4153]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(24.8534, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4877, -15.9385,  38.6296],\n",
      "        [-11.6180, -18.4561,  47.4269]])\n",
      "tensor([0.2026, 0.2451])\n",
      "Epoch: 986\n",
      "Loss: tensor(24.8534, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4980,  0.6837,  1.1019],\n",
      "        [-0.4278,  0.5949,  1.4148]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(24.8080, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4840, -15.9198,  38.5941],\n",
      "        [-11.6062, -18.4407,  47.3822]])\n",
      "tensor([0.2024, 0.2449])\n",
      "Epoch: 987\n",
      "Loss: tensor(24.8080, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4979,  0.6838,  1.1015],\n",
      "        [-0.4277,  0.5951,  1.4144]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(24.7627, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4808, -15.9018,  38.5582],\n",
      "        [-11.5941, -18.4247,  47.3379]])\n",
      "tensor([0.2021, 0.2447])\n",
      "Epoch: 988\n",
      "Loss: tensor(24.7627, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4978,  0.6840,  1.1011],\n",
      "        [-0.4276,  0.5952,  1.4139]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(24.7175, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4766, -15.8828,  38.5230],\n",
      "        [-11.5816, -18.4083,  47.2937]])\n",
      "tensor([0.2019, 0.2445])\n",
      "Epoch: 989\n",
      "Loss: tensor(24.7175, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4977,  0.6841,  1.1007],\n",
      "        [-0.4275,  0.5954,  1.4134]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4644], grad_fn=<SubBackward0>)\n",
      "tensor(24.6723, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4734, -15.8649,  38.4871],\n",
      "        [-11.5695, -18.3924,  47.2494]])\n",
      "tensor([0.2017, 0.2443])\n",
      "Epoch: 990\n",
      "Loss: tensor(24.6723, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4976,  0.6843,  1.1004],\n",
      "        [-0.4273,  0.5956,  1.4129]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4643], grad_fn=<SubBackward0>)\n",
      "tensor(24.6272, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4700, -15.8469,  38.4513],\n",
      "        [-11.5576, -18.3767,  47.2050]])\n",
      "tensor([0.2015, 0.2441])\n",
      "Epoch: 991\n",
      "Loss: tensor(24.6272, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4975,  0.6845,  1.1000],\n",
      "        [-0.4272,  0.5958,  1.4125]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4643], grad_fn=<SubBackward0>)\n",
      "tensor(24.5822, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4661, -15.8283,  38.4159],\n",
      "        [-11.5454, -18.3607,  47.1608]])\n",
      "tensor([0.2013, 0.2439])\n",
      "Epoch: 992\n",
      "Loss: tensor(24.5822, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4975,  0.6846,  1.0996],\n",
      "        [-0.4271,  0.5960,  1.4120]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4643], grad_fn=<SubBackward0>)\n",
      "tensor(24.5373, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4623, -15.8100,  38.3805],\n",
      "        [-11.5333, -18.3447,  47.1167]])\n",
      "tensor([0.2011, 0.2437])\n",
      "Epoch: 993\n",
      "Loss: tensor(24.5373, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4974,  0.6848,  1.0992],\n",
      "        [-0.4270,  0.5962,  1.4115]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4643], grad_fn=<SubBackward0>)\n",
      "tensor(24.4925, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4590, -15.7923,  38.3447],\n",
      "        [-11.5211, -18.3288,  47.0725]])\n",
      "tensor([0.2009, 0.2435])\n",
      "Epoch: 994\n",
      "Loss: tensor(24.4925, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4973,  0.6849,  1.0988],\n",
      "        [-0.4269,  0.5963,  1.4111]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4643], grad_fn=<SubBackward0>)\n",
      "tensor(24.4478, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4554, -15.7743,  38.3092],\n",
      "        [-11.5089, -18.3127,  47.0285]])\n",
      "tensor([0.2007, 0.2433])\n",
      "Epoch: 995\n",
      "Loss: tensor(24.4478, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4972,  0.6851,  1.0984],\n",
      "        [-0.4268,  0.5965,  1.4106]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4643], grad_fn=<SubBackward0>)\n",
      "tensor(24.4031, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4517, -15.7562,  38.2737],\n",
      "        [-11.4966, -18.2964,  46.9846]])\n",
      "tensor([0.2005, 0.2431])\n",
      "Epoch: 996\n",
      "Loss: tensor(24.4031, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4971,  0.6853,  1.0981],\n",
      "        [-0.4267,  0.5967,  1.4101]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4643], grad_fn=<SubBackward0>)\n",
      "tensor(24.3585, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4484, -15.7389,  38.2379],\n",
      "        [-11.4844, -18.2805,  46.9407]])\n",
      "tensor([0.2003, 0.2430])\n",
      "Epoch: 997\n",
      "Loss: tensor(24.3585, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4970,  0.6854,  1.0977],\n",
      "        [-0.4265,  0.5969,  1.4096]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4643], grad_fn=<SubBackward0>)\n",
      "tensor(24.3140, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4441, -15.7203,  38.2028],\n",
      "        [-11.4726, -18.2648,  46.8966]])\n",
      "tensor([0.2001, 0.2428])\n",
      "Epoch: 998\n",
      "Loss: tensor(24.3140, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4969,  0.6856,  1.0973],\n",
      "        [-0.4264,  0.5971,  1.4092]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4643], grad_fn=<SubBackward0>)\n",
      "tensor(24.2696, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[ -8.4405, -15.7025,  38.1674],\n",
      "        [-11.4604, -18.2486,  46.8529]])\n",
      "tensor([0.1999, 0.2426])\n",
      "Epoch: 999\n",
      "Loss: tensor(24.2696, grad_fn=<DivBackward0>)\n",
      "Wight: tensor([[-0.4969,  0.6857,  1.0969],\n",
      "        [-0.4263,  0.5973,  1.4087]], grad_fn=<SubBackward0>)\n",
      "Bias: tensor([-0.0353,  0.4643], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Let's modify our weight and bias multiple times in order to reach optimum value\n",
    "for i in range(1000):  \n",
    "    preds=model(inputs)\n",
    "    loss= mse(preds,targets)\n",
    "    print(loss)\n",
    "    w.retain_grad()\n",
    "    b.retain_grad()\n",
    "    print(w.grad)\n",
    "    print(b.grad)\n",
    "    loss.backward()\n",
    "    print(w.grad)\n",
    "    print(b.grad)\n",
    "    w = w - le*w.grad\n",
    "    b = b - le*b.grad\n",
    "    print(\"Epoch:\", i)\n",
    "    print(\"Loss:\",loss)\n",
    "    print(\"Wight:\",w)\n",
    "    print(\"Bias:\",b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24.2696, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.8046,  69.9341],\n",
       "        [ 85.2965, 104.3857],\n",
       "        [112.2459, 125.1124],\n",
       "        [ 19.3566,  34.7848],\n",
       "        [108.2948, 126.9948]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56.,  70.],\n",
       "       [ 81., 101.],\n",
       "       [119., 133.],\n",
       "       [ 22.,  37.],\n",
       "       [103., 119.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
